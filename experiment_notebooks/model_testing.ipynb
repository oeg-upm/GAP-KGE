{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFs download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to data/papers_data.json\n",
      "Downloaded: data/papers_pdfs/KG^2:_Learning_to_Reason_Science_Exam_Questions_with_Contextual_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Incorporating_Literals_into_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Adversarial_Contrastive_Estimation.pdf\n",
      "Downloaded: data/papers_pdfs/KBGAN:_Adversarial_Learning_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Convolutional_2D_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Answering_Visual-Relational_Queries_in_Web-Extracted_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Expeditious_Generation_of_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_Knowledge_Graph_Embeddings_with_Type_Regularizer.pdf\n",
      "Downloaded: data/papers_pdfs/Analysis_of_the_Impact_of_Negative_Sampling_on_Link_Prediction_in_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/DeepPath:_A_Reinforcement_Learning_Method_for_Knowledge_Graph_Reasoning.pdf\n",
      "Downloaded: data/papers_pdfs/Inducing_Interpretability_in_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Fast_Linear_Model_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Complex_and_Holographic_Embeddings_of_Knowledge_Graphs:_A_Comparison.pdf\n",
      "Downloaded: data/papers_pdfs/Multilingual_Knowledge_Graph_Embeddings_for_Cross-lingual_Knowledge_Alignment.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_Symmetric_Collaborative_Dialogue_Agents_with_Dynamic_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge-Based_Distant_Regularization_in_Learning_Probabilistic_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Embedding_Models_for_Episodic_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Seq2RDF:_An_end-to-end_application_for_deriving_Triples_from_Natural_Language_Text.pdf\n",
      "Downloaded: data/papers_pdfs/Hypernetwork_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Multi-Hop_Knowledge_Graph_Reasoning_with_Reward_Shaping.pdf\n",
      "Downloaded: data/papers_pdfs/MOHONE:_Modeling_Higher_Order_Network_Effects_in_KnowledgeGraphs_via_Network_Infused_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/DOLORES:_Deep_Contextualized_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Modelling_Salient_Features_as_Directions_in_Fine-Tuned_Semantic_Spaces.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Understanding_the_Geometry_of_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Multimodal_Named_Entity_Disambiguation_for_Noisy_Social_Media_Posts.pdf\n",
      "Downloaded: data/papers_pdfs/Recognizing_Mentions_of_Adverse_Drug_Reaction_in_Social_Media_Using_Knowledge-Infused_Recurrent_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Sparsity_and_Noise:_Where_Knowledge_Graph_Embeddings_Fall_Short.pdf\n",
      "Downloaded: data/papers_pdfs/Entity_Hierarchy_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/Binarized_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Long-tail_Relation_Extraction_via_Knowledge_Graph_Embeddings_and_Graph_Convolution_Networks.pdf\n",
      "Downloaded: data/papers_pdfs/Quaternion_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Relation_Embedding_with_Dihedral_Group_in_Knowledge_Graph.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_Attention-based_Embeddings_for_Relation_Prediction_in_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Neural_Variational_Inference_For_Estimating_Uncertainty_in_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Augmenting_and_Tuning_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Adaptive_Margin_Ranking_Loss_for_Knowledge_Graph_Embeddings_via_a_Correntropy_Objective_Function.pdf\n",
      "Downloaded: data/papers_pdfs/Drug-Drug_Interaction_Prediction_Based_on_Knowledge_Graph_Embeddings_and_Convolutional-LSTM_Network.pdf\n",
      "Downloaded: data/papers_pdfs/Linking_Physicians_to_Medical_Research_Results_via_Knowledge_Graph_Embeddings_and_Twitter.pdf\n",
      "Downloaded: data/papers_pdfs/RDF2Vec:_RDF_Graph_Embeddings_and_Their_Applications.pdf\n",
      "Downloaded: data/papers_pdfs/HyperKG:_Hyperbolic_Knowledge_Graph_Embeddings_for_Knowledge_Base_Completion.pdf\n",
      "Downloaded: data/papers_pdfs/Composing_Knowledge_Graph_Embeddings_via_Word_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Enriching_BERT_with_Knowledge_Graph_Embeddings_for_Document_Classification.pdf\n",
      "Downloaded: data/papers_pdfs/Recommendation_Through_Mixtures_of_Heterogeneous_Item_Relationships.pdf\n",
      "Downloaded: data/papers_pdfs/A_Survey_on_Knowledge_Graph_Embeddings_with_Literals:_Which_model_links_better_Literal-ly?.pdf\n",
      "Downloaded: data/papers_pdfs/CaRe:_Open_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/InteractE:_Improving_Convolution-based_Knowledge_Graph_Embeddings_by_Increasing_Feature_Interactions.pdf\n",
      "Downloaded: data/papers_pdfs/KEPLER:_A_Unified_Model_for_Knowledge_Embedding_and_Pre-trained_Language_Representation.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_Hierarchy-Aware_Knowledge_Graph_Embeddings_for_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Measuring_Social_Bias_in_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/A_Physical_Embedding_Model_for_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/The_KEEN_Universe:_An_Ecosystem_for_Knowledge_Graph_Embeddings_with_a_Focus_on_Reproducibility_and_Transferability.pdf\n",
      "Downloaded: data/papers_pdfs/End-to-End_Entity_Linking_and_Disambiguation_leveraging_Word_and_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/An_Evaluation_of_Knowledge_Graph_Embeddings_for_Autonomous_Driving_Data:_Experience_and_Practice.pdf\n",
      "Downloaded: data/papers_pdfs/KGvec2go_--_Knowledge_Graph_Embeddings_as_a_Service.pdf\n",
      "Downloaded: data/papers_pdfs/Evaluating_the_Calibration_of_Knowledge_Graph_Embeddings_for_Trustworthy_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Drug-Drug_Interaction_Prediction_with_Wasserstein_Adversarial_Autoencoder-based_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Exploring_the_Combination_of_Contextual_Word_Embeddings_and_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embeddings_and_Explainable_AI.pdf\n",
      "Downloaded: data/papers_pdfs/Low-Dimensional_Hyperbolic_Knowledge_Graph_Embeddings.pdf\n",
      "Failed to download GREG: A Global Level Relation Extraction with Knowledge Graph Embedding: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/10/3/1181/pdf\n",
      "Downloaded: data/papers_pdfs/Unveiling_Relations_in_the_Industry_4.0_Standards_Landscape_based_on_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/5*_Knowledge_Graph_Embeddings_with_Projective_Transformations.pdf\n",
      "Downloaded: data/papers_pdfs/Can_We_Predict_New_Facts_with_Open_Knowledge_Graph_Embeddings?_A_Benchmark_for_Open_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Benchmark_and_Best_Practices_for_Biomedical_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Adversarial_Learning_for_Debiasing_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/PyKEEN_1.0:_A_Python_Library_for_Training_and_Evaluating_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Convolutional_Complex_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Two_Stages_Approach_for_Tweet_Engagement_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/You_CAN_Teach_an_Old_Dog_New_Tricks!_On_Training_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/HittER:_Hierarchical_Transformers_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/More_is_not_Always_Better:_The_Negative_Impact_of_A-box_Materialization_on_RDF2vec_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_semantic_Image_attributes_using_Image_recognition_and_knowledge_graph_embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/DualDE:_Dually_Distilling_Knowledge_Graph_Embedding_for_Faster_and_Cheaper_Reasoning.pdf\n",
      "Downloaded: data/papers_pdfs/RDF2Vec_Light_--_A_Lightweight_Approach_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/QuatRE:_Relation-Aware_Quaternions_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embeddings_in_Geometric_Algebras.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Association_with_Hyperbolic_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Inductive_Entity_Representations_from_Text_via_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/On_the_Complementary_Nature_of_Knowledge_Graph_Embedding,_Fine_Grain_Entity_Types,_and_Language_Modeling.pdf\n",
      "Downloaded: data/papers_pdfs/MulDE:_Multi-teacher_Knowledge_Distillation_for_Low-dimensional_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Motif_Learning_in_Knowledge_Graphs_Using_Trajectories_Of_Differential_Equations.pdf\n",
      "Downloaded: data/papers_pdfs/FedE:_Embedding_Knowledge_Graphs_in_Federated_Setting.pdf\n",
      "Failed to download DisenE: Disentangling Knowledge Graph Embeddings: 404 Client Error: Not Found for url: http://arxiv.org/pdf/2010.14730v2\n",
      "Downloaded: data/papers_pdfs/Logic-guided_Semantic_Representation_Learning_for_Zero-Shot_Relation_Classification.pdf\n",
      "Downloaded: data/papers_pdfs/PairRE:_Knowledge_Graph_Embeddings_via_Paired_Relation_Vectors.pdf\n",
      "Downloaded: data/papers_pdfs/Debiasing_knowledge_graph_embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Overcoming_low-utility_facets_for_complex_answer_retrieval.pdf\n",
      "Downloaded: data/papers_pdfs/Seeing_is_Knowing!_Fact-based_Visual_Question_Answering_using_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Continual_Learning_of_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/RelWalk_A_Latent_Variable_Model_Approach_to_Knowledge_Graph_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/Demographic_Aware_Probabilistic_Medical_Knowledge_Graph_Embeddings_of_Electronic_Medical_Records.pdf\n",
      "Downloaded: data/papers_pdfs/Incorporating_Connections_Beyond_Knowledge_Embeddings:_A_Plug-and-Play_Module_to_Enhance_Commonsense_Reasoning_in_Machine_Reading_Comprehension.pdf\n",
      "Downloaded: data/papers_pdfs/Hyperbolic_Geometry_is_Not_Necessary:_Lightweight_Euclidean-Based_Models_for_Low-Dimensional_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/NuPS:_A_Parameter_Server_for_Machine_Learning_with_Non-Uniform_Parameter_Access.pdf\n",
      "Downloaded: data/papers_pdfs/Multiple_Run_Ensemble_Learning_with_Low-Dimensional_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Highly_Efficient_Knowledge_Graph_Embedding_Learning_with_Orthogonal_Procrustes_Analysis.pdf\n",
      "Downloaded: data/papers_pdfs/Edge:_Enriching_Knowledge_Graph_Embeddings_with_External_Text.pdf\n",
      "Downloaded: data/papers_pdfs/KI-BERT:_Infusing_Knowledge_Context_for_Better_Language_and_Domain_Understanding.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Robust_One-shot_Task_Execution_using_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Predicting_Gene-Disease_Associations_with_Knowledge_Graph_Embeddings_over_Multiple_Ontologies.pdf\n",
      "Downloaded: data/papers_pdfs/Understanding_the_Performance_of_Knowledge_Graph_Embeddings_in_Drug_Discovery.pdf\n",
      "Downloaded: data/papers_pdfs/A_Knowledge_Graph-Enhanced_Tensor_Factorisation_Model_for_Discovering_Drug_Targets.pdf\n",
      "Downloaded: data/papers_pdfs/[Re]_Improving_Multi-hop_Question_Answering_over_Knowledge_Graphs_using_Knowledge_Base_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Hyperbolic_Temporal_Knowledge_Graph_Embeddings_with_Relational_and_Time_Curvatures.pdf\n",
      "Downloaded: data/papers_pdfs/RelWalk_-_A_Latent_Variable_Model_Approach_to_Knowledge_Graph_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/A_Greedy_Bit-flip_Training_Algorithm_for_Binarized_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Exploiting_Network_Structures_to_Improve_Semantic_Representation_for_the_Financial_Domain.pdf\n",
      "Downloaded: data/papers_pdfs/Geometric_Models_for_(Temporally)_Attributed_Description_Logics.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_through_structure:_towards_deep_neuromorphic_knowledge_graph_embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Automatic_Bias_Detection_in_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/BiQUE:_Biquaternionic_Embeddings_of_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Multi-Relational_Embedding_for_Knowledge_Graph_Representation_and_Analysis.pdf\n",
      "Downloaded: data/papers_pdfs/Relation_Prediction_as_an_Auxiliary_Training_Objective_for_Improving_Multi-Relational_Graph_Representations.pdf\n",
      "Downloaded: data/papers_pdfs/CareGraph:_A_Graph-based_Recommender_System_for_Diabetes_Self-Care.pdf\n",
      "Downloaded: data/papers_pdfs/Explaining_Knowledge_Graph_Embedding_via_Latent_Rule_Learning.pdf\n",
      "Downloaded: data/papers_pdfs/Time-aware_Relational_Graph_Attention_Network_for_Temporal_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/What_is_Learned_in_Knowledge_Graph_Embeddings?.pdf\n",
      "Downloaded: data/papers_pdfs/Path-Enhanced_Multi-Relational_Question_Answering_with_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Low_Resource_Quadratic_Forms_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Can_Knowledge_Graph_Embeddings_Tell_Us_What_Fact-checked_Claims_Are_About?.pdf\n",
      "Downloaded: data/papers_pdfs/RelDiff:_Enriching_Knowledge_Graph_Relation_Representations_for_Sensitivity_Classification.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Representation_Learning_using_Ordinary_Differential_Equations.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_to_Interact:_An_Adaptive_Interaction_Framework_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Integrating_knowledge_graph_embeddings_to_improve_mention_representation_for_bridging_anaphora_resolution.pdf\n",
      "Downloaded: data/papers_pdfs/Utilising_Knowledge_Graph_Embeddings_for_Data-to-Text_Generation.pdf\n",
      "Downloaded: data/papers_pdfs/Adversarial_Attacks_on_Knowledge_Graph_Embeddings_via_Instance_Attribution_Methods.pdf\n",
      "Downloaded: data/papers_pdfs/Poisoning_Knowledge_Graph_Embeddings_via_Relation_Inference_Patterns.pdf\n",
      "Downloaded: data/papers_pdfs/Transformation_of_Node_to_Knowledge_Graph_Embeddings_for_Faster_Link_Prediction_in_Social_Networks.pdf\n",
      "Downloaded: data/papers_pdfs/A_Joint_Training_Framework_for_Open-World_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Probabilistic_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Drug_Re-positioning_via_Text_Augmented_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Pretrain-KGEs:_Learning_Knowledge_Representation_from_Pretrained_Models_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/QubitE:_Qubit_Embedding_for_Knowledge_Graph_Completion.pdf\n",
      "Downloaded: data/papers_pdfs/KGE-CL:_Contrastive_Learning_of_Tensor_Decomposition_Based_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Prediction_of_Adverse_Biological_Effects_of_Chemicals_Using_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Implications_of_Topological_Imbalance_for_Representation_Learning_on_Biomedical_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Improving_and_Diagnosing_Knowledge-Based_Visual_Question_Answering_via_Entity_Enhanced_Knowledge_Injection.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embedding_in_E-commerce_Applications:_Attentive_Reasoning,_Explanations,_and_Transferable_Rules.pdf\n",
      "Downloaded: data/papers_pdfs/Self-attention_Presents_Low-dimensional_Knowledge_Graph_Embeddings_for_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Zero-shot_and_Few-shot_Learning_with_Knowledge_Graphs:_A_Comprehensive_Survey.pdf\n",
      "Downloaded: data/papers_pdfs/Contrastive_Object_Detection_Using_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Swift_and_Sure:_Hardness-aware_Contrastive_Learning_for_Low-dimensional_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Reasoning_Through_Memorization:_Nearest_Neighbor_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/A_Knowledge_Graph_Embeddings_based_Approach_for_Author_Name_Disambiguation_using_Literals.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Loosely-Coupling_Knowledge_Graph_Embeddings_and_Ontology-based_Reasoning.pdf\n",
      "Downloaded: data/papers_pdfs/InterHT:_Knowledge_Graph_Embeddings_by_Interaction_between_Head_and_Tail_Entities.pdf\n",
      "Downloaded: data/papers_pdfs/Contextual_Semantic_Embeddings_for_Ontology_Subsumption_Prediction.pdf\n",
      "Failed to download Geometric Algebra based Embeddings for Static and Temporal Knowledge Graph Completion: 404 Client Error: Not Found for url: http://arxiv.org/pdf/2202.09464v3\n",
      "Downloaded: data/papers_pdfs/Dual_Embodied-Symbolic_Concept_Representations_for_Deep_Learning.pdf\n",
      "Downloaded: data/papers_pdfs/LEMON:_LanguagE_ModeL_for_Negative_Sampling_of_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Duality-Induced_Regularizer_for_Semantic_Matching_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Ontology_Matching_Through_Absolute_Orientation_of_Embedding_Spaces.pdf\n",
      "Failed to download Learning Entity and Relation Embeddings for Knowledge Graph Completion: 403 Client Error: Forbidden for url: https://dl.acm.org/doi/10.5555/2886521.2886624\n",
      "Downloaded: data/papers_pdfs/Hyperbolic_Hierarchical_Knowledge_Graph_Embeddings_for_Link_Prediction_in_Low_Dimensions.pdf\n",
      "Downloaded: data/papers_pdfs/Kronecker_Decomposition_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/CascadER:_Cross-Modal_Cascading_for_Knowledge_Graph_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/A_Birds_Eye_View_on_Knowledge_Graph_Embeddings,_Software_Libraries,_Applications_and_Challenges.pdf\n",
      "Downloaded: data/papers_pdfs/Ultrahyperbolic_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/On_the_Effectiveness_of_Knowledge_Graph_Embeddings:_a_Rule_Mining_Approach.pdf\n",
      "Downloaded: data/papers_pdfs/Geometry_Interaction_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Start_Small,_Think_Big:_On_Hyperparameter_Optimization_for_Large-Scale_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/The_DLCC_Node_Classification_Benchmark_for_Analyzing_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Hardware-agnostic_Computation_for_Large-scale_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/$Î¼\\text{KG}$:_A_Library_for_Multi-source_Knowledge_Graph_Embeddings_and_Applications.pdf\n",
      "Downloaded: data/papers_pdfs/KRACL:_Contrastive_Learning_with_Graph_Context_Modeling_for_Sparse_Knowledge_Graph_Completion.pdf\n",
      "Downloaded: data/papers_pdfs/Repurposing_Knowledge_Graph_Embeddings_for_Triple_Representation_via_Weak_Supervision.pdf\n",
      "Failed to download Mixed-Curvature Multi-Relational Graph Neural Network for Knowledge Graph Completion: 403 Client Error: Forbidden for url: https://dl.acm.org/doi/pdf/10.1145/3442381.3450118\n",
      "Downloaded: data/papers_pdfs/TripleRE:_Knowledge_Graph_Embeddings_via_Tripled_Relation_Vectors.pdf\n",
      "Downloaded: data/papers_pdfs/LambdaKG:_A_Library_for_Pre-trained_Language_Model-Based_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Adversarial_Robustness_of_Representation_Learning_for_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Learning_Hierarchy-Aware_Quaternion_Knowledge_Graph_Embeddings_with_Representing_Relations_as_3D_Rotations.pdf\n",
      "Downloaded: data/papers_pdfs/A_Survey_on_Knowledge_Graph-based_Methods_for_Automated_Driving.pdf\n",
      "Downloaded: data/papers_pdfs/GLINKX:_A_Scalable_Unified_Framework_For_Homophilous_and_Heterophilous_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Enhancing_Patent_Retrieval_using_Text_and_Knowledge_Graph_Embeddings:_A_Technical_Note.pdf\n",
      "Downloaded: data/papers_pdfs/Complex_Hyperbolic_Knowledge_Graph_Embeddings_with_Fast_Fourier_Transform.pdf\n",
      "Downloaded: data/papers_pdfs/KGTN-ens:_Few-Shot_Image_Classification_with_Knowledge_Graph_Ensembles.pdf\n",
      "Downloaded: data/papers_pdfs/Combining_Contrastive_Learning_and_Knowledge_Graph_Embeddings_to_develop_medical_word_embeddings_for_the_Italian_language.pdf\n",
      "Downloaded: data/papers_pdfs/Biomedical_Multi-hop_Question_Answering_Using_Knowledge_Graph_Embeddings_and_Language_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Customizing_Knowledge_Graph_Embedding_to_Improve_Clinical_Study_Recommendation.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Reasoning_via_Jointly_Modeling_Knowledge_Graphs_and_Soft_Rules.pdf\n",
      "Downloaded: data/papers_pdfs/Editing_Language_Model-based_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Link_Prediction_with_Attention_Applied_on_Multiple_Knowledge_Graph_Embedding_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Effects_of_Locality_and_Rule_Language_on_Explanations_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Cardinality_Estimation_over_Knowledge_Graphs_with_Embeddings_and_Graph_Neural_Networks.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graphs:_Opportunities_and_Challenges.pdf\n",
      "Downloaded: data/papers_pdfs/Enhancing_Embedding_Representations_of_Biomedical_Data_using_Logic_Knowledge.pdf\n",
      "Downloaded: data/papers_pdfs/Constructing_a_Knowledge_Graph_from_Textual_Descriptions_of_Software_Vulnerabilities_in_the_National_Vulnerability_Database.pdf\n",
      "Downloaded: data/papers_pdfs/Growing_and_Serving_Large_Open-domain_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/FedHGN:_A_Federated_Framework_for_Heterogeneous_Graph_Neural_Networks.pdf\n",
      "Downloaded: data/papers_pdfs/HaSa:_Hardness_and_Structure-Aware_Contrastive_Knowledge_Graph_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/Jointly_Learning_Propagating_Features_on_the_Knowledge_Graph_for_Movie_Recommendation.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embeddings_in_the_Biomedical_Domain:_Are_They_Useful?_A_Look_at_Link_Prediction,_Rule_Learning,_and_Downstream_Polypharmacy_Tasks.pdf\n",
      "Downloaded: data/papers_pdfs/What_Makes_Entities_Similar?_A_Similarity_Flooding_Perspective_for_Multi-sourced_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Schema_First!_Learn_Versatile_Knowledge_Graph_Embeddings_by_Capturing_Semantics_with_MASCHInE.pdf\n",
      "Downloaded: data/papers_pdfs/Leveraging_Knowledge_Graph_Embeddings_to_Enhance_Contextual_Representations_for_Relation_Extraction.pdf\n",
      "Downloaded: data/papers_pdfs/Explainable_Representations_for_Relation_Prediction_in_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Concept2Box:_Joint_Geometric_Embeddings_for_Learning_Two-View_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/A_Personalized_Recommender_System_Based-on_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Benchmark_datasets_for_biomedical_knowledge_graphs_with_negative_statements.pdf\n",
      "Downloaded: data/papers_pdfs/Rethinking_Uncertainly_Missing_and_Ambiguous_Visual_Modality_in_Multi-Modal_Entity_Alignment.pdf\n",
      "Downloaded: data/papers_pdfs/Biomedical_Knowledge_Graph_Embeddings_with_Negative_Statements.pdf\n",
      "Downloaded: data/papers_pdfs/Simple_Rule_Injection_for_ComplEx_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Development_of_a_Knowledge_Graph_Embeddings_Model_for_Pain.pdf\n",
      "Downloaded: data/papers_pdfs/Leveraging_Knowledge_and_Reinforcement_Learning_for_Enhanced_Reliability_of_Language_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Large_language_models_converge_toward_human-like_concept_organization.pdf\n",
      "Downloaded: data/papers_pdfs/Universal_Preprocessing_Operators_for_Embedding_Knowledge_Graphs_with_Literals.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embeddings_for_Multi-Lingual_Structured_Representations_of_Radiology_Reports.pdf\n",
      "Downloaded: data/papers_pdfs/Clinical_Trial_Recommendations_Using_Semantics-Based_Inductive_Inference_and_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/KGEx:_Explaining_Knowledge_Graph_Embeddings_via_Subgraph_Sampling_and_Knowledge_Distillation.pdf\n",
      "Downloaded: data/papers_pdfs/Accurate_prediction_of_international_trade_flows:_Leveraging_knowledge_graphs_and_their_embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Universal_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/A_Study_on_Knowledge_Graph_Embeddings_and_Graph_Neural_Networks_for_Web_Of_Things.pdf\n",
      "Downloaded: data/papers_pdfs/Faithful_Path_Language_Modeling_for_Explainable_Recommendation_over_Knowledge_Graph.pdf\n",
      "Downloaded: data/papers_pdfs/Linked_Papers_With_Code:_The_Latest_in_Machine_Learning_as_an_RDF_Knowledge_Graph.pdf\n",
      "Downloaded: data/papers_pdfs/EXTRACT:_Explainable_Transparent_Control_of_Bias_in_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Vehicle_Lane_Change_Prediction_based_on_Knowledge_Graph_Embeddings_and_Bayesian_Inference.pdf\n",
      "Downloaded: data/papers_pdfs/RDF-star2Vec:_RDF-star_Graph_Embeddings_for_Data_Mining.pdf\n",
      "Downloaded: data/papers_pdfs/BEV-TSR:_Text-Scene_Retrieval_in_BEV_Space_for_Autonomous_Driving.pdf\n",
      "Downloaded: data/papers_pdfs/Block-Diagonal_Orthogonal_Relation_and_Matrix_Entity_for_Knowledge_Graph_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/How_to_Turn_Your_Knowledge_Graph_Embeddings_into_Generative_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Efficient_Methods_in_Medical_Question_Answering_using_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Capturing_Knowledge_Graphs_and_Rules_with_Octagon_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Pre-training_and_Diagnosing_Knowledge_Base_Completion_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Embedding_Knowledge_Graphs_in_Degenerate_Clifford_Algebras.pdf\n",
      "Downloaded: data/papers_pdfs/Empowering_machine_learning_models_with_contextual_knowledge_for_enhancing_the_detection_of_eating_disorders_in_social_media_posts.pdf\n",
      "Downloaded: data/papers_pdfs/Improving_Molecule_Generation_and_Drug_Discovery_with_a_Knowledge-enhanced_Generative_Model.pdf\n",
      "Downloaded: data/papers_pdfs/Federated_Neural_Graph_Databases.pdf\n",
      "Downloaded: data/papers_pdfs/BloomGML:_Graph_Machine_Learning_through_the_Lens_of_Bilevel_Optimization.pdf\n",
      "Downloaded: data/papers_pdfs/Counterfactual_Reasoning_with_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/KnowLA:_Enhancing_Parameter-efficient_Finetuning_with_Knowledgeable_Adaptation.pdf\n",
      "Downloaded: data/papers_pdfs/Sharing_Parameter_by_Conjugation_for_Knowledge_Graph_Embeddings_in_Complex_Space.pdf\n",
      "Downloaded: data/papers_pdfs/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.pdf\n",
      "Downloaded: data/papers_pdfs/Towards_Knowledge-Infused_Automated_Disease_Diagnosis_Assistant.pdf\n",
      "Downloaded: data/papers_pdfs/Untargeted_Adversarial_Attack_on_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/From_Latent_to_Lucid:_Transforming_Knowledge_Graph_Embeddings_into_Interpretable_Structures_with_KGEPrisma.pdf\n",
      "Downloaded: data/papers_pdfs/Approximating_Probabilistic_Inference_in_Statistical_EL_with_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Base_Embeddings:_Semantics_and_Theoretical_Properties.pdf\n",
      "Downloaded: data/papers_pdfs/OWL2Vec4OA:_Tailoring_Knowledge_Graph_Embeddings_for_Ontology_Alignment.pdf\n",
      "Downloaded: data/papers_pdfs/Conformalized_Answer_Set_Prediction_for_Knowledge_Graph_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/Predictive_Multiplicity_of_Knowledge_Graph_Embeddings_in_Link_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Evaluating_the_Predictive_Features_of_Person-Centric_Knowledge_Graph_Embeddings:_Unfolding_Ablation_Studies.pdf\n",
      "Downloaded: data/papers_pdfs/TransBox:_EL++-closed_Ontology_Embedding.pdf\n",
      "Downloaded: data/papers_pdfs/Information_for_Conversation_Generation:_Proposals_Utilising_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/Visual_Representation_Learning_Guided_By_Multi-modal_Prior_Knowledge.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge_Graph_Embeddings:_A_Comprehensive_Survey_on_Capturing_Relation_Properties.pdf\n",
      "Downloaded: data/papers_pdfs/Resilience_in_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Multidimensional_Knowledge_Graph_Embeddings_for_International_Trade_Flow_Analysis.pdf\n",
      "Downloaded: data/papers_pdfs/Detecting_text_level_intellectual_influence_with_knowledge_graph_embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Capturing_and_Anticipating_User_Intents_in_Data_Analytics_via_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/MEG:_Medical_Knowledge-Augmented_Large_Language_Models_for_Question_Answering.pdf\n",
      "Downloaded: data/papers_pdfs/Addressing_Hallucinations_in_Language_Models_with_Knowledge_Graph_Embeddings_as_an_Additional_Modality.pdf\n",
      "Downloaded: data/papers_pdfs/Knowledge-enhanced_Transformer_for_Multivariate_Long_Sequence_Time-series_Forecasting.pdf\n",
      "Failed to download KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning: 404 Client Error: Not Found for url: http://arxiv.org/pdf/2411.12950v2\n",
      "Failed to download Predicting missing annotations in Gene Ontology with Knowledge Graph Embeddings and True Path Rule: 403 Client Error: Forbidden for url: https://cris.maastrichtuniversity.nl/ws/portalfiles/portal/160626358/Brewster-2023-Predicting-missing-annotations-in-Gene.pdf\n",
      "Downloaded: data/papers_pdfs/Visualization_of_Knowledge_Graphs_with_Embeddings:_an_Essay_on_Recent_Trends_and_Methods.pdf\n",
      "Downloaded: data/papers_pdfs/A_Survey_on_Knowledge_Graph_Structure_and_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/Extending_TWIG:_Zero-Shot_Predictive_Hyperparameter_Selection_for_KGEs_based_on_Graph_Structure.pdf\n",
      "Downloaded: data/papers_pdfs/Efficient_support_ticket_resolution_using_Knowledge_Graphs.pdf\n",
      "Downloaded: data/papers_pdfs/A_Semantic_Partitioning_Method_for_Large-Scale_Training_of_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/KGIF:_Optimizing_Relation-Aware_Recommendations_with_Knowledge_Graph_Information_Fusion.pdf\n",
      "Downloaded: data/papers_pdfs/Explainable_Lane_Change_Prediction_for_Near-Crash_Scenarios_Using_Knowledge_Graph_Embeddings_and_Retrieval_Augmented_Generation.pdf\n",
      "Downloaded: data/papers_pdfs/PathE:_Leveraging_Entity-Agnostic_Paths_for_Parameter-Efficient_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/SparseTransX:_Efficient_Training_of_Translation-Based_Knowledge_Graph_Embeddings_Using_Sparse_Matrix_Operations.pdf\n",
      "Downloaded: data/papers_pdfs/Corporate_Fraud_Detection_in_Rich-yet-Noisy_Financial_Graph.pdf\n",
      "Downloaded: data/papers_pdfs/Comparison_of_Metadata_Representation_Models_for_Knowledge_Graph_Embeddings.pdf\n",
      "Downloaded: data/papers_pdfs/ConceptFormer:_Towards_Efficient_Use_of_Knowledge-Graph_Embeddings_in_Large_Language_Models.pdf\n",
      "Downloaded: data/papers_pdfs/A_Systematic_Evaluation_of_Knowledge_Graph_Embeddings_for_Gene-Disease_Association_Prediction.pdf\n",
      "Downloaded: data/papers_pdfs/Predicate-Conditional_Conformalized_Answer_Sets_for_Knowledge_Graph_Embeddings.pdf\n",
      "Saved data to data/papers_data.json\n"
     ]
    }
   ],
   "source": [
    "from utils.pwc_service import PapersWithCodeClient\n",
    "\n",
    "client = PapersWithCodeClient(task_slug=\"knowledge-graph-embeddings\", data_dir =\"../data\")\n",
    "\n",
    "# Step 1: Fetch and save metadata\n",
    "papers = client.fetch_papers_metadata(limit=None) # fetch metadata for the first N papers in PapersWithCode\n",
    "client.save_json(papers, \"papers_data.json\")\n",
    "\n",
    "# Step 2: Load metadata and download PDFs\n",
    "papers = client.load_json(\"papers_data.json\")\n",
    "updated_papers = client.download_all_pdfs(papers) # download PDFs and update metadata with local paths\n",
    "client.save_json(updated_papers, \"papers_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:03:29.089796: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-21 09:03:29.438336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-21 09:03:29.438372: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-21 09:03:29.440257: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-21 09:03:29.599054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-21 09:03:30.604034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils.tei_extraction import extract_sections_fulltext, extract_abstract, tei_to_full_raw_text, extract_flat_sections_with_subtext, rank_sections_by_semantic_similarity\n",
    "from utils.grobid_service import GrobidService\n",
    "\n",
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "import ast\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "from bs4 import BeautifulSoup\n",
    "import Levenshtein\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the JSON file with paper metadata from paperswithcode\n",
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "# remove if Local PDF Path is None\n",
    "papers_list = [paper for paper in papers_list if paper.get(\"Local PDF Path\") is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "sim_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, tokenizer, max_tokens=8000, overlap=200):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    chunks = []\n",
    "    \n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + max_tokens, len(tokens))\n",
    "        chunk = tokenizer.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += max_tokens - overlap  # Overlapping context\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deduplicate_fuzzy(list, threshold=80):\n",
    "    unique = []\n",
    "    for name in list:\n",
    "        if all(fuzz.ratio(name, existing) < threshold for existing in unique):\n",
    "            unique.append(name)\n",
    "    return unique\n",
    "\n",
    "# def remove_fuzzy(names, threshold=80):\n",
    "#     # remove = ['Knolwedge Graph', 'Knowledge Graph Embeddings']\n",
    "#     remove = []\n",
    "#     unique = []\n",
    "#     for name in names:\n",
    "#         if all(fuzz.ratio(name, existing) < threshold for existing in remove):\n",
    "#             unique.append(name)\n",
    "#     return unique\n",
    "\n",
    "def compute_max_similarity(reference, prediction, model):\n",
    "    # Compute embeddings\n",
    "    ref_emb = model.encode(reference, convert_to_tensor=True)\n",
    "    pred_emb = model.encode(prediction, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarities: shape (len(ref), len(pred))\n",
    "    cos_sim = util.pytorch_cos_sim(ref_emb, pred_emb)\n",
    "\n",
    "    # For each reference entity, find the max similarity to predicted entities\n",
    "    max_similarities = cos_sim.max(dim=1).values\n",
    "\n",
    "    return max_similarities\n",
    "\n",
    "def closest_string_index(target, candidates):\n",
    "    distances = [Levenshtein.distance(target, cand) for cand in candidates]\n",
    "    return distances.index(min(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the unique task list that appears in the papers\n",
    "tasks_dataset = []\n",
    "for i,paper in enumerate(papers_list):\n",
    "    tasks_dataset.append(paper['Tasks'])\n",
    "\n",
    "for i in range(len(tasks_dataset)):\n",
    "    tasks_dataset[i] = deduplicate_fuzzy(tasks_dataset[i], threshold=80)\n",
    "    tasks_dataset[i] = [sublist for sublist in tasks_dataset[i] if sublist]\n",
    "\n",
    "# add everything in a set \n",
    "unique_labels = sorted({item for group in tasks_dataset for item in group if item})\n",
    "unique_labels = deduplicate_fuzzy(unique_labels, threshold=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169,\n",
       " ['AI2 Reasoning Challenge',\n",
       "  'ARC',\n",
       "  'Active Learning',\n",
       "  'Adversarial Attack',\n",
       "  'Adversarial Robustness',\n",
       "  'Answer Selection',\n",
       "  'Articles',\n",
       "  'Attribute',\n",
       "  'AutoML',\n",
       "  'Autonomous Driving',\n",
       "  'BIG-bench Machine Learning',\n",
       "  'Bayesian Inference',\n",
       "  'Benchmarking',\n",
       "  'Bias Detection',\n",
       "  'Bilevel Optimization',\n",
       "  'Blocking',\n",
       "  'Bridging Anaphora Resolution',\n",
       "  'Caption Generation',\n",
       "  'Classification',\n",
       "  'Click-Through Rate Prediction',\n",
       "  'Collaborative Filtering',\n",
       "  'Common Sense Reasoning',\n",
       "  'Complex Query Answering',\n",
       "  'Computational Efficiency',\n",
       "  'Conformal Prediction',\n",
       "  'Continual Learning',\n",
       "  'Contrastive Learning',\n",
       "  'Counterfactual Reasoning',\n",
       "  'Data Augmentation',\n",
       "  'Data Integration',\n",
       "  'Data Poisoning',\n",
       "  'Data-to-Text Generation',\n",
       "  'Decision Making',\n",
       "  'Decoder',\n",
       "  'Deep Learning',\n",
       "  'Descriptive',\n",
       "  'Diagnostic',\n",
       "  'Dialogue Generation',\n",
       "  'Disease Prediction',\n",
       "  'Diversity',\n",
       "  'Document Classification',\n",
       "  'Drug Discovery',\n",
       "  'EDIT Task',\n",
       "  'Ensemble Learning',\n",
       "  'Entity Alignment',\n",
       "  'Entity Disambiguation',\n",
       "  'Entity Embeddings',\n",
       "  'Entity Linking',\n",
       "  'Entity Resolution',\n",
       "  'Entity Typing',\n",
       "  'Explainable Recommendation',\n",
       "  'Fact Checking',\n",
       "  'Fact Verification',\n",
       "  'Fairness',\n",
       "  'Federated Learning',\n",
       "  'Few-Shot Class-Incremental Learning',\n",
       "  'Few-Shot Learning',\n",
       "  'Fraud Detection',\n",
       "  'General Classification',\n",
       "  'General Knowledge',\n",
       "  'Graph Attention',\n",
       "  'Graph Embedding',\n",
       "  'Graph Learning',\n",
       "  'Graph Neural Network',\n",
       "  'Graph Question Answering',\n",
       "  'Graph Representation Learning',\n",
       "  'Hyperparameter Optimization',\n",
       "  'Image Captioning',\n",
       "  'Image Retrieval',\n",
       "  'Image-text matching',\n",
       "  'Incremental Learning',\n",
       "  'Inductive Bias',\n",
       "  'Inductive Link Prediction',\n",
       "  'Inductive knowledge graph completion',\n",
       "  'Information Retrieval',\n",
       "  'Interpretable Machine Learning',\n",
       "  'Knowledge Base Completion',\n",
       "  'Knowledge Base Question Answering',\n",
       "  'Knowledge Distillation',\n",
       "  'Knowledge Graph Embeddings',\n",
       "  'Knowledge Graphs',\n",
       "  'Knowledge Probing',\n",
       "  'Language Modeling',\n",
       "  'Large Language Model',\n",
       "  'Learning Word Embeddings',\n",
       "  'Learning-To-Rank',\n",
       "  'Link Prediction',\n",
       "  'Link Property Prediction',\n",
       "  'Logical Reasoning',\n",
       "  'Machine Reading Comprehension',\n",
       "  'Machine Translation',\n",
       "  'Management',\n",
       "  'Marketing',\n",
       "  'Matrix Factorization / Decomposition',\n",
       "  'Medical Diagnosis',\n",
       "  'Memorization',\n",
       "  'Metric Learning',\n",
       "  'Misinformation',\n",
       "  'Motion Planning',\n",
       "  'Movie Recommendation',\n",
       "  'Multi-hop Question Answering',\n",
       "  'Multi-modal Entity Alignment',\n",
       "  'Multiple-choice',\n",
       "  'NER',\n",
       "  'Named Entity Recognition',\n",
       "  'Natural Language Inference',\n",
       "  'Natural Language Understanding',\n",
       "  'Navigate',\n",
       "  'Negation',\n",
       "  'Node Clustering',\n",
       "  'Object',\n",
       "  'Object Detection',\n",
       "  'Object Recognition',\n",
       "  'Ontology Embedding',\n",
       "  'Ontology Matching',\n",
       "  'Open Information Extraction',\n",
       "  'Open World Object Detection',\n",
       "  'Opinion Mining',\n",
       "  'Person-Centric Knowledge Graphs',\n",
       "  'Product Recommendation',\n",
       "  'Protein Function Prediction',\n",
       "  'QNLI',\n",
       "  'QQP',\n",
       "  'Quantization',\n",
       "  'RAG',\n",
       "  'Readmission Prediction',\n",
       "  'Recommendation Systems',\n",
       "  'Reinforcement Learning',\n",
       "  'Relation',\n",
       "  'Relation Classification',\n",
       "  'Relation Extraction',\n",
       "  'Relation Linking',\n",
       "  'Relational Reasoning',\n",
       "  'Response Generation',\n",
       "  'Retrieval',\n",
       "  'Retrieval-augmented Generation',\n",
       "  'Riemannian optimization',\n",
       "  'Scene Graph Generation',\n",
       "  'Scene Understanding',\n",
       "  'Self-Supervised Learning',\n",
       "  'Semantic Textual Similarity',\n",
       "  'Sensitivity Classification',\n",
       "  'Sentence',\n",
       "  'Sentiment Analysis',\n",
       "  'Survey',\n",
       "  'Tensor Decomposition',\n",
       "  'Text Generation',\n",
       "  'Text Matching',\n",
       "  'Text Retrieval',\n",
       "  'Time Series',\n",
       "  'Time Series Forecasting',\n",
       "  'Transfer Learning',\n",
       "  'Translation',\n",
       "  'Triplet',\n",
       "  'Type prediction',\n",
       "  'Uncertainty Quantification',\n",
       "  'Variational Inference',\n",
       "  'Visual Question Answering (VQA)',\n",
       "  'Vocal Bursts Type Prediction',\n",
       "  'Word Embeddings',\n",
       "  'World Knowledge',\n",
       "  'class-incremental learning',\n",
       "  'counterfactual',\n",
       "  'image-classification',\n",
       "  'knowledge editing',\n",
       "  'model',\n",
       "  'named-entity-recognition',\n",
       "  'text similarity',\n",
       "  'valid'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_labels), unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the name of datasets used in the paper?\"\n",
    "question2 = \"What are the tasks that the model is trained for?\"\n",
    "question3 = \"Who are the authors of the paper?\"\n",
    "questions = [question, question2, question3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_question = \"Is the model in this paper a Structural Information-based KGC Technology, Additional Information-based KGC Technology or Other KGC Technologies?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1bde6cf0144d2a83f9461660502c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd54b3e5bcb4dbd9b9f2640f8984d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# 1: Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "max_context_tokens = 8192 - 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "KG 2 : Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "31 May 2018\n",
      "Yuyu\n",
      "Zhang\n",
      "yuyu.zhang@cc.gatech.edu\n",
      "College of Computing\n",
      "Georgia Institute of Technology\n",
      "Hanjun\n",
      "Dai\n",
      "hanjun.dai@cc.gatech.edu\n",
      "College of Computing\n",
      "Georgia Institute of Technology\n",
      "Toraman\n",
      "Kamil\n",
      "Korea Advanced Institute of Science and Technology\n",
      "Le\n",
      "Song\n",
      "lsong@cc.gatech.edu\n",
      "College of Computing\n",
      "Georgia Institute of Technology\n",
      "KG 2 : Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "31 May 2018\n",
      "177559F076614A6214436678E9CC6581\n",
      "arXiv:1805.12393v1[cs.LG]\n",
      "GROBID - A machine learning software for extracting information from scholarly documents\n",
      "The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question answering (QA) has been recently released. ARC only contains natural science questions authored for human exams, which are hard to answer and require advanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art QA systems fail to significantly outperform random baseline, reflecting the difficult nature of this task. In this paper, we propose a novel framework for answering science exam questions, which mimics human solving process in an open-book exam. To address the reasoning challenge, we construct contextual knowledge graphs respectively for the question itself and supporting sentences. Our model learns to reason with neural embeddings of both knowledge graphs. Experiments on the ARC Challenge Set show that our model outperforms the previous state-of-the-art QA systems.\n",
      "Introduction\n",
      "Question answering (QA) has been a long-standing challenge in the field of artificial intelligence. Numerous research works have pushed forward techniques for building QA systems. Many existing approaches achieve high performance on benchmark datasets. However, most of the questions in those datasets only require surface-level reasoning, and do not reveal the full-scale complexity and challenge of the question answering problem. Recently, the AI2 Reasoning Challenge (ARC) has been proposed\n",
      "[Clark et al., 2018]\n",
      ", which is designed to pose a challenge to the QA community. On the ARC Challenge Set, several state-of-the-art QA systems, including leading neural models from the well-known SQuAD and SNLI tasks, only perform slightly better than the random baseline. This striking observation has demonstrated that QA is still far from being solved.\n",
      "Why it is so difficult to answer the questions in the ARC Challenge Set? 1) ARC consists of natural science questions, namely questions authored for human exams. All of these questions are drawn from real exams; 2) In order to encourage progress on hard questions, a Challenge Set has been partitioned from ARC. To be more specific, if a question could not be correctly answered by neither an information retrieval (IR) method nor a word co-occurrence method, it is sorted into the Challenge Set, otherwise the Easy Set. To illustrate the difference, consider the following two examples from both sets respectively, where the bold answers correspond to the correct choices:\n",
      "â¢ ARC Easy Set:\n",
      "Which property of air does a barometer measure? (A) speed (B) pressure (C) humidity (D) temperature This question is correctly answered by both the IR and word co-occurrence methods.\n",
      "1\n",
      "The IR method finds sentences relevant to the correct answer in the reference corpus, e.g., \"Air pressure will be measured with a barometer \". Due to the substantial word overlap, the question can be easily solved. Similarly, the word co-occurrence method finds that \"barometer\" and \"pressure\" co-occur frequently in the corpus, leading to the correct answer.\n",
      "â¢ ARC Challenge Set:\n",
      "Which property of a mineral can be determined just by looking at it? (A) luster (B) mass (C) weight (D) hardness Neither the IR method nor the word co-occurrence method can correctly answer this question. There are no sentences in the corpus similar to \"A material's luster can be determined by looking at it\". Also, \"mineral\" often co-occurs with distractor options (e.g., mass, hardness), which confuses the word co-occurrence method.\n",
      "From the examples above, we see that surface-level reasoning methods are not able to solve questions in the Challenge Set, even the required knowledge is already covered in the reference corpus. The ARC Corpus, a large science-related text corpus collected from the Web and released together with ARC, mentions knowledge relevant to about 95% of the ARC Challenge questions\n",
      "[Clark et al., 2018]\n",
      ". However, the IR method with the ARC Corpus, as listed in Table\n",
      "1\n",
      ", only achieves 20.26 test score, which underperforms the random baseline. Collecting more sentences into the corpus would not solve the challenge. Actually we tried to use the entire Web as the reference corpus with Google Search API, and select the answer option with the most number of hits. This only slightly improves the score to 21.58.\n",
      "To tackle the ARC Challenge, we believe that there is no shortcut to get around advanced logic reasoning and deeper text comprehension. These questions target at students of age 8 through 13 years old, and should be relatively easy for human to solve. For an adult with basic reasoning capability, even she forgets about the knowledge learned in grade school, she can still ace most of these questions in an open-book exam, by searching relevant supporting texts and reasoning over them.\n",
      "Inspired by the human problem solving process, we propose a neural reasoning engine named KG 2 for answering science exam questions: read the question, generate hypothesis by combining the question stem and answer option, find supporting sentences in the corpus, and verify the hypothesis. For effective and efficient reasoning, we represent both hypothesis and supporting sentences in knowledge graphs. For example, in the supporting graph, \"luster \" is linked to \"brightness\", and \"brightness\" connects to \"look \", which is consistent with the hypothesis graph. Therefore, such reasoning patterns on graphs can be learned by our differentiable neural engine. Experiments on the ARC Challenge Set show that our model achieves score that surpasses the previous state-of-the-art results.\n",
      "In summary, the contributions of this work are: 1) We propose a novel differential neural programming framework for reasoning about science exam questions; 2) Our method sets the new state of the art on the ARC Challenge Set; 3) We decompose the remaining difficulties towards solving the ARC Challenge, facilitating the community to engage with the dataset and progress on the challenging task.\n",
      "Related Work\n",
      "Science QA: For elementary science QA, simple IR-based methods have been proposed for science exams\n",
      "[Clark et al., 2016]\n",
      ". Markov Logic Networks\n",
      "[Richardson and Domingos, 2006]\n",
      "has been used to reason over a small set of logical rules\n",
      "[Khot et al., 2015]\n",
      ".\n",
      "Jansen et al. [2016]\n",
      "has analyzed knowledge and inference requirements for science exam questions.\n",
      "The work most related to us is DGEM\n",
      "[Khot et al., 2018]\n",
      ", a neural entailment model which also employs Open IE to generate hypothesis graph. Our key contributions over DGEM: 1) DGEM is designed for single sentence entailment, while we aggregate multiple supporting sentences for reasoning; 2) DGEM has no structured representation of supporting facts, while our model learns to reason over the paired hypothesis and supporting graphs together. Graph Embedding: We employ graph embedding techniques for reasoning over knowledge graphs. Graph embedding has provided the representational flexibility for neural models in many NLP tasks, such as dialog system\n",
      "[He et al., 2017]\n",
      ", question answering\n",
      "[Zhang et al., 2017]\n",
      ", link prediction\n",
      "[Bordes et al., 2013]\n",
      "and triple classification\n",
      "[Feng et al., 2016]\n",
      ". In our paper, we extend this technique to mimic the reasoning process on graph ranking problem.\n",
      "Task\n",
      "The ARC Challenge Set consists of science exam questions D = q i , c\n",
      "(1) i , . . . , c (m) i , a i n i=1\n",
      ", where q i is the question stem, c (j) i is the j-th answer option corresponding to q i (typically 4-way multiple choices), and a i is the label of correct answer. Both q i and c (j) i are in text format. Among the multiple choices, only one of them is the correct answer and others are distractors. With the question stem and options, the goal is to find the correct answer. Accompanied with ARC, the ARC Corpus is also provided, providing 14M science-related sentences from the Web with knowledge relevant to ARC. The use of the ARC Corpus is optional for the ARC Challenge.\n",
      "Approach\n",
      "Generating Hypothesis\n",
      "A hypothesis h is a statement that combines a question stem q and an answer option c, which helps us understand what is being asked and what is the target to be verified. For example, consider the question stem \"Which of these occurs due to the rotation of Earth? \" and one of the answer options \"day and night\". The hypothesis to be generated from them should be: \"Day and night occurs due to the rotation of Earth\".\n",
      "To automatically generate hypothesis, we first identify the wh-word (e.g., which, what, where, etc.) in the question stem, and replace it with the answer option. If there is no wh-word found, we just append the answer option behind the question stem. We create several rules to handle special cases and make hypothesis more natural. For example, \"Which of these\" and \"Which of the following\" should be replaced as a whole when they appear in the question stem. We successfully generate hypothesis for most questions, however, there are still a few corner cases requiring advanced rewording, which should be negligible.\n",
      "Searching Potential Supports\n",
      "To verify a hypothesis, we look for supports in the reference corpus. Although the corpus is typically gigantic, we only need to focus on a tiny part of it, which is relevant to the question we are solving. Therefore, we use the generated hypothesis as a query to search the entire corpus. The top retrieved sentences are treated as potential supports for the hypothesis. In order to efficiently search the corpus, we build a local search engine on top of ElasticSearch\n",
      "[Gormley and Tong, 2015]\n",
      ". Since the corpus sentences are not as clean as questions, we filter noisy sentences that contain negation words (e.g., not, except, etc.) or unexpected characters or simply too long, and then pick up the top 20 sentences for verifying the hypothesis.\n",
      "Constructing Knowledge Graphs\n",
      "Many questions in the ARC Challenge Set require advanced reasoning on multiple supporting sentences. To aggregate knowledge across sentences, we employ Open IE\n",
      "[Banko et al., 2007\n",
      ", Christensen et al., 2011\n",
      ", Pal et al., 2016\n",
      "] v4\n",
      "2\n",
      "to extract relation triples from each sentence, and collect them to construct a contextual knowledge graph.\n",
      "More specifically, each relation triple is represented as T (s, p, o i ), where s is the subject, p is the predicate, and o i is the i-th object. We construct the graph by adding nodes s, p and o i , and adding directed edges with labels subj and obj. If there is adverbial of time or location extracted by Open IE, we add an edge with label time or loc in the knowledge graph. Words in each graph node are lemmatized. Similarly, we construct another knowledge graph for the corresponding hypothesis, which is paired with the supporting knowledge graph. Refer to Appendix A for examples of our generated graphs.\n",
      "Learning with Graph Embeddings\n",
      "Given a question q and a candidate choice c, we construct the corresponding hypothesis graph G hypo q,c and supporting graph G supp q,c by aggregating the relation triples mentioned in Section 4.3. Thus, choosing the right answer for question q i becomes a graph ranking problem. A good graph scoring function f : G hypo ÃG supp â R should assign the highest score to the correct hypothesis-supporting graph pair. Without loss of generality, we use point-wise ranking objective, where f (â¢) becomes a binary classifier.\n",
      "To implement the graph scoring function, we adapt the recent advances in graph embedding\n",
      "[Dai et al., 2016\n",
      ", Gilmer et al., 2017]\n",
      "to our problem. Specifically, let G = (V, E) be a knowledge graph, and V p â V be the set of predicate nodes. We associate each node v â V with an embedding vector Âµ v that captures the local information, which is computed recursively using the equation:\n",
      "Âµ (t) v = h x v , Âµ (t-1) v , {(Âµ (t-1) u , e u,v )} (u,v,eu,v)âE (1)\n",
      "Here x v encodes the text feature of node generated by LSTM that is jointly trained with the supervision. The edge type e u,v can be time, loc, etc. We use a two-layer neural network for the function h(â¢). Eq. (\n",
      "1\n",
      ") iterates for T steps, and we use\n",
      "Âµ v = Âµ (T ) v\n",
      "as the node embedding representation. Finally, the scoring function f (â¢) is defined as:\n",
      "f (G hypo , G supp ) = f ({Âµ u } uâV hypo p , {Âµ v } vâV supp p ) = Ï max u,v Âµ u Âµv Âµu Âµv -0.5 ,\n",
      "(2)\n",
      "where Ï(â¢) is the sigmoid function, and the -0.5 shift is used to center the matching score at zero. Eq. (\n",
      "2\n",
      ") is making max inner product search between all pairs of predicate node embeddings. This mimics the procedure of reasoning on the most relevant hypothesis and corresponding supporting evidence, since each embedding vector already captures the information within its T -hop neighborhood.\n",
      "Experiments\n",
      "We compare our method against several recently published baseline models, including state-of-theart neural models from the well-known SQuAD and SNLI tasks.\n",
      "Setup\n",
      "We use the ARC Challenge Set\n",
      "[Clark et al., 2018]\n",
      "for all experiments. This dataset consists of 2,590 questions drawn from a variety of human exams. We use the original train / development / test split. The test set is held-out for model evaluation, which contains 1,172 questions. For each question, a QA system receives one point if it selects the correct answer, and 1/k points if it reports a k-way tie (i.e., chooses multiple answers) that includes the correct answer. The ARC Corpus can be optionally used for all models.\n",
      "Baselines\n",
      "Guess-all / Random: This naive baseline just selects all answer options, getting 1/k scores for each question with k answer options. Random selecting will also converge to this score after enough trials.\n",
      "IR-ARC: IR-based method sends question stem plus each option as a query to a search engine. For IR-ARC, the search engine is built on top of the ARC Corpus, and the search score is determined by the ElasticSearch score of the top retrieved sentence. The option with the highest search score is finally selected. IR-Google: This is similar to IR-ARC, but uses Google Search API\n",
      "3\n",
      "to retrieve documents from the entire Web, instead of just searching on the ARC Corpus. IR-Google uses the number of hits as the search score. TupleInference: This model\n",
      "[Khot et al., 2017]\n",
      "searches for graph that best connects the terms in the question with an answer choice via the knowledge extracted by Open IE. DecompAttn: It is a neural entailment model\n",
      "[Parikh et al., 2016]\n",
      "adapted to multiple-choice QA by assigning entailment score to the pair of hypothesis and single supporting sentence\n",
      "[Clark et al., 2018\n",
      "]. The answer option with the highest score is selected. DecompAttn is a top performer on SNLI\n",
      "[Bowman et al., 2015]\n",
      ". DGEM-OpenIE: DGEM\n",
      "[Khot et al., 2018]\n",
      "is also a neural model for sentence-level entailment, but uses Open IE to create structured representation of the hypothesis. On the SciTail task\n",
      "[Khot et al., 2018]\n",
      ", DGEM is a top performer. In\n",
      "Clark et al. [2018]\n",
      ", there is another version of DGEM, which uses a proprietary parser together with Open IE and achieves 27.11 test score. For fair comparison, we only list publicly available models in Table\n",
      "1\n",
      ".\n",
      "BiDAF: This model\n",
      "[Seo et al., 2016]\n",
      "is for span prediction QA, and has been adapted to multiplechoice QA\n",
      "[Clark et al., 2018]\n",
      ". BiDAF is a top performer on SQuAD\n",
      "[Rajpurkar et al., 2016]\n",
      ".\n",
      "Results and Analysis\n",
      "Table\n",
      "1\n",
      "summarizes the test scores of all baseline models and our method. It is striking to see that none of the baseline methods perform significantly better than the random baseline, where the 95% confidence interval is Â±2.5%. Our method KG 2 achieves 31.70, which substantially improves the previous state of the art by 17.5%. Nevertheless, we are still far from \"passing\" the exam. To dissect the difficulties, we randomly sample 100 questions for investigation and report the results in Figure\n",
      "1\n",
      ". More than half of the questions are lack of support: even human couldn't solve them by only referring to the supporting sentences. This may be caused by the limited coverage of the corpus, and the retrieval bias where sentences with low word overlap can partially explain concept which is indispensable for reasoning. External knowledge sources may help on these questions. 12% questions have lost key information in graph, due to the failure of Open IE. Sentence parsing may be helpful since it reserves more text. 21% questions require very complex reasoning, and only 15% questions are \"learnable\" given the current framework. This gives us an estimated upper bound when we correctly answer all the learnable questions, and just randomly guess the others, which should be 36.25. Improving the learning algorithm should bring our current result closer to this upper bound.\n",
      "Conclusion and Future Work\n",
      "We present a neural reasoning engine for answering science exam questions, which learns to reason over contextual knowledge graphs. Experimental results show that our method outperforms existing QA systems on the ARC Challenge Set. In the future, we will explore how to exploit external knowledge sources, and try to improve the quality of open IE by sentence parsing. Note that the knowledge graphs can be very complicated when the question stem has multiple sentences, or there is rich information in the supporting sentences extracted by Open IE. We show another example in Figure\n",
      "3\n",
      ", which has a heavier supporting graph than the previous example. This is actually common in the ARC Challenge Set. In this example, the hypothesis is \"day and night occurs due to rotation of earth\", as plotted in Figure\n",
      "3a\n",
      ". Looking at the supporting graph in Figure\n",
      "3b\n",
      ", we can find key information for this question, such as \"day and night occurs because earth rotates\", \"day and night causes earth rotation on its axis\", \"day and night is caused by earth's rotation\", etc. With the supporting knowledge graph, we should have necessary information to verify the hypothesis.\n",
      "Figure 1 :\n",
      "1\n",
      "Figure 1: Distribution of various difficulties in solving the ARC Challenge Set.\n",
      "Figure 2 :\n",
      "2\n",
      "Figure 2: Example of knowledge graphs for paired hypothesis and supports.\n",
      "Figure 3 :\n",
      "3\n",
      "Figure 3: Another example of knowledge graphs for paired hypothesis and supports.\n",
      "Table 1 :\n",
      "1\n",
      "Test performance of different QA systems on the ARC Challenge Set. The ARC Corpus is used in DecompAttn, DGEM, BiDAF and KG 2 . This method\n",
      "[Khashabi et al., 2016]\n",
      "performs table-based reasoning, which is formulated as an Integer Linear Program (ILP).\n",
      "Method\n",
      "Test Scores\n",
      "IR-ARC\n",
      "20.26\n",
      "IR-Google\n",
      "21.58\n",
      "TupleInference\n",
      "23.83\n",
      "DecompAttn\n",
      "24.34\n",
      "Guess-all / Random\n",
      "25.02\n",
      "DGEM-OpenIE\n",
      "26.41\n",
      "BiDAF\n",
      "26.54\n",
      "TableILP\n",
      "26.97\n",
      "KG 2\n",
      "31.70\n",
      "TableILP:\n",
      "Note that even it is correctly answered by only one of them, ARC would exclude it from the Challenge Set.\n",
      "https://github.com/allenai/openie-standalone\n",
      "https://developers.google.com/custom-search\n",
      "Appendix A Examples of Knowledge Graphs\n",
      "To illustrate how we construct knowledge graphs from hypothesis and supporting sentences, here we present some examples.\n",
      "We first show a relatively simple example in Figure\n",
      "2\n",
      ". We see a pair of hypothesis and supporting graphs. The hypothesis is \"seed of oak comes from fruit\", as shown in Figure\n",
      "2a\n",
      ". Note that the verb \"comes\" is lemmatized and becomes \"come\" in the graph. The supporting knowledge graph is plotted in Figure\n",
      "2b\n",
      ", where we obtain knowledge including \"fruit contains seed \", \"fruit is part of tree\", and \"oak is kind of tree\". With the supporting knowledge graph, we should be able to infer that the hypothesis is true.\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "responses_task = []\n",
    "responses_authors = []\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:1]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "    raw_text = tei_to_full_raw_text(tei,remove_ref=True)\n",
    "    print(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "responses_task = []\n",
    "responses_authors = []\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:30]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "\n",
    "    # abstract\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    for i, question in enumerate(questions):\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i == 2:\n",
    "            # only chunk 0 when i == 2\n",
    "            chunks_to_process = chunks[:1]\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "        # Loop over the chosen chunks\n",
    "        for j, chunk in enumerate(chunks_to_process):\n",
    "            # Build the chat history\n",
    "            chat = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response.\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "            ]\n",
    "\n",
    "            # Add the question prompt (with or without task labels)\n",
    "            if i != 1:\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}. Give back the answer only and only in a Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "            else:\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}, and those possible tasks: {unique_labels}. Give back the answer only and only in a Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "            # 2: Apply the chat template\n",
    "            formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "            #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "            # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "            inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n",
    "            # Move the tokenized inputs to the same device the model is on (GPU/CPU)\n",
    "            inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "            #print(\"Tokenized inputs:\\n\", inputs)\n",
    "\n",
    "            # 4: Generate text from the model\n",
    "            outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.6, top_p=0.9,)\n",
    "            #print(\"Generated tokens:\\n\", outputs)\n",
    "\n",
    "            # 5: Decode the output back to a string\n",
    "            decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):], skip_special_tokens=True)\n",
    "            print(\"Decoded output:\\n\", decoded_output)\n",
    "            # print decoded output datatype\n",
    "\n",
    "            response.append(decoded_output)\n",
    "\n",
    "        # Route responses into the right list\n",
    "        if i == 0:\n",
    "            responses_dataset.append(response)\n",
    "        elif i == 1:\n",
    "            responses_task.append(response)\n",
    "        else:\n",
    "            responses_authors.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [responses_authors, responses_dataset, responses_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"E_pred\": predictions\n",
    "}\n",
    "\n",
    "with open(\"../data/test_answers/qa_entities_with_options_grobid_llama3_experiment.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen/Qwen3-1.7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541d3968c59d4b15893622445971927b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "max_context_tokens = 32768 - 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "responses_task = []\n",
    "responses_authors = []\n",
    "\n",
    "\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:1]:\n",
    "    print(\"Processing paper:\", paper['Title'])\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "    print(\"Grobid processing took:\", time.time() - start, \"seconds\")\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"Processing question {i+1}: {question}\")\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i == 2:\n",
    "            # only chunk 0 when i == 2\n",
    "            chunks_to_process = chunks[:1]\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "        # Loop over the chosen chunks\n",
    "        for j, chunk in enumerate(chunks_to_process):\n",
    "            # Build the chat history\n",
    "            chat = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response.\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "            ]\n",
    "\n",
    "            # Add the question prompt (with or without task labels)\n",
    "            if i != 1:\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "            else:\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}, and those possible tasks: {unique_labels}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "            # 2: Apply the chat template\n",
    "            formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=False)\n",
    "            #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "            # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "            model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "            # 4: Generate text from the model\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=8192,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.8,\n",
    "                    top_k=20,\n",
    "                )\n",
    "            output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "            # parsing thinking content\n",
    "            try:\n",
    "                # rindex finding 151668 (</think>)\n",
    "                index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "            except ValueError:\n",
    "                index = 0\n",
    "\n",
    "            #thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "            content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "            print(\"content:\", content)\n",
    "            #print(\"thinking content:\", thinking_content)\n",
    "\n",
    "            response.append(content)\n",
    "            print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "            del model_inputs, generated_ids\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "\n",
    "        # Route responses into the right list\n",
    "        if i == 0:\n",
    "            responses_dataset.append(response)\n",
    "        elif i == 1:\n",
    "            responses_task.append(response)\n",
    "        else:\n",
    "            responses_authors.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problema con que se queda generando todos los tokens sin parar, no se detiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the name of unique datasets used in the paper?\"\n",
    "question2 = \"What are the unique tasks that the model is trained for?\"\n",
    "question3 = \"Who are the authors of the paper?\"\n",
    "questions = [question, question2, question3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asking only dataset\n",
    "import time\n",
    "\n",
    "# only doing the task part full text\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "acuumulated_time = 0\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list:\n",
    "\n",
    "    print(\"Processing paper:\", paper['Title'])\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    for i, question in enumerate(questions):\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i != 0:\n",
    "            continue  # skip all except i == 1\n",
    "\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "            # Loop over the chosen chunks\n",
    "            for j, chunk in enumerate(chunks_to_process):\n",
    "                # Build the chat history\n",
    "                chat = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response.\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "                ]\n",
    "\n",
    "\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "\n",
    "                # 2: Apply the chat template\n",
    "                formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=False)\n",
    "                #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "                # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "                model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "                print(\"Input tokens:\", model_inputs.input_ids.shape[-1])\n",
    "                print(\"GPU memory:\", torch.cuda.memory_allocated() / 1e6, \"MB\")\n",
    "\n",
    "\n",
    "                # 4: Generate text from the model\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=512,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.8,\n",
    "                    top_k=20,\n",
    "                )\n",
    "                output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "                # parsing thinking content\n",
    "                try:\n",
    "                    # rindex finding 151668 (</think>)\n",
    "                    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "                except ValueError:\n",
    "                    index = 0\n",
    "\n",
    "                # thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "                content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "                # print(\"thinking content:\", thinking_content)\n",
    "                print(\"content:\", content)\n",
    "\n",
    "\n",
    "                response.append(content)\n",
    "                print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "                acuumulated_time += (time.time() - start)\n",
    "            responses_dataset.append(response)\n",
    "            print(f\"Accumulated time: {acuumulated_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Processing paper: KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6906\n",
      "GPU memory: 4718.162432 MB\n",
      "content: ['AI2 Reasoning Challenge', 'ARC', 'Knowledge Graph Embeddings', 'Graph Question Answering', 'Graph Representation Learning', 'Graph Learning', 'Graph Neural Network', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Attention', 'Graph Embedding', 'Graph\n",
      "Generation took 154.14 seconds\n",
      "Accumulated time: 154.14 seconds\n",
      "Processing paper: Incorporating Literals into Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11024\n",
      "GPU memory: 4718.210048 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Knowledge Probing', 'Relation Extraction', 'Relation Linking', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Variational Inference', 'Sensitivity Classification', 'Uncertainty Quantification', 'Counterfactual', 'Class-incremental learning', 'Image-classification', 'Knowledge Editing', 'Model', 'Text Similarity', 'Valid']\n",
      "Generation took 18.44 seconds\n",
      "Accumulated time: 172.58 seconds\n",
      "Processing paper: Adversarial Contrastive Estimation\n",
      "Number of chunks: 1\n",
      "Input tokens: 13019\n",
      "GPU memory: 4718.260224 MB\n",
      "content: ['Learning Word Embeddings', 'Contrastive Learning', 'Knowledge Graph Embeddings', 'Image Captioning', 'Text Generation', 'Image Retrieval', 'Text Retrieval', 'Sentence', 'Text Matching', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Visual Question Answering (VQA)', 'Relation Extraction', 'Relation Classification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Question Answering', 'Graph Representation Learning', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', '\n",
      "Generation took 171.52 seconds\n",
      "Accumulated time: 344.10 seconds\n",
      "Processing paper: KBGAN: Adversarial Learning for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11020\n",
      "GPU memory: 4718.2592 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Adversarial Robustness', 'Counterfactual Reasoning', 'Contrastive Learning', 'Deep Learning', 'Text Generation', 'Image Captioning', 'Image Retrieval', 'Text Retrieval', 'Semantic Textual Similarity', 'Natural Language Understanding', 'Named Entity Recognition', 'Text Matching', 'Sentence', 'Text Similarity', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Relation', 'Link Prediction', 'Counterfactual', 'Model', 'Text Similarity', 'Sentence', 'Relation Extraction', '\n",
      "Generation took 179.63 seconds\n",
      "Accumulated time: 523.72 seconds\n",
      "Processing paper: Convolutional 2D Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12374\n",
      "GPU memory: 4718.264832 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Link Prediction', 'Convolutional 2D Knowledge Graph Embeddings']\n",
      "Generation took 7.11 seconds\n",
      "Accumulated time: 530.83 seconds\n",
      "Processing paper: Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 14770\n",
      "GPU memory: 4718.297088 MB\n",
      "content: ['Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Representation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', '\n",
      "Generation took 230.12 seconds\n",
      "Accumulated time: 760.95 seconds\n",
      "Processing paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7895\n",
      "GPU memory: 4718.222848 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Learning Word Embeddings', 'Learning-To-Rank', 'Link Prediction', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Natural Language Understanding', 'Natural Language Inference', 'Semantic Textual Similarity', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Text Retrieval', 'Visual Question Answering (VQA)', 'Word Embeddings', 'World Knowledge', 'Class-incremental learning', 'Counterfactual', 'Image-classification', 'Knowledge editing', 'Model', 'Named-entity-recognition', 'Text similarity', 'Valid']\n",
      "Generation took 17.37 seconds\n",
      "Accumulated time: 778.32 seconds\n",
      "Processing paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "Number of chunks: 1\n",
      "Input tokens: 7752\n",
      "GPU memory: 4718.151168 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Embeddings', 'Link Prediction', 'Relation Extraction', 'Entity Disambiguation', 'Entity Alignment', 'Entity Typing', 'Entity Resolution', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Representation Learning', 'Knowledge Probing', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Semantic Textual Similarity', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Text Similarity', 'Uncertainty Quantification', 'Variational Inference', 'Self-Supervised Learning', 'Sentence', 'Sentiment Analysis', 'Classification', 'Click-Through Rate Prediction', 'Collaborative Filtering', 'Common Sense Reasoning', 'Complex Query Answering', 'Computational Efficiency', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Augmentation', 'Data Integration', 'Data Poisoning', 'Data-to-Text Generation', 'Decision Making', 'Explainable Recommendation', 'Fact Checking', 'Fact Verification', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'Inductive Bias', 'Inductive Link Prediction', 'Inductive knowledge graph completion', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Machine Reading Comprehension', 'Machine Translation', 'Multi-modal Entity Alignment', 'Multi-hop Question Answering', 'Movie Recommendation', 'Natural Language Inference', 'Natural Language Understanding', 'Negation', 'Object Recognition', 'Object Detection', 'Ontology Embedding', 'Ontology Matching', 'Open Information Extraction', 'Open World Object Detection', 'Opinion Mining', 'Person-Centric Knowledge Graphs', 'Product Recommendation', 'Protein Function Prediction', 'QNLI', 'QQP', 'Sentence', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Variational Inference', 'Visual Question Answering (VQA)', 'Word Embeddings', 'World Knowledge', 'class-incremental learning', 'counterfactual', 'image-classification', 'knowledge editing', 'model', 'named-entity-recognition', 'text similarity', 'valid']\n",
      "Generation took 45.92 seconds\n",
      "Accumulated time: 824.24 seconds\n",
      "Processing paper: Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 12906\n",
      "GPU memory: 4718.234624 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Link Prediction', 'Learning To Rank', 'Relation Extraction', 'Relation Classification', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Similarity', 'Visual Question Answering (VQA)', 'Word Embeddings', 'World Knowledge']\n",
      "Generation took 11.28 seconds\n",
      "Accumulated time: 835.52 seconds\n",
      "Processing paper: DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning\n",
      "Number of chunks: 1\n",
      "Input tokens: 10387\n",
      "GPU memory: 4718.232064 MB\n",
      "content: ['Multi-hop Question Answering', 'Knowledge Graph Question Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction', 'Logical Reasoning', 'Relation Classification', 'Relation Extraction', 'Relation Linking', 'Relational Reasoning', 'Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Relation Reasoning', 'Counterfactual Reasoning', 'Counterfactual', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Text Similarity', 'Semantic Textual Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Reinforcement Learning', 'Deep Learning', 'Learning To Rank', 'Link Prediction', 'Link Property Prediction',\n",
      "Generation took 151.92 seconds\n",
      "Accumulated time: 987.44 seconds\n",
      "Processing paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 5415\n",
      "GPU memory: 4718.148096 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Interpretable Machine Learning']\n",
      "Generation took 5.14 seconds\n",
      "Accumulated time: 992.57 seconds\n",
      "Processing paper: Fast Linear Model for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7897\n",
      "GPU memory: 4718.132224 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Base Question Answering', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Text Retrieval', 'Text Matching', 'Text Generation', 'Sentence', 'Text Similarity', 'Word Embeddings', 'World Knowledge', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Explainable Recommendation', 'Fact Checking', 'Fact Verification', 'Fairness', 'Graph Representation Learning', 'Knowledge Distillation', 'Model', 'Named Entity Recognition', 'Text Similarity', 'Variational Inference', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Sensitivity Classification', 'Uncertainty Quantification', 'Variational Inference', 'Text Retrieval', 'Text Matching', 'Text Generation', 'Text Retrieval', 'Time Series', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Triplet', 'Type prediction', 'Uncertainty Quantification', 'Variational Inference', 'Text Retrieval', 'Text Matching', 'Text Generation', 'Sentence', 'Text Similarity', 'Word Embeddings', 'World Knowledge', 'class-incremental learning', 'counterfactual', 'image-classification', 'knowledge editing', 'model', 'named-entity-recognition', 'text similarity', 'valid']\n",
      "Generation took 24.55 seconds\n",
      "Accumulated time: 1017.12 seconds\n",
      "Processing paper: Complex and Holographic Embeddings of Knowledge Graphs: A Comparison\n",
      "Number of chunks: 1\n",
      "Input tokens: 5707\n",
      "GPU memory: 4718.118912 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Classification', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Disambiguation', 'Entity Typing', 'Entity Alignment', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Pro\n",
      "Generation took 161.80 seconds\n",
      "Accumulated time: 1178.92 seconds\n",
      "Processing paper: Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment\n",
      "Number of chunks: 1\n",
      "Input tokens: 12335\n",
      "GPU memory: 4718.221312 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Relation Extraction', 'Relation Linking', 'Relation Classification', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Text Similarity', 'Sentiment Analysis', 'Text Generation', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Text Matching', 'Visual Question Answering (VQA)', 'Sentence', 'Word Embeddings', 'World Knowledge', 'Class-incremental Learning', 'Counterfactual', 'Image-classification', 'Knowledge Editing', 'Model', 'Named-entity-recognition', 'Text similarity', 'Valid']\n",
      "Generation took 20.01 seconds\n",
      "Accumulated time: 1198.94 seconds\n",
      "Processing paper: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13751\n",
      "GPU memory: 4718.281728 MB\n",
      "content: ['Dialogue Generation', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Knowledge Representation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Tri\n",
      "Generation took 198.16 seconds\n",
      "Accumulated time: 1397.10 seconds\n",
      "Processing paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 9697\n",
      "GPU memory: 4718.243328 MB\n",
      "content: ['Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Editing', 'Knowledge Representation', 'Knowledge Extraction', 'Knowledge Fusion', 'Knowledge Traversal', 'Knowledge Navigation', 'Knowledge Mapping', 'Knowledge Integration', 'Knowledge Validation', 'Knowledge Verification', 'Knowledge Retrieval', 'Knowledge Search', 'Knowledge Mining', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', 'Knowledge Discovery', '\n",
      "Generation took 194.37 seconds\n",
      "Accumulated time: 1591.47 seconds\n",
      "Processing paper: Embedding Models for Episodic Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 11611\n",
      "GPU memory: 4718.241792 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Probing\n",
      "Generation took 238.21 seconds\n",
      "Accumulated time: 1829.68 seconds\n",
      "Processing paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "Number of chunks: 1\n",
      "Input tokens: 3198\n",
      "GPU memory: 4718.121984 MB\n",
      "content: ['Classification', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Relation Extraction', 'Relation Classification', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', 'Object Detection', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Sentence', 'Text Similarity', 'Triplet', 'Language Modeling', 'Large Language Model', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Open Information Extraction', 'Open World Object Detection', 'Object Recognition', '\n",
      "Generation took 127.24 seconds\n",
      "Accumulated time: 1956.92 seconds\n",
      "Processing paper: Hypernetwork Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10039\n",
      "GPU memory: 4718.163968 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Link Prediction', 'Counterfactual Reasoning', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Graph Representation Learning', 'Graph Learning', 'Graph Neural Network', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relational Reasoning', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural\n",
      "Generation took 168.98 seconds\n",
      "Accumulated time: 2125.90 seconds\n",
      "Processing paper: Multi-Hop Knowledge Graph Reasoning with Reward Shaping\n",
      "Number of chunks: 1\n",
      "Input tokens: 13931\n",
      "GPU memory: 4718.281216 MB\n",
      "content: ['Multi-Hop Knowledge Graph Reasoning with Reward Shaping', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Knowledge Graphs', 'Knowledge Representation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation', 'Knowledge Triangulation',\n",
      "Generation took 194.49 seconds\n",
      "Accumulated time: 2320.38 seconds\n",
      "Processing paper: MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via Network Infused Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10329\n",
      "GPU memory: 4718.255104 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', '\n",
      "Generation took 156.85 seconds\n",
      "Accumulated time: 2477.23 seconds\n",
      "Processing paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10455\n",
      "GPU memory: 4718.22848 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graphs', 'Knowledge Probing', 'Language Modeling', 'Deep Learning', 'Text Retrieval', 'Image Retrieval', 'Image Captioning', 'Image-text matching', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching', 'Sentiment Analysis', 'Time Series Forecasting', 'Transfer Learning', 'Counterfactual Reasoning', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Variational Inference', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Complex Query Answering', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Text Retrieval', 'Text Generation', 'Text Matching\n",
      "Generation took 157.28 seconds\n",
      "Accumulated time: 2634.51 seconds\n",
      "Processing paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "Number of chunks: 1\n",
      "Input tokens: 11763\n",
      "GPU memory: 4718.249984 MB\n",
      "content: ['Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification', 'Classification\n",
      "Generation took 229.45 seconds\n",
      "Accumulated time: 2863.96 seconds\n",
      "Processing paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 8713\n",
      "GPU memory: 4718.212096 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Logical Reasoning', 'Machine Translation', 'Machine Reading Comprehension', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Text Similarity', 'Sentence', 'Text Generation', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Variational Inference', 'Visual Question Answering (VQA)', 'Word Embeddings', 'World Knowledge']\n",
      "Generation took 23.49 seconds\n",
      "Accumulated time: 2887.46 seconds\n",
      "Processing paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "Number of chunks: 1\n",
      "Input tokens: 9802\n",
      "GPU memory: 4718.19008 MB\n",
      "content: ['Image Captioning', 'Entity Disambiguation', 'Entity Linking', 'Entity Resolution', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Named Entity Recognition', 'Text Retrieval', 'Text Similarity', 'Sentence', 'Classification', 'Relation Extraction', 'Relation Classification', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Sentiment Analysis', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Variational Inference', 'Visual Question Answering (VQA)', 'Word Embeddings', 'World Knowledge', 'Class-incremental Learning', 'Counterfactual', 'Image-classification', 'Knowledge Editing', 'Model', 'Named-entity-recognition', 'Text Similarity']\n",
      "Generation took 19.94 seconds\n",
      "Accumulated time: 2907.40 seconds\n",
      "Processing paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 9741\n",
      "GPU memory: 4718.19776 MB\n",
      "content: ['Classification', 'Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Knowledge Fusion', 'Knowledge Graph Learning', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Knowledge Distillation',\n",
      "Generation took 249.80 seconds\n",
      "Accumulated time: 3157.20 seconds\n",
      "Processing paper: Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short\n",
      "Number of chunks: 1\n",
      "Input tokens: 5812\n",
      "GPU memory: 4718.14912 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Probing', 'Knowledge Distillation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Entity Alignment', 'Entity Disambiguation', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Classification', 'Logical Reasoning', 'Machine Reading Comprehension', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Sentence', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Variational Inference', 'Text Similarity', 'Sentence', 'Uncertainty Quantification', 'Variational Inference', 'Sensitivity Classification', 'Counterfactual', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Visual Question Answering (VQA)', 'Text Retrieval', 'Time Series', 'Classification', 'Contrastive Learning', 'Self-Supervised Learning', 'Semantic Textual Similarity', 'Deep Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Fact Checking', 'Fact Verification', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'Class-incremental Learning', 'AutoML', 'Adversarial Robustness', 'Adversarial Attack', 'Bias Detection', 'Data Poisoning', 'Data Augmentation', 'Data Integration', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Collaborative Filtering', 'Recommendation Systems', 'Machine Translation', 'Natural Language Inference', 'Natural Language Understanding', 'Named Entity Recognition', 'Sentence', 'Text Retrieval', 'Time Series Forecasting', 'Transfer Learning', 'Variational Inference', 'Text Similarity', 'Sentence', 'Uncertainty Quantification', 'Variational Inference', 'Sensitivity Classification', 'Counterfactual', 'Image-classification', 'Knowledge Editing', 'Model', 'Valid']\n",
      "Generation took 47.17 seconds\n",
      "Accumulated time: 3204.37 seconds\n",
      "Processing paper: Entity Hierarchy Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 9978\n",
      "GPU memory: 4718.171136 MB\n",
      "content: ['Entity Linking', 'Entity Resolution', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Entity Embeddings', 'Knowledge Distillation', 'Knowledge Probing', 'Information Retrieval', 'Text Retrieval', 'Semantic Textual Similarity', 'Text Generation', 'Text Matching', 'Text Retrieval', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Translation', 'Text Similarity', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation', 'Natural Language Understanding', 'Natural Language Inference', 'Named Entity Recognition', 'Entity Recognition', 'Object Recognition', 'Object Detection', 'Image Captioning', 'Image Retrieval', 'Image-text matching', 'Text Retrieval', 'Sentiment Analysis', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Data Integration', 'Data Augmentation', 'Data Poisoning', 'Data-to-Text Generation', 'Click-Through Rate Prediction', 'Decision Making', 'Reinforcement Learning', 'Fairness', 'Federated Learning', 'Few-Shot Learning', 'General Classification', 'General Knowledge', 'Graph Neural Network', 'Graph Embedding', 'Graph Learning', 'Graph Question Answering', 'Graph Representation Learning', 'Hyperparameter Optimization', 'Matrix Factorization / Decomposition', 'Medical Diagnosis', 'Drug Discovery', 'Protein Function Prediction', 'NER', 'Natural Language Inference', 'Sentence', 'Time Series', 'Visual Question Answering (VQA)', 'Text Similarity', 'Variational Inference', 'Uncertainty Quantification', 'Sensitivity Classification', 'Metric Learning', 'Learning Word Embeddings', 'Learning-To-Rank', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Reasoning', 'Logical Reasoning', 'Machine Translation',\n",
      "Generation took 146.22 seconds\n",
      "Accumulated time: 3350.60 seconds\n",
      "Processing paper: Binarized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11479\n",
      "GPU memory: 4718.241792 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Knowledge Base Question Answering', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Knowledge Graphs', 'Tensor Decomposition', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Similarity', 'Sentence', 'Time Series Forecasting', 'Transfer Learning', 'Model', 'Tensor Decomposition', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Semantic Textual Similarity', 'Visual Question Answering (VQA)', 'Text Generation', 'Text Retrieval', 'Text Matching\n",
      "Generation took 213.70 seconds\n",
      "Accumulated time: 3564.30 seconds\n",
      "Processing paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 11206\n",
      "GPU memory: 4718.249984 MB\n",
      "content: ['Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Convolutional Networks', 'Long-tail Relation Extraction', 'Class-incremental Learning', 'Few-Shot Learning', 'Counterfactual Reasoning', 'Text Generation', 'Text Retrieval', 'Semantic Textual Similarity', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Linking', 'Relation Classification', 'Relation Extraction', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Text Retrieval', 'Sentence', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Neural Network', 'Graph Representation Learning', 'Graph Attention', 'Graph Embedding', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Knowledge Graphs', 'Entity Disambiguation', 'Entity Alignment', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Named Entity Recognition', 'Natural Language Inference', 'Natural Language Understanding', 'Machine Translation', 'Machine Reading Comprehension', 'Machine Learning', 'Deep Learning', 'Transfer Learning', 'Adversarial Robustness', 'Adversarial Attack', 'Fairness', 'Federated Learning', 'Counterfactual', 'Class-incremental Learning', 'Few-Shot Learning', 'Text Generation', 'Text Retrieval', 'Text Matching', '\n",
      "Generation took 161.66 seconds\n",
      "Accumulated time: 3725.95 seconds\n"
     ]
    }
   ],
   "source": [
    "# without the 10\n",
    "import time\n",
    "\n",
    "# only doing the task part full text\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_tasks = []\n",
    "acuumulated_time = 0\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[:30]:\n",
    "    \n",
    "    print(\"Processing paper:\", paper['Title'])\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    for i, question in enumerate(questions):\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i != 1:\n",
    "            continue  # skip all except i == 1\n",
    "\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "            # Loop over the chosen chunks\n",
    "            for j, chunk in enumerate(chunks_to_process):\n",
    "                # Build the chat history\n",
    "                chat = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response. \"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "                ]\n",
    "\n",
    "\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}, and those possible tasks: {unique_labels}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "\n",
    "                # 2: Apply the chat template\n",
    "                formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=False)\n",
    "                #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "                # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "                model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "                print(\"Input tokens:\", model_inputs.input_ids.shape[-1])\n",
    "                print(\"GPU memory:\", torch.cuda.memory_allocated() / 1e6, \"MB\")\n",
    "\n",
    "\n",
    "                # 4: Generate text from the model\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=2048,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.8,\n",
    "                    top_k=20,\n",
    "                )\n",
    "                output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "                # parsing thinking content\n",
    "                try:\n",
    "                    # rindex finding 151668 (</think>)\n",
    "                    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "                except ValueError:\n",
    "                    index = 0\n",
    "\n",
    "                # thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "                content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "                # print(\"thinking content:\", thinking_content)\n",
    "                print(\"content:\", content)\n",
    "\n",
    "\n",
    "                response.append(content)\n",
    "                print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "                acuumulated_time += (time.time() - start)\n",
    "            responses_tasks.append(response)\n",
    "            print(f\"Accumulated time: {acuumulated_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Processing paper: KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6914\n",
      "GPU memory: 12466.5216 MB\n",
      "content: ['AI2 Reasoning Challenge', 'ARC', 'Graph Knowledge Embeddings', 'Knowledge Graphs', 'Learning To Rank', 'Multi-hop Question Answering', 'Text Retrieval', 'Text Similarity', 'Variational Inference', 'Self-Supervised Learning']\n",
      "Generation took 26.40 seconds\n",
      "Accumulated time: 26.40 seconds\n",
      "Processing paper: Incorporating Literals into Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11032\n",
      "GPU memory: 12466.537984 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Entity Embeddings', 'Entity Resolution', 'Entity Linking', 'Entity Disambiguation', 'Entity Typing', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing']\n",
      "Generation took 35.10 seconds\n",
      "Accumulated time: 61.50 seconds\n",
      "Processing paper: Adversarial Contrastive Estimation\n",
      "Number of chunks: 1\n",
      "Input tokens: 13027\n",
      "GPU memory: 12466.603008 MB\n",
      "content: ['Learning Word Embeddings', 'Contrastive Learning', 'Knowledge Graph Embeddings', 'Image Captioning', 'Text Generation', 'Sentence', 'Text Retrieval', 'Image Retrieval', 'Visual Question Answering (VQA)', 'Text Matching']\n",
      "Generation took 38.59 seconds\n",
      "Accumulated time: 100.09 seconds\n",
      "Processing paper: KBGAN: Adversarial Learning for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11028\n",
      "GPU memory: 12466.587136 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Embeddings', 'Link Prediction', 'Adversarial Robustness', 'Contrastive Learning', 'Deep Learning', 'Classification', 'Text Generation', 'Image Retrieval', 'Text Retrieval']\n",
      "Generation took 32.22 seconds\n",
      "Accumulated time: 132.31 seconds\n",
      "Processing paper: Convolutional 2D Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12382\n",
      "GPU memory: 12466.592768 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Link Prediction', 'Classification', 'Contrastive Learning', 'Deep Learning', 'Text Generation', 'Sentiment Analysis', 'Image Captioning', 'Image Retrieval', 'Text Retrieval']\n",
      "Generation took 38.79 seconds\n",
      "Accumulated time: 171.11 seconds\n",
      "Processing paper: Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 14778\n",
      "GPU memory: 12466.641408 MB\n",
      "content: ['Knowledge Base Question Answering', 'Image Retrieval', 'Knowledge Graph Embeddings', 'Relation Extraction', 'Relation Classification', 'Text Retrieval', 'Image Captioning', 'Text Generation', 'Knowledge Base Completion', 'Semantic Textual Similarity']\n",
      "Generation took 49.58 seconds\n",
      "Accumulated time: 220.69 seconds\n",
      "Processing paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7903\n",
      "GPU memory: 12466.550784 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Embeddings', 'Link Prediction', 'Entity Resolution', 'Entity Alignment', 'Entity Disambiguation', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning']\n",
      "Generation took 19.32 seconds\n",
      "Accumulated time: 240.01 seconds\n",
      "Processing paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "Number of chunks: 1\n",
      "Input tokens: 7760\n",
      "GPU memory: 12466.493952 MB\n",
      "content: ['Knowledge Base Completion', 'Graph Embedding', 'Relation Extraction', 'Link Prediction', 'Entity Disambiguation', 'Entity Typing', 'Entity Resolution', 'Relation Classification', 'Common Sense Reasoning', 'Counterfactual Reasoning']\n",
      "Generation took 24.86 seconds\n",
      "Accumulated time: 264.86 seconds\n",
      "Processing paper: Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 12914\n",
      "GPU memory: 12466.574848 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Graph Question Answering', 'Link Prediction', 'Counterfactual Reasoning', 'Contrastive Learning', 'Deep Learning', 'Text Generation', 'Natural Language Understanding', 'Semantic Textual Similarity', 'Text Retrieval']\n",
      "Generation took 45.12 seconds\n",
      "Accumulated time: 309.99 seconds\n",
      "Processing paper: DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning\n",
      "Number of chunks: 1\n",
      "Input tokens: 10395\n",
      "GPU memory: 12466.575872 MB\n",
      "content: ['Multi-hop Question Answering', 'Knowledge Base Question Answering', 'Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Logical Reasoning', 'Counterfactual Reasoning', 'Deep Learning', 'Reinforcement Learning']\n",
      "Generation took 33.21 seconds\n",
      "Accumulated time: 343.20 seconds\n",
      "Processing paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 5423\n",
      "GPU memory: 12466.476032 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Interpretable Machine Learning', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Common Sense Reasoning', 'Text Retrieval', 'Semantic Textual Similarity', 'Knowledge Distillation']\n",
      "Generation took 6.97 seconds\n",
      "Accumulated time: 350.17 seconds\n",
      "Processing paper: Fast Linear Model for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7905\n",
      "GPU memory: 12466.476032 MB\n",
      "content: ['Knowledge Base Completion', 'Knowledge Base Question Answering', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Text Retrieval', 'Text Matching', 'Text Generation', 'Text Similarity', 'Classification']\n",
      "Generation took 18.28 seconds\n",
      "Accumulated time: 368.45 seconds\n",
      "Processing paper: Complex and Holographic Embeddings of Knowledge Graphs: A Comparison\n",
      "Number of chunks: 1\n",
      "Input tokens: 5715\n",
      "GPU memory: 12466.461184 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Link Prediction', 'Entity Resolution', 'Relation Extraction', 'Entity Embeddings', 'Complex Query Answering', 'Classification', 'Machine Translation', 'Knowledge Distillation']\n",
      "Generation took 10.55 seconds\n",
      "Accumulated time: 379.00 seconds\n",
      "Processing paper: Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment\n",
      "Number of chunks: 1\n",
      "Input tokens: 12343\n",
      "GPU memory: 12466.549248 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Relation Extraction', 'Relation Linking', 'Logical Reasoning']\n",
      "Generation took 42.80 seconds\n",
      "Accumulated time: 421.80 seconds\n",
      "Processing paper: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13759\n",
      "GPU memory: 4718.280704 MB\n",
      "content: ['Dialogue Generation', 'Common Sense Reasoning', 'Classification', 'Fact Checking', 'Fact Verification', 'Entity Alignment', 'Entity Disambiguation', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution']\n",
      "Generation took 11.45 seconds\n",
      "Accumulated time: 433.24 seconds\n",
      "Processing paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 9705\n",
      "GPU memory: 4718.227456 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Graphs', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Knowledge Distillation', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Relation Linking', 'Logical Reasoning']\n",
      "Generation took 8.32 seconds\n",
      "Accumulated time: 441.56 seconds\n",
      "Processing paper: Embedding Models for Episodic Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 11619\n",
      "GPU memory: 4718.22592 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Graph Embedding', 'Graph Learning', 'Graph Neural Network', 'Text Generation', 'Text Retrieval', 'Text Matching', 'Tensor Decomposition']\n",
      "Generation took 13.13 seconds\n",
      "Accumulated time: 454.69 seconds\n",
      "Processing paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "Number of chunks: 1\n",
      "Input tokens: 3206\n",
      "GPU memory: 4718.107136 MB\n",
      "content: ['Classification', 'Entity Linking', 'Entity Resolution', 'Relation Extraction', 'Knowledge Graph Embeddings', 'Text Generation', 'Sentence', 'Text Retrieval', 'Text Matching', 'Text Similarity']\n",
      "Generation took 4.24 seconds\n",
      "Accumulated time: 458.93 seconds\n",
      "Processing paper: Hypernetwork Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10047\n",
      "GPU memory: 4718.148096 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Link Prediction', 'Hyperparameter Optimization', 'Contrastive Learning', 'Class-Incremental Learning', 'Model', 'Text Generation', 'Sentence', 'Text Matching', 'Text Retrieval']\n",
      "Generation took 8.15 seconds\n",
      "Accumulated time: 467.08 seconds\n",
      "Processing paper: Multi-Hop Knowledge Graph Reasoning with Reward Shaping\n",
      "Number of chunks: 1\n",
      "Input tokens: 13939\n",
      "GPU memory: 4718.265344 MB\n",
      "content: ['Multi-Hop Knowledge Graph Reasoning with Reward Shaping', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Reinforcement Learning', 'Deep Learning', 'Knowledge Base Completion', 'Knowledge Probing', 'Relation Extraction', 'Relation Classification', 'Text Generation']\n",
      "Generation took 11.15 seconds\n",
      "Accumulated time: 478.23 seconds\n",
      "Processing paper: MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via Network Infused Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10337\n",
      "GPU memory: 4718.239232 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Link Prediction', 'Counterfactual Reasoning', 'Contrastive Learning', 'Deep Learning', 'Text Generation', 'Text Retrieval', 'Image Captioning', 'Image Retrieval']\n",
      "Generation took 8.34 seconds\n",
      "Accumulated time: 486.57 seconds\n",
      "Processing paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10463\n",
      "GPU memory: 4718.212608 MB\n",
      "content: ['Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Link Prediction', 'Classification', 'Contrastive Learning', 'Deep Learning', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Text Generation']\n",
      "Generation took 7.78 seconds\n",
      "Accumulated time: 494.35 seconds\n",
      "Processing paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "Number of chunks: 1\n",
      "Input tokens: 11771\n",
      "GPU memory: 4718.234112 MB\n",
      "content: ['Classification', 'Classification', 'Contrastive Learning', 'Counterfactual Reasoning', 'Deep Learning', 'Explainable Recommendation', 'Image Captioning', 'Image Retrieval', 'Knowledge Base Question Answering', 'Learning Word Embeddings']\n",
      "Generation took 13.47 seconds\n",
      "Accumulated time: 507.83 seconds\n",
      "Processing paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 8721\n",
      "GPU memory: 4718.196224 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Link Prediction', 'Classification', 'Contrastive Learning', 'Deep Learning', 'Text Generation', 'Text Retrieval', 'Image Captioning']\n",
      "Generation took 11.44 seconds\n",
      "Accumulated time: 519.26 seconds\n",
      "Processing paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "Number of chunks: 1\n",
      "Input tokens: 9810\n",
      "GPU memory: 4718.189568 MB\n",
      "content: ['Image Captioning', 'Entity Disambiguation', 'Entity Linking', 'Entity Resolution', 'Knowledge Graph Embeddings', 'Text Generation', 'Named Entity Recognition', 'Classification', 'Sentiment Analysis', 'Text Retrieval']\n",
      "Generation took 8.41 seconds\n",
      "Accumulated time: 527.67 seconds\n",
      "Processing paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 9749\n",
      "GPU memory: 4718.197248 MB\n",
      "content: ['Classification', 'Knowledge Graph Embeddings', 'Entity Recognition', 'Text Generation', 'Sentiment Analysis', 'Text Retrieval', 'Text Matching', 'Image Retrieval', 'Text Similarity', 'Model Training']\n",
      "Generation took 8.22 seconds\n",
      "Accumulated time: 535.89 seconds\n",
      "Processing paper: Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short\n",
      "Number of chunks: 1\n",
      "Input tokens: 5820\n",
      "GPU memory: 4718.133248 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Question Answering', 'Knowledge Base Completion', 'Entity Embeddings', 'Entity Linking', 'Entity Resolution', 'Entity Typing', 'Relation Extraction', 'Relation Classification', 'Logical Reasoning']\n",
      "Generation took 9.79 seconds\n",
      "Accumulated time: 545.69 seconds\n",
      "Processing paper: Entity Hierarchy Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 9986\n",
      "GPU memory: 4718.169088 MB\n",
      "content: ['Entity Linking', 'Entity Resolution', 'Entity Typing', 'Entity Embeddings', 'Knowledge Base Question Answering', 'Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Machine Translation', 'Natural Language Understanding', 'Text Retrieval']\n",
      "Generation took 8.26 seconds\n",
      "Accumulated time: 553.94 seconds\n",
      "Processing paper: Binarized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11487\n",
      "GPU memory: 4718.22592 MB\n",
      "content: ['Knowledge Graph Embeddings', 'Knowledge Base Completion', 'Tensor Decomposition', 'Model Compression', 'Binary Connect', 'Learning To Rank', 'Deep Learning', 'Contrastive Learning', 'Self-Supervised Learning', 'Model Optimization']\n",
      "Generation took 12.47 seconds\n",
      "Accumulated time: 566.41 seconds\n",
      "Processing paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 11214\n",
      "GPU memory: 4718.234112 MB\n",
      "content: ['Relation Extraction', 'Relation Classification', 'Knowledge Graph Embeddings', 'Graph Convolutional Networks', 'Long-Tail Relation Extraction', 'Class-incremental Learning', 'Adversarial Robustness', 'Counterfactual Reasoning', 'Text Retrieval', 'Semantic Textual Similarity']\n",
      "Generation took 9.13 seconds\n",
      "Accumulated time: 575.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# task but only 10 answer max\n",
    "import time\n",
    "\n",
    "# only doing the task part full text\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_tasks = []\n",
    "acuumulated_time = 0\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[:30]:\n",
    "    print(\"Processing paper:\", paper['Title'])\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    for i, question in enumerate(questions):\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i != 1:\n",
    "            continue  # skip all except i == 1\n",
    "\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "            # Loop over the chosen chunks\n",
    "            for j, chunk in enumerate(chunks_to_process):\n",
    "                # Build the chat history\n",
    "                # chat = [\n",
    "                #     {\n",
    "                #         \"role\": \"system\",\n",
    "                #         \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response. \"\n",
    "                #     },\n",
    "                #     {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "                # ]\n",
    "                chat = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response. \"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "                ]\n",
    "\n",
    "\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}, and those possible tasks: {unique_labels}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list. Return 10 taks max.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "\n",
    "                # 2: Apply the chat template\n",
    "                formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=False)\n",
    "                #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "                # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "                model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "                print(\"Input tokens:\", model_inputs.input_ids.shape[-1])\n",
    "                print(\"GPU memory:\", torch.cuda.memory_allocated() / 1e6, \"MB\")\n",
    "\n",
    "\n",
    "                # 4: Generate text from the model\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=2048,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.8,\n",
    "                    top_k=20,\n",
    "                )\n",
    "                output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "                # parsing thinking content\n",
    "                try:\n",
    "                    # rindex finding 151668 (</think>)\n",
    "                    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "                except ValueError:\n",
    "                    index = 0\n",
    "\n",
    "                # thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "                content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "                # print(\"thinking content:\", thinking_content)\n",
    "                print(\"content:\", content)\n",
    "\n",
    "\n",
    "                response.append(content)\n",
    "                print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "                acuumulated_time += (time.time() - start)\n",
    "            responses_tasks.append(response)\n",
    "            print(f\"Accumulated time: {acuumulated_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the name of unique datasets used in the paper?',\n",
       " 'What are the unique tasks that the model is trained for?',\n",
       " 'Who are the authors of the paper?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Paper index: 0\n",
      "Processing paper: KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6061\n",
      "GPU memory: 8030.641152 MB\n",
      "content: ['ARC Challenge Set']\n",
      "Generation took 2.15 seconds\n",
      "Accumulated time: 2.15 seconds\n",
      "Paper index: 1\n",
      "Processing paper: Incorporating Literals into Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10179\n",
      "GPU memory: 8030.65856 MB\n",
      "content: ['FB15k', 'FB15k-237', 'YAGO3-10']\n",
      "Generation took 3.23 seconds\n",
      "Accumulated time: 5.37 seconds\n",
      "Paper index: 2\n",
      "Processing paper: Adversarial Contrastive Estimation\n",
      "Number of chunks: 1\n",
      "Input tokens: 12174\n",
      "GPU memory: 8030.723584 MB\n",
      "content: ['RW', 'WS353']\n",
      "Generation took 3.00 seconds\n",
      "Accumulated time: 8.37 seconds\n",
      "Paper index: 3\n",
      "Processing paper: KBGAN: Adversarial Learning for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10175\n",
      "GPU memory: 8030.706688 MB\n",
      "content: ['FB15k-237', 'WN18', 'WN18RR']\n",
      "Generation took 3.03 seconds\n",
      "Accumulated time: 11.40 seconds\n",
      "Paper index: 4\n",
      "Processing paper: Convolutional 2D Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11529\n",
      "GPU memory: 5063.109632 MB\n",
      "content: ['WN18', 'FB15k', 'YAGO3-10', 'Countries', 'FB15k-237', 'WN18RR']\n",
      "Generation took 4.51 seconds\n",
      "Accumulated time: 15.91 seconds\n",
      "Paper index: 5\n",
      "Processing paper: Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 13925\n",
      "GPU memory: 5063.158272 MB\n",
      "content: ['ImageGraph', 'FB15k', 'VisualGenome', 'ImageNet']\n",
      "Generation took 5.16 seconds\n",
      "Accumulated time: 21.07 seconds\n",
      "Paper index: 6\n",
      "Processing paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7050\n",
      "GPU memory: 5063.067648 MB\n",
      "content: ['AKSW-bib', 'DBpedia 2015-10', 'DBpedia 2016-04']\n",
      "Generation took 3.60 seconds\n",
      "Accumulated time: 24.67 seconds\n",
      "Paper index: 7\n",
      "Processing paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "Number of chunks: 1\n",
      "Input tokens: 6907\n",
      "GPU memory: 5063.009792 MB\n",
      "content: ['Freebase', 'FB15K']\n",
      "Generation took 6.88 seconds\n",
      "Accumulated time: 31.55 seconds\n",
      "Paper index: 8\n",
      "Processing paper: Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 12061\n",
      "GPU memory: 5063.091712 MB\n",
      "content: ['FB15k', 'WN18']\n",
      "Generation took 3.78 seconds\n",
      "Accumulated time: 35.33 seconds\n",
      "Paper index: 9\n",
      "Processing paper: DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning\n",
      "Number of chunks: 1\n",
      "Input tokens: 9542\n",
      "GPU memory: 5063.092736 MB\n",
      "content: ['Freebase', 'NELL-995']\n",
      "Generation took 2.82 seconds\n",
      "Accumulated time: 38.15 seconds\n",
      "Paper index: 10\n",
      "Processing paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 4570\n",
      "GPU memory: 5062.992896 MB\n",
      "content: ['FB15k-237']\n",
      "Generation took 1.92 seconds\n",
      "Accumulated time: 40.07 seconds\n",
      "Paper index: 11\n",
      "Processing paper: Fast Linear Model for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7052\n",
      "GPU memory: 5062.992896 MB\n",
      "content: ['WN18', 'FB15k', 'SVO', 'FB15k-237', 'SQ', 'WikiMovies']\n",
      "Generation took 2.92 seconds\n",
      "Accumulated time: 42.99 seconds\n",
      "Paper index: 12\n",
      "Processing paper: Complex and Holographic Embeddings of Knowledge Graphs: A Comparison\n",
      "Number of chunks: 1\n",
      "Input tokens: 4862\n",
      "GPU memory: 5062.977024 MB\n",
      "content: ['WN18', 'FB15K']\n",
      "Generation took 1.93 seconds\n",
      "Accumulated time: 44.92 seconds\n",
      "Paper index: 13\n",
      "Processing paper: Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment\n",
      "Number of chunks: 1\n",
      "Input tokens: 11490\n",
      "GPU memory: 5063.066112 MB\n",
      "content: ['WK3l', 'CN3l']\n",
      "Generation took 2.90 seconds\n",
      "Accumulated time: 47.82 seconds\n",
      "Paper index: 14\n",
      "Processing paper: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12906\n",
      "GPU memory: 5063.141376 MB\n",
      "content: ['MutualFriends', 'MutualFriends', 'MutualFriends']\n",
      "Generation took 3.74 seconds\n",
      "Accumulated time: 51.55 seconds\n",
      "Paper index: 15\n",
      "Processing paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 8852\n",
      "GPU memory: 5063.088128 MB\n",
      "content: ['World Bank Climate Change Knowledge Portal Dataset', 'Countries Dataset']\n",
      "Generation took 2.59 seconds\n",
      "Accumulated time: 54.14 seconds\n",
      "Paper index: 16\n",
      "Processing paper: Embedding Models for Episodic Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 10766\n",
      "GPU memory: 5063.086592 MB\n",
      "content: ['GDELT', 'ICEWS']\n",
      "Generation took 2.94 seconds\n",
      "Accumulated time: 57.09 seconds\n",
      "Paper index: 17\n",
      "Processing paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "Number of chunks: 1\n",
      "Input tokens: 2353\n",
      "GPU memory: 5062.966784 MB\n",
      "content: ['NYT', 'ADE', 'Wiki-DBpedia']\n",
      "Generation took 1.74 seconds\n",
      "Accumulated time: 58.82 seconds\n",
      "Paper index: 18\n",
      "Processing paper: Hypernetwork Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9194\n",
      "GPU memory: 5063.008768 MB\n",
      "content: ['FB15k', 'WN18RR', 'FB15k-237', 'WN18', 'YAGO3-10']\n",
      "Generation took 3.46 seconds\n",
      "Accumulated time: 62.28 seconds\n",
      "Paper index: 19\n",
      "Processing paper: Multi-Hop Knowledge Graph Reasoning with Reward Shaping\n",
      "Number of chunks: 1\n",
      "Input tokens: 13086\n",
      "GPU memory: 5063.126528 MB\n",
      "content: ['UMLS', 'Kinship', 'FB15k-237', 'WN18RR', 'NELL-995']\n",
      "Generation took 4.42 seconds\n",
      "Accumulated time: 66.70 seconds\n",
      "Paper index: 20\n",
      "Processing paper: MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via Network Infused Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9484\n",
      "GPU memory: 5063.099904 MB\n",
      "content: ['FB15K-237', 'WN18RR']\n",
      "Generation took 2.80 seconds\n",
      "Accumulated time: 69.49 seconds\n",
      "Paper index: 21\n",
      "Processing paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9610\n",
      "GPU memory: 5063.07328 MB\n",
      "content: ['FB15K-237', 'WN11', 'FB13']\n",
      "Generation took 3.10 seconds\n",
      "Accumulated time: 72.59 seconds\n",
      "Paper index: 22\n",
      "Processing paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "Number of chunks: 1\n",
      "Input tokens: 10918\n",
      "GPU memory: 5063.094784 MB\n",
      "content: ['movies', 'place-types', 'newsgroups', 'IMDB sentiment']\n",
      "Generation took 3.17 seconds\n",
      "Accumulated time: 75.76 seconds\n",
      "Paper index: 23\n",
      "Processing paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7868\n",
      "GPU memory: 5063.055872 MB\n",
      "content: ['FB15k', 'WN18']\n",
      "Generation took 2.54 seconds\n",
      "Accumulated time: 78.30 seconds\n",
      "Paper index: 24\n",
      "Processing paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "Number of chunks: 1\n",
      "Input tokens: 8957\n",
      "GPU memory: 5063.049216 MB\n",
      "content: ['SnapCaptionsKB']\n",
      "Generation took 2.61 seconds\n",
      "Accumulated time: 80.91 seconds\n",
      "Paper index: 25\n",
      "Processing paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 8896\n",
      "GPU memory: 5063.056896 MB\n",
      "content: ['CADEC']\n",
      "Generation took 2.55 seconds\n",
      "Accumulated time: 83.46 seconds\n",
      "Paper index: 26\n",
      "Processing paper: Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short\n",
      "Number of chunks: 1\n",
      "Input tokens: 4967\n",
      "GPU memory: 5062.99392 MB\n",
      "content: ['Freebase', 'WordNet', 'NELL', 'FB15K', 'WN18', 'NELL165']\n",
      "Generation took 2.52 seconds\n",
      "Accumulated time: 85.97 seconds\n",
      "Paper index: 27\n",
      "Processing paper: Entity Hierarchy Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 9133\n",
      "GPU memory: 5063.029248 MB\n",
      "content: ['Wikipedia snapshot from Jan 12th, 2015', 'INEX 2009 entity ranking track']\n",
      "Generation took 3.25 seconds\n",
      "Accumulated time: 89.22 seconds\n",
      "Paper index: 28\n",
      "Processing paper: Binarized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10634\n",
      "GPU memory: 5063.087104 MB\n",
      "content: ['WN18', 'FB15k', 'WN18RR', 'FB15k-237']\n",
      "Generation took 3.49 seconds\n",
      "Accumulated time: 92.71 seconds\n",
      "Paper index: 29\n",
      "Processing paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 10361\n",
      "GPU memory: 5063.09376 MB\n",
      "content: ['NYT dataset']\n",
      "Generation took 2.76 seconds\n",
      "Accumulated time: 95.47 seconds\n",
      "Paper index: 30\n",
      "Processing paper: Quaternion Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14292\n",
      "GPU memory: 5063.154688 MB\n",
      "content: ['WN18', 'FB15K', 'WN18RR', 'FB15K-237']\n",
      "Generation took 4.13 seconds\n",
      "Accumulated time: 99.60 seconds\n",
      "Paper index: 31\n",
      "Processing paper: Relation Embedding with Dihedral Group in Knowledge Graph\n",
      "Number of chunks: 1\n",
      "Input tokens: 10242\n",
      "GPU memory: 5063.12192 MB\n",
      "content: ['WN18', 'FB15K', 'YAGO3-10', 'FB15K-237', 'WN18RR']\n",
      "Generation took 3.74 seconds\n",
      "Accumulated time: 103.33 seconds\n",
      "Paper index: 32\n",
      "Processing paper: Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 9014\n",
      "GPU memory: 5063.069184 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'NELL-995', 'UMLS', 'Alyawarra Kinship']\n",
      "Generation took 3.54 seconds\n",
      "Accumulated time: 106.87 seconds\n",
      "Paper index: 33\n",
      "Processing paper: Neural Variational Inference For Estimating Uncertainty in Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7078\n",
      "GPU memory: 5063.028736 MB\n",
      "content: ['WN18', 'WN18RR']\n",
      "Generation took 2.39 seconds\n",
      "Accumulated time: 109.26 seconds\n",
      "Paper index: 34\n",
      "Processing paper: Augmenting and Tuning Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14640\n",
      "GPU memory: 5063.133696 MB\n",
      "content: ['FB15K', 'WN18', 'FB15K-237', 'WN18RR']\n",
      "Generation took 4.31 seconds\n",
      "Accumulated time: 113.56 seconds\n",
      "Paper index: 35\n",
      "Processing paper: Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a Correntropy Objective Function\n",
      "Number of chunks: 1\n",
      "Input tokens: 8767\n",
      "GPU memory: 5063.100416 MB\n",
      "content: ['WN18', 'FB15k']\n",
      "Generation took 2.55 seconds\n",
      "Accumulated time: 116.11 seconds\n",
      "Paper index: 36\n",
      "Processing paper: Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and Convolutional-LSTM Network\n",
      "Number of chunks: 1\n",
      "Input tokens: 15940\n",
      "GPU memory: 5063.169024 MB\n",
      "content: ['DrugBank', 'KEGG Drug', 'TWOSIDES', 'MEDLINE', 'PharmGKB', 'OFFSIDES']\n",
      "Generation took 5.38 seconds\n",
      "Accumulated time: 121.49 seconds\n",
      "Paper index: 37\n",
      "Processing paper: Linking Physicians to Medical Research Results via Knowledge Graph Embeddings and Twitter\n",
      "Number of chunks: 1\n",
      "Input tokens: 5185\n",
      "GPU memory: 5063.054336 MB\n",
      "content: ['TW52']\n",
      "Generation took 1.83 seconds\n",
      "Accumulated time: 123.33 seconds\n",
      "Paper index: 38\n",
      "Processing paper: RDF2Vec: RDF Graph Embeddings and Their Applications\n",
      "Number of chunks: 2\n",
      "Input tokens: 30822\n",
      "GPU memory: 5063.37792 MB\n",
      "content: ['DBpedia', 'Wikidata', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes']\n",
      "Generation took 19.00 seconds\n",
      "Input tokens: 12696\n",
      "GPU memory: 5063.293952 MB\n",
      "content: ['Movielens', 'LibraryThing', 'Last.fm', 'DBpedia', 'Wikidata', 'DB2vec', 'WD2vec', 'Wiki2vec', 'DB_TransE', 'DB_TransH', 'DB_TransR', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w 200v 4d', 'H-DB2vec SG 500w 500v 4d', 'H-DB2vec SG 500w 200v 8d', 'H-DB2vec SG 500w 500v 8d', 'H-DB2vec SG 500w \n",
      "Generation took 236.72 seconds\n",
      "Accumulated time: 379.05 seconds\n",
      "Paper index: 39\n",
      "Processing paper: HyperKG: Hyperbolic Knowledge Graph Embeddings for Knowledge Base Completion\n",
      "Number of chunks: 1\n",
      "Input tokens: 14453\n",
      "GPU memory: 5063.208448 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'WD', 'WD++']\n",
      "Generation took 4.51 seconds\n",
      "Accumulated time: 383.56 seconds\n",
      "Paper index: 40\n",
      "Processing paper: Composing Knowledge Graph Embeddings via Word Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9872\n",
      "GPU memory: 5063.117312 MB\n",
      "content: ['FB15K', 'WN11', 'FB13']\n",
      "Generation took 3.21 seconds\n",
      "Accumulated time: 386.77 seconds\n",
      "Paper index: 41\n",
      "Processing paper: Enriching BERT with Knowledge Graph Embeddings for Document Classification\n",
      "Number of chunks: 1\n",
      "Input tokens: 7299\n",
      "GPU memory: 5063.039488 MB\n",
      "content: ['GermEval 2019 shared task on hierarchical text classification']\n",
      "Generation took 2.72 seconds\n",
      "Accumulated time: 389.49 seconds\n",
      "Paper index: 42\n",
      "Processing paper: Recommendation Through Mixtures of Heterogeneous Item Relationships\n",
      "Number of chunks: 1\n",
      "Input tokens: 15023\n",
      "GPU memory: 5063.141888 MB\n",
      "content: ['Amazon', 'Google Local', 'Steam', 'Amazon Toys', 'Amazon Clothing', 'Amazon Beauty', 'Amazon Games', 'Google Local', 'Steam']\n",
      "Generation took 5.83 seconds\n",
      "Accumulated time: 395.32 seconds\n",
      "Paper index: 43\n",
      "Processing paper: A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly?\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.456768 MB\n",
      "content: ['FB15K', 'FB15K-237']\n",
      "Generation took 9.31 seconds\n",
      "Input tokens: 2064\n",
      "GPU memory: 5063.122944 MB\n",
      "content: ['Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge']\n",
      "Generation took 9.91 seconds\n",
      "Accumulated time: 414.54 seconds\n",
      "Paper index: 44\n",
      "Processing paper: CaRe: Open Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 15253\n",
      "GPU memory: 5063.104 MB\n",
      "content: ['ReVerb45K', 'ReVerb20K']\n",
      "Generation took 4.19 seconds\n",
      "Accumulated time: 418.73 seconds\n",
      "Paper index: 45\n",
      "Processing paper: InteractE: Improving Convolution-based Knowledge Graph Embeddings by Increasing Feature Interactions\n",
      "Number of chunks: 1\n",
      "Input tokens: 12068\n",
      "GPU memory: 5063.158272 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'YAGO3-10']\n",
      "Generation took 4.05 seconds\n",
      "Accumulated time: 422.78 seconds\n",
      "Paper index: 46\n",
      "Processing paper: KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation\n",
      "Number of chunks: 1\n",
      "Input tokens: 18261\n",
      "GPU memory: 5063.232 MB\n",
      "content: ['Wikidata5M']\n",
      "Generation took 4.51 seconds\n",
      "Accumulated time: 427.28 seconds\n",
      "Paper index: 47\n",
      "Processing paper: Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 11290\n",
      "GPU memory: 5063.170048 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'YAGO3-10']\n",
      "Generation took 3.86 seconds\n",
      "Accumulated time: 431.15 seconds\n",
      "Paper index: 48\n",
      "Processing paper: Measuring Social Bias in Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13716\n",
      "GPU memory: 5063.153152 MB\n",
      "content: ['Wikidata', 'FB3M']\n",
      "Generation took 3.53 seconds\n",
      "Accumulated time: 434.68 seconds\n",
      "Paper index: 49\n",
      "Processing paper: A Physical Embedding Model for Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 9692\n",
      "GPU memory: 5063.108096 MB\n",
      "content: ['Drugbank', 'DBpedia', 'LUBM100', 'LUBM200', 'LUBM500', 'LUBM1000']\n",
      "Generation took 4.28 seconds\n",
      "Accumulated time: 438.96 seconds\n",
      "Paper index: 50\n",
      "Processing paper: The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a Focus on Reproducibility and Transferability\n",
      "Number of chunks: 1\n",
      "Input tokens: 9283\n",
      "GPU memory: 5063.070208 MB\n",
      "content: ['KEEN Universe', 'Bio2RDF', 'DBpedia', 'Freebase', 'Wikidata', 'Knowledge Vault', 'ComPath', 'Bio2Vec', 'NDEx', 'BioKEEN', 'PyKEEN', 'OpenKE', 'KEEN Model Zoo']\n",
      "Generation took 4.73 seconds\n",
      "Accumulated time: 443.70 seconds\n",
      "Paper index: 51\n",
      "Processing paper: End-to-End Entity Linking and Disambiguation leveraging Word and Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9091\n",
      "GPU memory: 5063.063552 MB\n",
      "content: ['SimpleQuestions', 'FB2M', 'Wikidata', 'DBpedia']\n",
      "Generation took 2.94 seconds\n",
      "Accumulated time: 446.64 seconds\n",
      "Paper index: 52\n",
      "Processing paper: An Evaluation of Knowledge Graph Embeddings for Autonomous Driving Data: Experience and Practice\n",
      "Number of chunks: 1\n",
      "Input tokens: 8227\n",
      "GPU memory: 5063.04768 MB\n",
      "content: ['NuScenes', 'Lyft-Level5']\n",
      "Generation took 2.73 seconds\n",
      "Accumulated time: 449.37 seconds\n",
      "Paper index: 53\n",
      "Processing paper: KGvec2go -- Knowledge Graph Embeddings as a Service\n",
      "Number of chunks: 1\n",
      "Input tokens: 8067\n",
      "GPU memory: 5063.038464 MB\n",
      "content: ['DBpedia', 'WebIsALOD', 'Wiktionary', 'WordNet']\n",
      "Generation took 2.89 seconds\n",
      "Accumulated time: 452.26 seconds\n",
      "Paper index: 54\n",
      "Processing paper: Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 13463\n",
      "GPU memory: 5063.123456 MB\n",
      "content: ['WN18RR', 'FB15K-Wiki']\n",
      "Generation took 3.77 seconds\n",
      "Accumulated time: 456.03 seconds\n",
      "Paper index: 55\n",
      "Processing paper: Drug-Drug Interaction Prediction with Wasserstein Adversarial Autoencoder-based Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 17927\n",
      "GPU memory: 5063.238144 MB\n",
      "content: ['DeepDDI', 'Decagon']\n",
      "Generation took 4.75 seconds\n",
      "Accumulated time: 460.78 seconds\n",
      "Paper index: 56\n",
      "Processing paper: Exploring the Combination of Contextual Word Embeddings and Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12760\n",
      "GPU memory: 5063.19104 MB\n",
      "content: ['FB15K', 'FB-NYT']\n",
      "Generation took 3.49 seconds\n",
      "Accumulated time: 464.27 seconds\n",
      "Paper index: 57\n",
      "Processing paper: Knowledge Graph Embeddings and Explainable AI\n",
      "Number of chunks: 1\n",
      "Input tokens: 18747\n",
      "GPU memory: 5063.2448 MB\n",
      "content: ['FB15k', 'FB15k-237', 'WN18', 'WN18RR', 'YAGO3-10']\n",
      "Generation took 6.62 seconds\n",
      "Accumulated time: 470.90 seconds\n",
      "Paper index: 58\n",
      "Processing paper: Low-Dimensional Hyperbolic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13242\n",
      "GPU memory: 5063.204864 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'YAGO3-10']\n",
      "Generation took 4.28 seconds\n",
      "Accumulated time: 475.17 seconds\n",
      "Paper index: 59\n",
      "Processing paper: Unveiling Relations in the Industry 4.0 Standards Landscape based on Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9402\n",
      "GPU memory: 5063.099392 MB\n",
      "content: ['I4.0KG', 'relatedTo', 'I4.0 standards', 'I4.0KG embeddings', 'I4.0RD', 'Trans * family of embedding models', 'I4.0KG embeddings', 'I4.0KG', 'I4.0 standards', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', 'I4.0KG', '\n",
      "Generation took 202.00 seconds\n",
      "Accumulated time: 677.18 seconds\n",
      "Paper index: 60\n",
      "Processing paper: 5* Knowledge Graph Embeddings with Projective Transformations\n",
      "Number of chunks: 1\n",
      "Input tokens: 18640\n",
      "GPU memory: 5063.249408 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'NELL']\n",
      "Generation took 5.70 seconds\n",
      "Accumulated time: 682.88 seconds\n",
      "Paper index: 61\n",
      "Processing paper: Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 13112\n",
      "GPU memory: 5063.201792 MB\n",
      "content: ['OLPBENCH']\n",
      "Generation took 3.33 seconds\n",
      "Accumulated time: 686.21 seconds\n",
      "Paper index: 62\n",
      "Processing paper: Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9154\n",
      "GPU memory: 5063.094784 MB\n",
      "content: ['SNOMED-CT', 'FB15k-237', 'WN18RR']\n",
      "Generation took 3.65 seconds\n",
      "Accumulated time: 689.85 seconds\n",
      "Paper index: 63\n",
      "Processing paper: Adversarial Learning for Debiasing Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 8275\n",
      "GPU memory: 5063.049216 MB\n",
      "content: ['DBpedia', 'AstroPh']\n",
      "Generation took 2.69 seconds\n",
      "Accumulated time: 692.54 seconds\n",
      "Paper index: 64\n",
      "Processing paper: PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 4183\n",
      "GPU memory: 5062.976512 MB\n",
      "content: ['AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', 'AmpliGraph', 'DGL-KE', 'GraphVite', 'LibKGE', 'OpenKE', 'PyTorch-BigGraph', 'PyKEEN', '\n",
      "Generation took 137.12 seconds\n",
      "Accumulated time: 829.66 seconds\n",
      "Paper index: 65\n",
      "Processing paper: Convolutional Complex Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9778\n",
      "GPU memory: 5063.0656 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15K', 'FB15K-237', 'YAGO3-10']\n",
      "Generation took 4.19 seconds\n",
      "Accumulated time: 833.84 seconds\n",
      "Paper index: 66\n",
      "Processing paper: Two Stages Approach for Tweet Engagement Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 5190\n",
      "GPU memory: 5063.005184 MB\n",
      "content: ['challenge dataset', 'Sent140 dataset', 'Tweet KB dataset', 'public engagements dataset']\n",
      "Generation took 2.44 seconds\n",
      "Accumulated time: 836.28 seconds\n",
      "Paper index: 67\n",
      "Processing paper: You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10661\n",
      "GPU memory: 5063.05536 MB\n",
      "content: ['FB15K-237', 'WNRR']\n",
      "Generation took 3.43 seconds\n",
      "Accumulated time: 839.71 seconds\n",
      "Paper index: 68\n",
      "Processing paper: HittER: Hierarchical Transformers for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14068\n",
      "GPU memory: 5063.153152 MB\n",
      "content: ['FB15K-237', 'WN18RR']\n",
      "Generation took 4.22 seconds\n",
      "Accumulated time: 843.93 seconds\n",
      "Paper index: 69\n",
      "Processing paper: More is not Always Better: The Negative Impact of A-box Materialization on RDF2vec Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10510\n",
      "GPU memory: 5063.12448 MB\n",
      "content: ['MetacriticMovies', 'MetacriticAlbums', 'Forbes2013', 'CitiesQualityOfLiving', 'AAUP']\n",
      "Generation took 4.01 seconds\n",
      "Accumulated time: 847.94 seconds\n",
      "Paper index: 70\n",
      "Processing paper: Learning semantic Image attributes using Image recognition and knowledge graph embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6301\n",
      "GPU memory: 5063.028224 MB\n",
      "content: ['COCO dataset']\n",
      "Generation took 2.15 seconds\n",
      "Accumulated time: 850.09 seconds\n",
      "Paper index: 71\n",
      "Processing paper: DualDE: Dually Distilling Knowledge Graph Embedding for Faster and Cheaper Reasoning\n",
      "Number of chunks: 1\n",
      "Input tokens: 14375\n",
      "GPU memory: 5063.123456 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 4.78 seconds\n",
      "Accumulated time: 854.88 seconds\n",
      "Paper index: 72\n",
      "Processing paper: RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 3909\n",
      "GPU memory: 5063.021056 MB\n",
      "content: ['Cities', 'Movies', 'Albums', 'AAUP', 'Forbes']\n",
      "Generation took 1.97 seconds\n",
      "Accumulated time: 856.85 seconds\n",
      "Paper index: 73\n",
      "Processing paper: QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6994\n",
      "GPU memory: 5062.986752 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15K', 'FB15k-237']\n",
      "Generation took 3.55 seconds\n",
      "Accumulated time: 860.40 seconds\n",
      "Paper index: 74\n",
      "Processing paper: Knowledge Graph Embeddings in Geometric Algebras\n",
      "Number of chunks: 1\n",
      "Input tokens: 12796\n",
      "GPU memory: 5063.103488 MB\n",
      "content: ['FB15K', 'WN18', 'FB15K-237', 'WN18RR']\n",
      "Generation took 4.32 seconds\n",
      "Accumulated time: 864.72 seconds\n",
      "Paper index: 75\n",
      "Processing paper: Knowledge Association with Hyperbolic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 16894\n",
      "GPU memory: 5063.215616 MB\n",
      "content: ['DBP15K', 'YAGO26K-906', 'DB111K-174']\n",
      "Generation took 5.73 seconds\n",
      "Accumulated time: 870.45 seconds\n",
      "Paper index: 76\n",
      "Processing paper: Inductive Entity Representations from Text via Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 18751\n",
      "GPU memory: 5063.27808 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'Wikidata5M']\n",
      "Generation took 6.30 seconds\n",
      "Accumulated time: 876.76 seconds\n",
      "Paper index: 77\n",
      "Processing paper: On the Complementary Nature of Knowledge Graph Embedding, Fine Grain Entity Types, and Language Modeling\n",
      "Number of chunks: 1\n",
      "Input tokens: 12391\n",
      "GPU memory: 5063.191552 MB\n",
      "content: ['WN11', 'FB13', 'OntoNotes', 'FIGER', 'WikiFact']\n",
      "Generation took 4.23 seconds\n",
      "Accumulated time: 880.99 seconds\n",
      "Paper index: 78\n",
      "Processing paper: MulDE: Multi-teacher Knowledge Distillation for Low-dimensional Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14972\n",
      "GPU memory: 5063.181312 MB\n",
      "content: ['FB15k-237', 'WN18RR']\n",
      "Generation took 5.16 seconds\n",
      "Accumulated time: 886.15 seconds\n",
      "Paper index: 79\n",
      "Processing paper: Motif Learning in Knowledge Graphs Using Trajectories Of Differential Equations\n",
      "Number of chunks: 1\n",
      "Input tokens: 13054\n",
      "GPU memory: 5063.171584 MB\n",
      "content: ['FB15k-237', 'YAGO3-10']\n",
      "Generation took 4.08 seconds\n",
      "Accumulated time: 890.23 seconds\n",
      "Paper index: 80\n",
      "Processing paper: FedE: Embedding Knowledge Graphs in Federated Setting\n",
      "Number of chunks: 1\n",
      "Input tokens: 10290\n",
      "GPU memory: 5063.112192 MB\n",
      "content: ['FB15k-237-Fed3', 'FB15k-237-Fed5', 'FB15k-237-Fed10', 'NELL-995-Fed3']\n",
      "Generation took 5.07 seconds\n",
      "Accumulated time: 895.30 seconds\n",
      "Paper index: 81\n",
      "Processing paper: Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification\n",
      "Number of chunks: 1\n",
      "Input tokens: 10179\n",
      "GPU memory: 5063.089152 MB\n",
      "content: ['Wikipedia-Wikidata', 'ConSE', 'DeViSE', 'KG+Rule', 'Rule+Word', 'KG+Word', 'Rule', 'ConSE+KG', 'DeViSE+KG', 'KG+Rule+Word', 'Rule+KG', 'KG+Rule+Word', 'KG+Rule', 'Rule+KG+Word', 'KG+Rule+Word+Rule', 'KG+Rule+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG', 'KG+Rule+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+Word+Rule+KG+\n",
      "Generation took 206.99 seconds\n",
      "Accumulated time: 1102.30 seconds\n",
      "Paper index: 82\n",
      "Processing paper: PairRE: Knowledge Graph Embeddings via Paired Relation Vectors\n",
      "Number of chunks: 1\n",
      "Input tokens: 11969\n",
      "GPU memory: 5063.149568 MB\n",
      "content: ['ogbl-wikikg2', 'ogbl-biokg', 'FB15k', 'FB15k-237', 'DB100k', 'Sports']\n",
      "Generation took 5.12 seconds\n",
      "Accumulated time: 1107.41 seconds\n",
      "Paper index: 83\n",
      "Processing paper: Debiasing knowledge graph embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13200\n",
      "GPU memory: 5063.150592 MB\n",
      "content: ['FB15K', 'FB3M', 'Wikidata']\n",
      "Generation took 4.01 seconds\n",
      "Accumulated time: 1111.43 seconds\n",
      "Paper index: 84\n",
      "Processing paper: Overcoming low-utility facets for complex answer retrieval\n",
      "Number of chunks: 1\n",
      "Input tokens: 11970\n",
      "GPU memory: 5063.140864 MB\n",
      "content: ['TREC CAR dataset']\n",
      "Generation took 3.22 seconds\n",
      "Accumulated time: 1114.65 seconds\n",
      "Paper index: 85\n",
      "Processing paper: Seeing is Knowing! Fact-based Visual Question Answering using Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 13881\n",
      "GPU memory: 5063.160832 MB\n",
      "content: ['ILSVRC', 'MSCOCO', 'OpenImages', 'DBPedia', 'ConceptNet', 'FVQA']\n",
      "Generation took 4.78 seconds\n",
      "Accumulated time: 1119.42 seconds\n",
      "Paper index: 86\n",
      "Processing paper: Continual Learning of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14262\n",
      "GPU memory: 5063.182336 MB\n",
      "content: ['WN18RR', 'FB15K237', 'AI2Thor']\n",
      "Generation took 4.63 seconds\n",
      "Accumulated time: 1124.05 seconds\n",
      "Paper index: 87\n",
      "Processing paper: RelWalk A Latent Variable Model Approach to Knowledge Graph Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 16606\n",
      "GPU memory: 5063.223296 MB\n",
      "content: ['FB15K237', 'WN18RR']\n",
      "Generation took 4.72 seconds\n",
      "Accumulated time: 1128.77 seconds\n",
      "Paper index: 88\n",
      "Processing paper: Demographic Aware Probabilistic Medical Knowledge Graph Embeddings of Electronic Medical Records\n",
      "Number of chunks: 1\n",
      "Input tokens: 7781\n",
      "GPU memory: 5063.100416 MB\n",
      "content: ['MIMIC-III', 'DrugBank', 'ICD-9']\n",
      "Generation took 2.73 seconds\n",
      "Accumulated time: 1131.50 seconds\n",
      "Paper index: 89\n",
      "Processing paper: Incorporating Connections Beyond Knowledge Embeddings: A Plug-and-Play Module to Enhance Commonsense Reasoning in Machine Reading Comprehension\n",
      "Number of chunks: 1\n",
      "Input tokens: 10703\n",
      "GPU memory: 5063.076864 MB\n",
      "content: ['ReCoRD']\n",
      "Generation took 2.94 seconds\n",
      "Accumulated time: 1134.44 seconds\n",
      "Paper index: 90\n",
      "Processing paper: Hyperbolic Geometry is Not Necessary: Lightweight Euclidean-Based Models for Low-Dimensional Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12534\n",
      "GPU memory: 5063.129088 MB\n",
      "content: ['WN18RR', 'FB15k237']\n",
      "Generation took 4.16 seconds\n",
      "Accumulated time: 1138.61 seconds\n",
      "Paper index: 91\n",
      "Processing paper: NuPS: A Parameter Server for Machine Learning with Non-Uniform Parameter Access\n",
      "Number of chunks: 1\n",
      "Input tokens: 22850\n",
      "GPU memory: 5063.309824 MB\n",
      "content: ['Wikidata5M', 'One Billion Word Benchmark', 'Word2Vec', 'ComplEx', 'Matrix Factorization', 'KGE', 'WV', 'MF', 'Lapse', 'NuPS', 'Petuum', 'SSP', 'ESSP', 'PyTorch-BigGraph', 'DGL-KE']\n",
      "Generation took 10.95 seconds\n",
      "Accumulated time: 1149.56 seconds\n",
      "Paper index: 92\n",
      "Processing paper: Multiple Run Ensemble Learning with Low-Dimensional Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9642\n",
      "GPU memory: 5063.1808 MB\n",
      "content: ['FB15K', 'FB15K-237', 'WN18RR']\n",
      "Generation took 3.63 seconds\n",
      "Accumulated time: 1153.19 seconds\n",
      "Paper index: 93\n",
      "Processing paper: Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis\n",
      "Number of chunks: 1\n",
      "Input tokens: 14155\n",
      "GPU memory: 5063.14752 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 12.59 seconds\n",
      "Accumulated time: 1165.78 seconds\n",
      "Paper index: 94\n",
      "Processing paper: Edge: Enriching Knowledge Graph Embeddings with External Text\n",
      "Number of chunks: 1\n",
      "Input tokens: 9890\n",
      "GPU memory: 5063.114752 MB\n",
      "content: ['SNOMED', 'Cora', 'Citeseer', 'PubMed']\n",
      "Generation took 3.45 seconds\n",
      "Accumulated time: 1169.22 seconds\n",
      "Paper index: 95\n",
      "Processing paper: KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding\n",
      "Number of chunks: 1\n",
      "Input tokens: 9767\n",
      "GPU memory: 5063.0784 MB\n",
      "content: ['SciTail', 'GLUE', 'ConceptNet', 'WordNet', 'MNLI', 'QQP', 'QNLI', 'SQNLI', 'CoLA', 'STS-B', 'MRPC', 'RTE', 'SST-2']\n",
      "Generation took 5.02 seconds\n",
      "Accumulated time: 1174.24 seconds\n",
      "Paper index: 96\n",
      "Processing paper: Towards Robust One-shot Task Execution using Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 10463\n",
      "GPU memory: 5063.089152 MB\n",
      "content: ['VirtualHome', 'Fetch']\n",
      "Generation took 2.90 seconds\n",
      "Accumulated time: 1177.14 seconds\n",
      "Paper index: 97\n",
      "Processing paper: Predicting Gene-Disease Associations with Knowledge Graph Embeddings over Multiple Ontologies\n",
      "Number of chunks: 1\n",
      "Input tokens: 5060\n",
      "GPU memory: 5063.008256 MB\n",
      "content: ['DisGeNET']\n",
      "Generation took 1.90 seconds\n",
      "Accumulated time: 1179.04 seconds\n",
      "Paper index: 98\n",
      "Processing paper: Understanding the Performance of Knowledge Graph Embeddings in Drug Discovery\n",
      "Number of chunks: 1\n",
      "Input tokens: 15899\n",
      "GPU memory: 5063.138304 MB\n",
      "content: ['Hetionet', 'BioKG']\n",
      "Generation took 4.09 seconds\n",
      "Accumulated time: 1183.13 seconds\n",
      "Paper index: 99\n",
      "Processing paper: A Knowledge Graph-Enhanced Tensor Factorisation Model for Discovering Drug Targets\n",
      "Number of chunks: 1\n",
      "Input tokens: 13529\n",
      "GPU memory: 5063.186944 MB\n",
      "content: ['Open Targets', 'PharmaProjects', 'Hetionet', 'ClinVar', 'PheWAS Catalog', 'Genomics', 'ClinGen', 'Cancer Gene Census', 'ClinVar somatic', 'IntOGen', 'ChEMBL', 'Reactome', 'Sysbio', 'SLAPenrich', 'PROGENy', 'Project Score (CRISPR)']\n",
      "Generation took 7.70 seconds\n",
      "Accumulated time: 1190.83 seconds\n",
      "Paper index: 100\n",
      "Processing paper: [Re] Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings\n",
      "Number of chunks: 0\n",
      "Accumulated time: 1190.83 seconds\n",
      "Paper index: 101\n",
      "Processing paper: Hyperbolic Temporal Knowledge Graph Embeddings with Relational and Time Curvatures\n",
      "Number of chunks: 1\n",
      "Input tokens: 13658\n",
      "GPU memory: 5063.17056 MB\n",
      "content: ['ICEWS14', 'ICEWS05-15']\n",
      "Generation took 6.18 seconds\n",
      "Accumulated time: 1197.01 seconds\n",
      "Paper index: 102\n",
      "Processing paper: RelWalk - A Latent Variable Model Approach to Knowledge Graph Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 16845\n",
      "GPU memory: 5063.222272 MB\n",
      "content: ['FB15K237', 'WN18RR', 'FB13']\n",
      "Generation took 5.21 seconds\n",
      "Accumulated time: 1202.21 seconds\n",
      "Paper index: 103\n",
      "Processing paper: A Greedy Bit-flip Training Algorithm for Binarized Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6110\n",
      "GPU memory: 5063.07584 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 2.57 seconds\n",
      "Accumulated time: 1204.79 seconds\n",
      "Paper index: 104\n",
      "Processing paper: Exploiting Network Structures to Improve Semantic Representation for the Financial Domain\n",
      "Number of chunks: 1\n",
      "Input tokens: 4212\n",
      "GPU memory: 5062.959104 MB\n",
      "content: ['FinSim-3']\n",
      "Generation took 1.84 seconds\n",
      "Accumulated time: 1206.62 seconds\n",
      "Paper index: 105\n",
      "Processing paper: Geometric Models for (Temporally) Attributed Description Logics\n",
      "Number of chunks: 1\n",
      "Input tokens: 21211\n",
      "GPU memory: 5063.216128 MB\n",
      "content: ['Geometric Models for (Temporally) Attributed Description Logics']\n",
      "Generation took 5.84 seconds\n",
      "Accumulated time: 1212.46 seconds\n",
      "Paper index: 106\n",
      "Processing paper: Learning through structure: towards deep neuromorphic knowledge graph embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14236\n",
      "GPU memory: 5063.240704 MB\n",
      "content: ['FB15k-237', 'UMLS', 'Countries S1']\n",
      "Generation took 4.57 seconds\n",
      "Accumulated time: 1217.04 seconds\n",
      "Paper index: 107\n",
      "Processing paper: Towards Automatic Bias Detection in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 8426\n",
      "GPU memory: 5063.091712 MB\n",
      "content: ['FB15K-237', 'Wikidata5m']\n",
      "Generation took 2.87 seconds\n",
      "Accumulated time: 1219.90 seconds\n",
      "Paper index: 108\n",
      "Processing paper: BiQUE: Biquaternionic Embeddings of Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 17124\n",
      "GPU memory: 5063.184384 MB\n",
      "content: ['WN18RR', 'FB15K-237', 'YAGO3-10', 'CN-100K', 'ATOMIC']\n",
      "Generation took 6.04 seconds\n",
      "Accumulated time: 1225.94 seconds\n",
      "Paper index: 109\n",
      "Processing paper: Multi-Relational Embedding for Knowledge Graph Representation and Analysis\n",
      "Number of chunks: 0\n",
      "Accumulated time: 1225.94 seconds\n",
      "Paper index: 110\n",
      "Processing paper: Relation Prediction as an Auxiliary Training Objective for Improving Multi-Relational Graph Representations\n",
      "Number of chunks: 1\n",
      "Input tokens: 11221\n",
      "GPU memory: 5063.16032 MB\n",
      "content: ['FB15k-237', 'Aristo-v4', 'WN18RR', 'Nations', 'UMLS', 'Kinship']\n",
      "Generation took 4.76 seconds\n",
      "Accumulated time: 1230.70 seconds\n",
      "Paper index: 111\n",
      "Processing paper: CareGraph: A Graph-based Recommender System for Diabetes Self-Care\n",
      "Number of chunks: 1\n",
      "Input tokens: 10014\n",
      "GPU memory: 5063.093248 MB\n",
      "content: []\n",
      "Generation took 2.55 seconds\n",
      "Accumulated time: 1233.25 seconds\n",
      "Paper index: 112\n",
      "Processing paper: Explaining Knowledge Graph Embedding via Latent Rule Learning\n",
      "Number of chunks: 1\n",
      "Input tokens: 13162\n",
      "GPU memory: 5063.133696 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 3.76 seconds\n",
      "Accumulated time: 1237.01 seconds\n",
      "Paper index: 113\n",
      "Processing paper: Time-aware Relational Graph Attention Network for Temporal Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14602\n",
      "GPU memory: 5063.182336 MB\n",
      "content: ['ICEWS14', 'ICEWS05-15', 'YAGO15K', 'DICEWS-1K', 'DICEWS-200', 'YAGO-WIKI50K-5K', 'YAGO-WIKI50K-1K', 'YAGO-WIKI20K']\n",
      "Generation took 7.29 seconds\n",
      "Accumulated time: 1244.30 seconds\n",
      "Paper index: 114\n",
      "Processing paper: What is Learned in Knowledge Graph Embeddings?\n",
      "Number of chunks: 1\n",
      "Input tokens: 10892\n",
      "GPU memory: 5063.135232 MB\n",
      "content: ['ogbl-wikikg2']\n",
      "Generation took 3.13 seconds\n",
      "Accumulated time: 1247.43 seconds\n",
      "Paper index: 115\n",
      "Processing paper: Path-Enhanced Multi-Relational Question Answering with Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 5565\n",
      "GPU memory: 5063.019008 MB\n",
      "content: ['MetaQA']\n",
      "Generation took 1.88 seconds\n",
      "Accumulated time: 1249.30 seconds\n",
      "Paper index: 116\n",
      "Processing paper: Low Resource Quadratic Forms for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11747\n",
      "GPU memory: 5063.07584 MB\n",
      "content: ['Freebase', 'WordNet', 'PRM45k']\n",
      "Generation took 3.50 seconds\n",
      "Accumulated time: 1252.80 seconds\n",
      "Paper index: 117\n",
      "Processing paper: Can Knowledge Graph Embeddings Tell Us What Fact-checked Claims Are About?\n",
      "Number of chunks: 1\n",
      "Input tokens: 5686\n",
      "GPU memory: 5063.027712 MB\n",
      "content: ['ClaimsKG', 'TEDR', 'TEGPT2', 'CKG', 'CKG-KW', 'CKG Flat concat', 'CKG Triple concat', 'CKG No KW', 'CKG Flat concat No KW', 'CKG Triple concat No KW', 'TEDR All text', 'TEGPT2 All text']\n",
      "Generation took 4.21 seconds\n",
      "Accumulated time: 1257.01 seconds\n",
      "Paper index: 118\n",
      "Processing paper: RelDiff: Enriching Knowledge Graph Relation Representations for Sensitivity Classification\n",
      "Number of chunks: 1\n",
      "Input tokens: 12354\n",
      "GPU memory: 5063.087104 MB\n",
      "content: ['GovSensitivity']\n",
      "Generation took 3.11 seconds\n",
      "Accumulated time: 1260.12 seconds\n",
      "Paper index: 119\n",
      "Processing paper: Knowledge Graph Representation Learning using Ordinary Differential Equations\n",
      "Number of chunks: 1\n",
      "Input tokens: 18393\n",
      "GPU memory: 5063.236608 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'YAGO3-10', 'YouTube']\n",
      "Generation took 6.16 seconds\n",
      "Accumulated time: 1266.28 seconds\n",
      "Paper index: 120\n",
      "Processing paper: Learning to Interact: An Adaptive Interaction Framework for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 20599\n",
      "GPU memory: 5063.319552 MB\n",
      "content: ['FB15K-237', 'WN18RR']\n",
      "Generation took 5.84 seconds\n",
      "Accumulated time: 1272.12 seconds\n",
      "Paper index: 121\n",
      "Processing paper: Integrating knowledge graph embeddings to improve mention representation for bridging anaphora resolution\n",
      "Number of chunks: 1\n",
      "Input tokens: 13887\n",
      "GPU memory: 5063.229952 MB\n",
      "content: ['ISNotes', 'BASHI']\n",
      "Generation took 3.55 seconds\n",
      "Accumulated time: 1275.67 seconds\n",
      "Paper index: 122\n",
      "Processing paper: Utilising Knowledge Graph Embeddings for Data-to-Text Generation\n",
      "Number of chunks: 1\n",
      "Input tokens: 7221\n",
      "GPU memory: 5063.069696 MB\n",
      "content: ['WebNLG corpus', 'DBpedia', 'GloVe word-embeddings', 'FastText model', 'E2E dataset', 'ROTOWIRE dataset', 'Wik-iBio dataset']\n",
      "Generation took 3.39 seconds\n",
      "Accumulated time: 1279.06 seconds\n",
      "Paper index: 123\n",
      "Processing paper: Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods\n",
      "Number of chunks: 1\n",
      "Input tokens: 16793\n",
      "GPU memory: 5063.170048 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 4.87 seconds\n",
      "Accumulated time: 1283.93 seconds\n",
      "Paper index: 124\n",
      "Processing paper: Poisoning Knowledge Graph Embeddings via Relation Inference Patterns\n",
      "Number of chunks: 1\n",
      "Input tokens: 15354\n",
      "GPU memory: 5063.222784 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 4.48 seconds\n",
      "Accumulated time: 1288.41 seconds\n",
      "Paper index: 125\n",
      "Processing paper: Transformation of Node to Knowledge Graph Embeddings for Faster Link Prediction in Social Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 6997\n",
      "GPU memory: 5063.0784 MB\n",
      "content: ['DBLP 1', 'YouTube 1', 'Orkut 1', 'LiveJournal 1', 'Amazon 1']\n",
      "Generation took 2.95 seconds\n",
      "Accumulated time: 1291.36 seconds\n",
      "Paper index: 126\n",
      "Processing paper: A Joint Training Framework for Open-World Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11060\n",
      "GPU memory: 5063.07584 MB\n",
      "content: ['FB15k-237-OWE', 'FB15k-237-OWE(L)', 'YAGO3-10-Open', 'WN18RR-Open']\n",
      "Generation took 4.88 seconds\n",
      "Accumulated time: 1296.24 seconds\n",
      "Paper index: 127\n",
      "Processing paper: Probabilistic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12479\n",
      "GPU memory: 5063.131136 MB\n",
      "content: ['FB15K', 'WN18', 'FB15K-237', 'WN18RR']\n",
      "Generation took 4.29 seconds\n",
      "Accumulated time: 1300.53 seconds\n",
      "Paper index: 128\n",
      "Processing paper: Drug Re-positioning via Text Augmented Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 5861\n",
      "GPU memory: 5063.036928 MB\n",
      "content: ['Hetionet']\n",
      "Generation took 1.94 seconds\n",
      "Accumulated time: 1302.46 seconds\n",
      "Paper index: 129\n",
      "Processing paper: Pretrain-KGEs: Learning Knowledge Representation from Pretrained Models for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11578\n",
      "GPU memory: 5063.074816 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15K', 'FB15K-237']\n",
      "Generation took 7.36 seconds\n",
      "Accumulated time: 1309.82 seconds\n",
      "Paper index: 130\n",
      "Processing paper: QubitE: Qubit Embedding for Knowledge Graph Completion\n",
      "Number of chunks: 1\n",
      "Input tokens: 12620\n",
      "GPU memory: 5063.138304 MB\n",
      "content: ['FB15k', 'FB15k-237', 'WN18', 'WN18RR']\n",
      "Generation took 4.35 seconds\n",
      "Accumulated time: 1314.17 seconds\n",
      "Paper index: 131\n",
      "Processing paper: KGE-CL: Contrastive Learning of Tensor Decomposition Based Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11891\n",
      "GPU memory: 5063.134208 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'YAGO3-10']\n",
      "Generation took 4.08 seconds\n",
      "Accumulated time: 1318.24 seconds\n",
      "Paper index: 132\n",
      "Processing paper: Prediction of Adverse Biological Effects of Chemicals Using Knowledge Graph Embeddings\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.43168 MB\n",
      "content: ['TERA', 'ECOTOX', 'ChEMBL', 'MeSH', 'Wikidata', 'PubChem', 'EOL', 'NCBI Taxonomy', 'InChIKey', 'OWL', 'SPARQL', 'RDF', 'KG', 'KGE', 'Chemical', 'Species', 'Effect', 'Chemical Concentration', 'Chemical Interaction', 'Biological', 'Ecotoxicology', 'Risk Assessment', 'Adverse Biological Effect', 'Prediction Model', 'Embedding', 'Knowledge Graph', 'Ontology', 'Semantic Web', 'Machine Learning', 'Deep Learning', 'Convolutional Neural Networks', 'Random Forests', 'Graph Embedding', 'Graph Neural Networks', 'Graph Representation', 'Graph Learning', 'Graph Mining', 'Graph Analysis', 'Graph Visualization', 'Graph Querying', 'Graph Reasoning', 'Graph Reasoning Engine', 'Graph Reasoning System', 'Graph Reasoning Framework', 'Graph Reasoning Architecture', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reasoning Standard', 'Graph Reasoning Specification', 'Graph Reasoning Framework', 'Graph Reasoning Implementation', 'Graph Reasoning Algorithm', 'Graph Reasoning Method', 'Graph Reasoning Protocol', 'Graph Reason\n",
      "Generation took 1559.61 seconds\n",
      "Input tokens: 8582\n",
      "GPU memory: 5063.26016 MB\n",
      "content: []\n",
      "Generation took 1560.74 seconds\n",
      "Accumulated time: 4438.58 seconds\n",
      "Paper index: 133\n",
      "Processing paper: Implications of Topological Imbalance for Representation Learning on Biomedical Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 15338\n",
      "GPU memory: 5063.157248 MB\n",
      "content: ['Hetionet']\n",
      "Generation took 4.68 seconds\n",
      "Accumulated time: 4443.26 seconds\n",
      "Paper index: 134\n",
      "Processing paper: Improving and Diagnosing Knowledge-Based Visual Question Answering via Entity Enhanced Knowledge Injection\n",
      "Number of chunks: 1\n",
      "Input tokens: 10724\n",
      "GPU memory: 5063.13728 MB\n",
      "content: ['KVQA', 'OKVQA']\n",
      "Generation took 3.72 seconds\n",
      "Accumulated time: 4446.98 seconds\n",
      "Paper index: 135\n",
      "Processing paper: Knowledge Graph Embedding in E-commerce Applications: Attentive Reasoning, Explanations, and Transferable Rules\n",
      "Number of chunks: 1\n",
      "Input tokens: 15308\n",
      "GPU memory: 5063.174144 MB\n",
      "content: ['PLP[all]', 'PLP[part.]', 'PLP[life.]', 'PLP[cate.]']\n",
      "Generation took 6.51 seconds\n",
      "Accumulated time: 4453.49 seconds\n",
      "Paper index: 136\n",
      "Processing paper: Self-attention Presents Low-dimensional Knowledge Graph Embeddings for Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 11940\n",
      "GPU memory: 5063.156736 MB\n",
      "content: ['FB15k-237', 'WN18RR']\n",
      "Generation took 4.18 seconds\n",
      "Accumulated time: 4457.67 seconds\n",
      "Paper index: 137\n",
      "Processing paper: Zero-shot and Few-shot Learning with Knowledge Graphs: A Comprehensive Survey\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.43168 MB\n",
      "content: ['ImageNet', 'NUS-WIDE', 'ZS-F-VQA', 'OK-VQA', 'IMDb', 'IMDb-M', 'SQuAD', 'SQuAD-M', 'SQuAD-2', 'SQuAD-3', 'SQuAD-4', 'SQuAD-5', 'SQuAD-6', 'SQuAD-7', 'SQuAD-8', 'SQuAD-9', 'SQuAD-10', 'SQuAD-11', 'SQuAD-12', 'SQuAD-13', 'SQuAD-14', 'SQuAD-15', 'SQuAD-16', 'SQuAD-17', 'SQuAD-18', 'SQuAD-19', 'SQuAD-20', 'SQuAD-21', 'SQuAD-22', 'SQuAD-23', 'SQuAD-24', 'SQuAD-25', 'SQuAD-26', 'SQuAD-27', 'SQuAD-28', 'SQuAD-29', 'SQuAD-30', 'SQuAD-31', 'SQuAD-32', 'SQuAD-33', 'SQuAD-34', 'SQuAD-35', 'SQuAD-36', 'SQuAD-37', 'SQuAD-38', 'SQuAD-39', 'SQuAD-40', 'SQuAD-41', 'SQuAD-42', 'SQuAD-43', 'SQuAD-44', 'SQuAD-45', 'SQuAD-46', 'SQuAD-47', 'SQuAD-48', 'SQuAD-49', 'SQuAD-50', 'SQuAD-51', 'SQuAD-52', 'SQuAD-53', 'SQuAD-54', 'SQuAD-55', 'SQuAD-56', 'SQuAD-57', 'SQuAD-58', 'SQuAD-59', 'SQuAD-60', 'SQuAD-61', 'SQuAD-62', 'SQuAD-63', 'SQuAD-64', 'SQuAD-65', 'SQuAD-66', 'SQuAD-67', 'SQuAD-68', 'SQuAD-69', 'SQuAD-70', 'SQuAD-71', 'SQuAD-72', 'SQuAD-73', 'SQuAD-74', 'SQuAD-75', 'SQuAD-76', 'SQuAD-77', 'SQuAD-78', 'SQuAD-79', 'SQuAD-80', 'SQuAD-81', 'SQuAD-82', 'SQuAD-83', 'SQuAD-84', 'SQuAD-85', 'SQuAD-86', 'SQuAD-87', 'SQuAD-88', 'SQuAD-89', 'SQuAD-90', 'SQuAD-91', 'SQuAD-92', 'SQuAD-93', 'SQuAD-94', 'SQuAD-95', 'SQuAD-96', 'SQuAD-97', 'SQuAD-98', 'SQuAD-99', 'SQuAD-100', 'SQuAD-101', 'SQuAD-102', 'SQuAD-103', 'SQuAD-104', 'SQuAD-105', 'SQuAD-106', 'SQuAD-107', 'SQuAD-108', 'SQuAD-109', 'SQuAD-110', 'SQuAD-111', 'SQuAD-112', 'SQuAD-113', 'SQuAD-114', 'SQuAD-115', 'SQuAD-116', 'SQuAD-117', 'SQuAD-118', 'SQuAD-119', 'SQuAD-120', 'SQuAD-121', 'SQuAD-122', 'SQuAD-123', 'SQuAD-124', 'SQuAD-125', 'SQuAD-126', 'SQuAD-127', 'SQuAD-128', 'SQuAD-129', 'SQuAD-130', 'SQuAD-131', 'SQuAD-132', 'SQuAD-133', 'SQuAD-134', 'SQuAD-135', 'SQuAD-136', 'SQuAD-137', 'SQuAD-138', 'SQuAD-139', 'SQuAD-140', 'SQuAD-141', 'SQuAD-142', 'SQuAD-143', 'SQuAD-144', 'SQuAD-145', 'SQuAD-146', 'SQuAD-147', 'SQuAD-148', 'SQuAD-149', 'SQuAD-150', 'SQuAD-151', 'SQuAD-152', 'SQuAD-153', 'SQuAD-154', 'SQuAD-155', 'SQuAD-156', 'SQuAD-157', 'SQuAD-158', 'SQuAD-159', 'SQuAD-160', 'SQuAD-161', 'SQuAD-162', 'SQuAD-163', 'SQuAD-164', 'SQuAD-165', 'SQuAD-166', 'SQuAD-167', 'SQuAD-168', 'SQuAD-169', 'SQuAD-170', 'SQuAD-171', 'SQuAD-172', 'SQuAD-173', 'SQuAD-174', 'SQuAD-175', 'SQuAD-176', 'SQuAD-177', 'SQuAD-178', 'SQuAD-179', 'SQuAD-180', 'SQuAD-181', 'SQuAD-182', 'SQuAD-183', 'SQuAD-184', 'SQuAD-185', 'SQuAD-186', 'SQuAD-187', 'SQuAD-188', 'SQuAD-189', 'SQuAD-190', 'SQuAD-191', 'SQuAD-192', 'SQuAD-193', 'SQuAD-194', 'SQuAD-195', 'SQuAD-196', 'SQuAD-197', 'SQuAD-198', 'SQuAD-199', 'SQuAD-200', 'SQuAD-201', 'SQuAD-202', 'SQuAD-203', 'SQuAD-204', 'SQuAD-205', 'SQuAD-206', 'SQuAD-207', 'SQuAD-208', 'SQuAD-209', 'SQuAD-210', 'SQuAD-211', 'SQuAD-212', 'SQuAD-213', 'SQuAD-214', 'SQuAD-215', 'SQuAD-216', 'SQuAD-217', 'SQuAD-218', 'SQuAD-219', 'SQuAD-220', 'SQuAD-221', 'SQuAD-222', 'SQuAD-223', 'SQuAD-224', 'SQuAD-225', 'SQuAD-226', 'SQuAD-227', 'SQuAD-228', 'SQuAD-229', 'SQuAD-230', 'SQuAD-231', 'SQuAD-232', 'SQuAD-233', 'SQuAD-234', 'SQuAD-235', 'SQuAD-236', 'SQuAD-237', 'SQuAD-238', 'SQuAD-239', 'SQuAD-240', 'SQuAD-241', 'SQuAD-242', 'SQuAD-243', 'SQuAD-244', 'SQuAD-245', 'SQuAD-246', 'SQuAD-247', 'SQuAD-248', 'SQuAD-249', 'SQuAD-250', 'SQuAD-251', 'SQuAD-252', 'SQuAD-253', 'SQuAD-254', 'SQuAD-255', 'SQuAD-256', 'SQuAD-257', 'SQuAD-258', 'SQuAD-259', 'SQuAD-260', 'SQuAD-261', 'SQuAD-262', 'SQuAD-263', 'SQuAD-264', 'SQuAD-265', 'SQuAD-266', 'SQuAD-267', 'SQuAD-268', 'SQuAD-269', 'SQuAD-270', 'SQuAD-271', 'SQuAD-272', 'SQuAD-273', 'SQuAD-274', 'SQuAD-275', 'SQuAD-276', 'SQuAD-277', 'SQuAD-278', 'SQuAD-279', 'SQuAD-280', 'SQuAD-281', 'SQuAD-282', 'SQuAD-283', 'SQuAD-284', 'SQuAD-285', 'SQuAD-286', 'SQuAD-287', 'SQuAD-288', 'SQuAD-289', 'SQuAD-290', 'SQuAD-291', 'SQuAD-292', 'SQuAD-293', 'SQuAD-294', 'SQuAD-295', 'SQuAD-296', 'SQuAD-297', 'SQuAD-298', 'SQuAD-299', 'SQuAD-300', 'SQuAD-301', 'SQuAD-302', 'SQuAD-303', 'SQuAD-304', 'SQuAD-305', 'SQuAD-306', 'SQuAD-307', 'SQuAD-308', 'SQuAD-309', 'SQuAD-310', 'SQuAD-311', 'SQuAD-312', 'SQuAD-313', 'SQuAD-314', 'SQuAD-315', 'SQuAD-316', 'SQuAD-317', 'SQuAD-318', 'SQuAD-319', 'SQuAD-320', 'SQuAD-321', 'SQuAD-322', 'SQuAD-323', 'SQuAD-324', 'SQuAD-325', 'SQuAD-326', 'SQuAD-327', 'SQuAD-328', 'SQuAD-329', 'SQuAD-330', 'SQuAD-331', 'SQuAD-332', 'SQuAD-333', 'SQuAD-334', 'SQuAD-335', 'SQuAD-336', 'SQuAD-337', 'SQuAD-338', 'SQuAD-339', 'SQuAD-340', 'SQuAD-341', 'SQuAD-342', 'SQuAD-343', 'SQuAD-344', 'SQuAD-345', 'SQuAD-346', 'SQuAD-347', 'SQuAD-348', 'SQuAD-349', 'SQuAD-350', 'SQuAD-351', 'SQuAD-352', 'SQuAD-353', 'SQuAD-354', 'SQuAD-355', 'SQuAD-356', 'SQuAD-357', 'SQuAD-358', 'SQuAD-359', 'SQuAD-360', 'SQuAD-361', 'SQuAD-362', 'SQuAD-363', 'SQuAD-364', 'SQuAD-365', 'SQuAD-366', 'SQuAD-367', 'SQuAD-368', 'SQuAD-369', 'SQuAD-370', 'SQuAD-371', 'SQuAD-372', 'SQuAD-373', 'SQuAD-374', 'SQuAD-375', 'SQuAD-376', 'SQuAD-377', 'SQuAD-378', 'SQuAD-379', 'SQuAD-380', 'SQuAD-381', 'SQuAD-382', 'SQuAD-383', 'SQuAD-384', 'SQuAD-385', 'SQuAD-386', 'SQuAD-387', 'SQuAD-388', 'SQuAD-389', 'SQuAD-390', 'SQuAD-391', 'SQuAD-392', 'SQuAD-393', 'SQuAD-394', 'SQuAD-395', 'SQuAD-396', 'SQuAD-397', 'SQuAD-398', 'SQuAD-399', 'SQuAD-400', 'SQuAD-401', 'SQuAD-402', 'SQuAD-403', 'SQuAD-404', 'SQuAD-405', 'SQuAD-406', 'SQuAD-407', 'SQuAD-408', 'SQuAD-409', 'SQuAD-410', 'SQuAD-411', 'SQuAD-412', 'SQuAD-413', 'SQuAD-414', 'SQuAD-415', 'SQuAD-416', 'SQuAD-417', 'SQuAD-418', 'SQuAD-419', 'SQuAD-420', 'SQuAD-421', 'SQuAD-422', 'SQuAD-423', 'SQuAD-424', 'SQuAD-425', 'SQuAD-426', 'SQuAD-427', 'SQuAD-428', 'SQuAD-429', 'SQuAD-430', 'SQuAD-431', 'SQuAD-432', 'SQuAD-433', 'SQuAD-434', 'SQuAD-435', 'SQuAD-436', 'SQuAD-437', 'SQuAD-438', 'SQuAD-439', 'SQuAD-440', 'SQuAD-441', 'SQuAD-442', 'SQuAD-443', 'SQuAD-444', 'SQuAD-445', 'SQuAD-446', 'SQuAD-447', 'SQuAD-448', 'SQuAD-449', 'SQuAD-450', 'SQuAD-451', 'SQuAD-452', 'SQuAD-453', 'SQuAD-454', 'SQuAD-455', 'SQuAD-456', 'SQuAD-457', 'SQuAD-458', 'SQuAD-459', 'SQuAD-460', 'SQuAD-461', 'SQuAD-462', 'SQuAD-463', 'S\n",
      "Generation took 2075.66 seconds\n",
      "Input tokens: 14231\n",
      "GPU memory: 5063.350272 MB\n",
      "content: ['OntoNotes', 'ACE05', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'Wikidata5M', 'NELL-One', 'Wiki-One', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k', 'NELL-ZS', 'Wiki-ZS', 'DBpedia50k', 'DBpedia500k', 'FB15k', 'FB20k\n",
      "Generation took 2402.26 seconds\n",
      "Accumulated time: 8935.60 seconds\n",
      "Paper index: 138\n",
      "Processing paper: Contrastive Object Detection Using Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12893\n",
      "GPU memory: 5063.19616 MB\n",
      "content: ['COCO', 'Cityscapes', 'OpenImages']\n",
      "Generation took 8.48 seconds\n",
      "Accumulated time: 8944.07 seconds\n",
      "Paper index: 139\n",
      "Processing paper: Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14715\n",
      "GPU memory: 5063.181312 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'CoDEx-S', 'CoDEx-M', 'CoDex-L']\n",
      "Generation took 11.78 seconds\n",
      "Accumulated time: 8955.86 seconds\n",
      "Paper index: 140\n",
      "Processing paper: Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 8085\n",
      "GPU memory: 5063.090688 MB\n",
      "content: ['FB15k-237', 'WN18RR']\n",
      "Generation took 3.52 seconds\n",
      "Accumulated time: 8959.37 seconds\n",
      "Paper index: 141\n",
      "Processing paper: A Knowledge Graph Embeddings based Approach for Author Name Disambiguation using Literals\n",
      "Number of chunks: 1\n",
      "Input tokens: 20098\n",
      "GPU memory: 5063.229952 MB\n",
      "content: ['OC-782K', 'AMiner-534K']\n",
      "Generation took 8.02 seconds\n",
      "Accumulated time: 8967.39 seconds\n",
      "Paper index: 142\n",
      "Processing paper: Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based Reasoning\n",
      "Number of chunks: 1\n",
      "Input tokens: 6802\n",
      "GPU memory: 5063.113216 MB\n",
      "content: ['LUBM', 'DBPedia', 'DBPedia20k']\n",
      "Generation took 3.05 seconds\n",
      "Accumulated time: 8970.44 seconds\n",
      "Paper index: 143\n",
      "Processing paper: InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail Entities\n",
      "Number of chunks: 1\n",
      "Input tokens: 6448\n",
      "GPU memory: 5063.000576 MB\n",
      "content: ['ogbl-wikikg2']\n",
      "Generation took 2.54 seconds\n",
      "Accumulated time: 8972.98 seconds\n",
      "Paper index: 144\n",
      "Processing paper: Contextual Semantic Embeddings for Ontology Subsumption Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 19456\n",
      "GPU memory: 5063.205376 MB\n",
      "content: ['FoodOn', 'GO', 'HeLiS', 'NCIT', 'DOID']\n",
      "Generation took 7.12 seconds\n",
      "Accumulated time: 8980.09 seconds\n",
      "Paper index: 145\n",
      "Processing paper: Dual Embodied-Symbolic Concept Representations for Deep Learning\n",
      "Number of chunks: 1\n",
      "Input tokens: 7911\n",
      "GPU memory: 5063.125504 MB\n",
      "content: ['Few-Shot Class Incremental Learning (CIL) Dataset', 'Scene Concept Graph (SCG) Dataset', 'Commonsense Knowledge Graph (CSKG) Dataset', 'Image-Text Matching Dataset', 'Multimodal Knowledge Graph (MMKG) Dataset']\n",
      "Generation took 5.29 seconds\n",
      "Accumulated time: 8985.39 seconds\n",
      "Paper index: 146\n",
      "Processing paper: LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11931\n",
      "GPU memory: 5063.097856 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15k-237']\n",
      "Generation took 4.91 seconds\n",
      "Accumulated time: 8990.29 seconds\n",
      "Paper index: 147\n",
      "Processing paper: Duality-Induced Regularizer for Semantic Matching Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 22084\n",
      "GPU memory: 5063.292416 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'YAGO3-10', 'ICEWS14', 'ICEWS05-15', 'YAGO15k', 'TRESCAL', 'TComplEx', 'TTransE', 'TA-TransE', 'RFTE-HAKE', 'BoxTE', 'TRESCAL-DURA1', 'TRESCAL-DURA2', 'CP', 'RESCAL', 'ComplEx', 'StAR', 'CP-DURA', 'RESCAL-DURA', 'ComplEx-DURA']\n",
      "Generation took 18.10 seconds\n",
      "Accumulated time: 9008.39 seconds\n",
      "Paper index: 148\n",
      "Processing paper: Ontology Matching Through Absolute Orientation of Embedding Spaces\n",
      "Number of chunks: 1\n",
      "Input tokens: 2730\n",
      "GPU memory: 5063.064576 MB\n",
      "content: ['jRDF2vec 4', 'OAEI 6 multifarm dataset']\n",
      "Generation took 2.11 seconds\n",
      "Accumulated time: 9010.50 seconds\n",
      "Paper index: 149\n",
      "Processing paper: Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions\n",
      "Number of chunks: 1\n",
      "Input tokens: 14625\n",
      "GPU memory: 5063.09888 MB\n",
      "content: ['WN18RR', 'FB15K-237', 'YAGO3-10']\n",
      "Generation took 6.25 seconds\n",
      "Accumulated time: 9016.75 seconds\n",
      "Paper index: 150\n",
      "Processing paper: Kronecker Decomposition for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 16016\n",
      "GPU memory: 5063.21664 MB\n",
      "content: ['UMLS', 'KINSHIP']\n",
      "Generation took 6.58 seconds\n",
      "Accumulated time: 9023.33 seconds\n",
      "Paper index: 151\n",
      "Processing paper: CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 14504\n",
      "GPU memory: 5063.203328 MB\n",
      "content: ['FB15K-237', 'WN18RR', 'CoDEx-S', 'CoDEx-M', 'RepoDB']\n",
      "Generation took 6.61 seconds\n",
      "Accumulated time: 9029.94 seconds\n",
      "Paper index: 152\n",
      "Processing paper: A Birds Eye View on Knowledge Graph Embeddings, Software Libraries, Applications and Challenges\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.452672 MB\n",
      "content: ['DBpedia', 'Freebase', 'YAGO3', 'ICEWS2014', 'ICEWS2005-15', 'ICEWS', 'GDELT', 'Wikidata', 'OpenKE', 'Pykg2vec', 'PyKEEN', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E', 'TransE', 'ComplEx', 'DistMult', 'Rescal', 'HolE', 'SimplE', 'TransH', 'TransD', 'TransR', 'RotatE', 'TuckER', 'NTN', 'KGlove', 'KDCoE', 'LiteralE', 'TransEA', 'EAKGAE', 'TNTComplEx', 'DyERNIE', 'TeLM', 'SDG', 'TuckERTNT', 'DyERNIE', 'KGE', 'OpenKE', 'PyTorch BigGraph', 'GraphVite', 'LibKGE', 'Pykg2vec', 'AmpliGraph', 'KGTK', 'TNTComplEx', 'DGL-KE', 'TORCH-KGE', 'KG2E',\n",
      "Generation took 1588.12 seconds\n",
      "Input tokens: 13797\n",
      "GPU memory: 5063.343104 MB\n",
      "content: []\n",
      "Generation took 1589.34 seconds\n",
      "Accumulated time: 12207.41 seconds\n",
      "Paper index: 153\n",
      "Processing paper: Ultrahyperbolic Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 15314\n",
      "GPU memory: 5063.19872 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'YAGO3-10']\n",
      "Generation took 5.64 seconds\n",
      "Accumulated time: 12213.05 seconds\n",
      "Paper index: 154\n",
      "Processing paper: On the Effectiveness of Knowledge Graph Embeddings: a Rule Mining Approach\n",
      "Number of chunks: 1\n",
      "Input tokens: 13553\n",
      "GPU memory: 5063.182336 MB\n",
      "content: ['WN18RR', 'Family KG']\n",
      "Generation took 3.75 seconds\n",
      "Accumulated time: 12216.80 seconds\n",
      "Paper index: 155\n",
      "Processing paper: Geometry Interaction Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 15380\n",
      "GPU memory: 5063.197696 MB\n",
      "content: ['WN18RR', 'FB15K-237', 'YAGO3-10']\n",
      "Generation took 4.79 seconds\n",
      "Accumulated time: 12221.59 seconds\n",
      "Paper index: 156\n",
      "Processing paper: Start Small, Think Big: On Hyperparameter Optimization for Large-Scale Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11726\n",
      "GPU memory: 5063.154176 MB\n",
      "content: ['Yago3-10', 'Wikidata5M', 'Freebase']\n",
      "Generation took 3.70 seconds\n",
      "Accumulated time: 12225.29 seconds\n",
      "Paper index: 157\n",
      "Processing paper: The DLCC Node Classification Benchmark for Analyzing Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11042\n",
      "GPU memory: 5063.113728 MB\n",
      "content: ['DBpedia', 'Synthetic Benchmark']\n",
      "Generation took 3.27 seconds\n",
      "Accumulated time: 12228.56 seconds\n",
      "Paper index: 158\n",
      "Processing paper: Hardware-agnostic Computation for Large-scale Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 3690\n",
      "GPU memory: 5062.990336 MB\n",
      "content: ['DBpedia 2021']\n",
      "Generation took 1.83 seconds\n",
      "Accumulated time: 12230.39 seconds\n",
      "Paper index: 159\n",
      "Processing paper: $Î¼\\text{KG}$: A Library for Multi-source Knowledge Graph Embeddings and Applications\n",
      "Number of chunks: 1\n",
      "Input tokens: 12343\n",
      "GPU memory: 5063.069696 MB\n",
      "content: ['FB15K', 'FB15K-237', 'YAGO3-10', 'DBP15K', 'DWY100K', 'WN18', 'WN18RR', 'OpenEA', 'FB15K-ET']\n",
      "Generation took 6.17 seconds\n",
      "Accumulated time: 12236.56 seconds\n",
      "Paper index: 160\n",
      "Processing paper: KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion\n",
      "Number of chunks: 1\n",
      "Input tokens: 17890\n",
      "GPU memory: 5063.228416 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'NELL-995', 'Kinship', 'UMLS']\n",
      "Generation took 6.54 seconds\n",
      "Accumulated time: 12243.10 seconds\n",
      "Paper index: 161\n",
      "Processing paper: Repurposing Knowledge Graph Embeddings for Triple Representation via Weak Supervision\n",
      "Number of chunks: 1\n",
      "Input tokens: 11274\n",
      "GPU memory: 5063.167488 MB\n",
      "content: ['WN18RR', 'FB15K-237']\n",
      "Generation took 3.36 seconds\n",
      "Accumulated time: 12246.47 seconds\n",
      "Paper index: 162\n",
      "Processing paper: TripleRE: Knowledge Graph Embeddings via Tripled Relation Vectors\n",
      "Number of chunks: 1\n",
      "Input tokens: 9652\n",
      "GPU memory: 5063.087616 MB\n",
      "content: ['ogbl-wikikg2', 'ogbl-biokg', 'FB15k', 'FB15k237', 'WN18']\n",
      "Generation took 3.86 seconds\n",
      "Accumulated time: 12250.33 seconds\n",
      "Paper index: 163\n",
      "Processing paper: LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9993\n",
      "GPU memory: 5063.08096 MB\n",
      "content: ['WN18RR', 'FB15k-237', 'ATOMIC2020']\n",
      "Generation took 3.49 seconds\n",
      "Accumulated time: 12253.82 seconds\n",
      "Paper index: 164\n",
      "Processing paper: Adversarial Robustness of Representation Learning for Knowledge Graphs\n",
      "Number of chunks: 3\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.41632 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 13.03 seconds\n",
      "Input tokens: 30824\n",
      "GPU memory: 5063.58272 MB\n",
      "content: ['WN18', 'FB15k-237']\n",
      "Generation took 18.65 seconds\n",
      "Input tokens: 9732\n",
      "GPU memory: 5063.245824 MB\n",
      "content: ['node2vec', 'KBlrn', 'Debiasing knowledge graph embeddings', 'Learning discrete structures for graph neural networks', 'Fast rule mining in ontological knowledge bases with AMIE++', 'KBlrn: End-to-end learning of knowledge base representations with latent, relational, and numerical features', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on large graphs', 'Graph representation learning', 'Representation learning on graphs: Methods and applications', 'Graph neural networks: Adversarial robustness', 'Jointly embedding knowledge graphs and logical rules', 'Knowledge graph embedding with iterative guidance from soft rules', 'From knowledge graph embedding to ontology embedding? An analysis of the compatibility between vector space representations and rules', 'Traversing knowledge graphs in vector space', 'A simplified benchmark for non-ambiguous explanations of knowledge graph link prediction using relational graph convolutional networks', 'Inductive representation learning on\n",
      "Generation took 195.56 seconds\n",
      "Accumulated time: 12481.06 seconds\n",
      "Paper index: 165\n",
      "Processing paper: Learning Hierarchy-Aware Quaternion Knowledge Graph Embeddings with Representing Relations as 3D Rotations\n",
      "Number of chunks: 1\n",
      "Input tokens: 17344\n",
      "GPU memory: 5063.230976 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15K', 'FB15K-237']\n",
      "Generation took 5.06 seconds\n",
      "Accumulated time: 12486.12 seconds\n",
      "Paper index: 166\n",
      "Processing paper: A Survey on Knowledge Graph-based Methods for Automated Driving\n",
      "Number of chunks: 1\n",
      "Input tokens: 11765\n",
      "GPU memory: 5063.170048 MB\n",
      "content: ['AD-1', 'AD-2', 'AD-3', 'AD-4', 'AD-5', 'AD-6', 'AD-7', 'AD-8', 'AD-9', 'AD-10']\n",
      "Generation took 5.02 seconds\n",
      "Accumulated time: 12491.14 seconds\n",
      "Paper index: 167\n",
      "Processing paper: GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 20678\n",
      "GPU memory: 5063.268864 MB\n",
      "content: ['PubMed', 'ogbn-arxiv', 'squirrel', 'yelp-chi', 'arxiv-year']\n",
      "Generation took 5.55 seconds\n",
      "Accumulated time: 12496.69 seconds\n",
      "Paper index: 168\n",
      "Processing paper: Enhancing Patent Retrieval using Text and Knowledge Graph Embeddings: A Technical Note\n",
      "Number of chunks: 1\n",
      "Input tokens: 10547\n",
      "GPU memory: 5063.177216 MB\n",
      "content: ['PatentsView', 'InnoGPS', 'PatentsGoogle', 'CSV file', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'PatentsGoogle', 'Pat\n",
      "Generation took 185.93 seconds\n",
      "Accumulated time: 12682.61 seconds\n",
      "Paper index: 169\n",
      "Processing paper: Complex Hyperbolic Knowledge Graph Embeddings with Fast Fourier Transform\n",
      "Number of chunks: 1\n",
      "Input tokens: 12050\n",
      "GPU memory: 5063.153152 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 3.83 seconds\n",
      "Accumulated time: 12686.44 seconds\n",
      "Paper index: 170\n",
      "Processing paper: KGTN-ens: Few-Shot Image Classification with Knowledge Graph Ensembles\n",
      "Number of chunks: 1\n",
      "Input tokens: 11338\n",
      "GPU memory: 5063.121408 MB\n",
      "content: ['ImageNet-FS']\n",
      "Generation took 3.06 seconds\n",
      "Accumulated time: 12689.50 seconds\n",
      "Paper index: 171\n",
      "Processing paper: Combining Contrastive Learning and Knowledge Graph Embeddings to develop medical word embeddings for the Italian language\n",
      "Number of chunks: 1\n",
      "Input tokens: 8221\n",
      "GPU memory: 5063.0656 MB\n",
      "content: ['UMLS IT A', 'MayoSRS', 'UMNSRS']\n",
      "Generation took 2.68 seconds\n",
      "Accumulated time: 12692.18 seconds\n",
      "Paper index: 172\n",
      "Processing paper: Biomedical Multi-hop Question Answering Using Knowledge Graph Embeddings and Language Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 5891\n",
      "GPU memory: 5063.003648 MB\n",
      "content: ['Hetionet', 'ComplEx', 'RoBERTa', 'BioBERT', 'AlphaFold', 'QA-GNN', 'BERT', 'Bioinformatics', 'Nature', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv:1412.6575', 'arXiv:1902.10197', 'arXiv:1907.11692', 'arXiv:2007.13069', 'arXiv:2104.06378', 'arXiv:1810.04805', 'arXiv\n",
      "Generation took 141.98 seconds\n",
      "Accumulated time: 12834.16 seconds\n",
      "Paper index: 173\n",
      "Processing paper: Customizing Knowledge Graph Embedding to Improve Clinical Study Recommendation\n",
      "Number of chunks: 1\n",
      "Input tokens: 8077\n",
      "GPU memory: 5063.0528 MB\n",
      "content: ['PD-1', 'Docetaxel']\n",
      "Generation took 2.46 seconds\n",
      "Accumulated time: 12836.62 seconds\n",
      "Paper index: 174\n",
      "Processing paper: Knowledge Reasoning via Jointly Modeling Knowledge Graphs and Soft Rules\n",
      "Number of chunks: 1\n",
      "Input tokens: 12411\n",
      "GPU memory: 5063.106048 MB\n",
      "content: ['FB15K', 'DB100K', 'FB15K-sparse']\n",
      "Generation took 3.92 seconds\n",
      "Accumulated time: 12840.53 seconds\n",
      "Paper index: 175\n",
      "Processing paper: Editing Language Model-based Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11320\n",
      "GPU memory: 5063.123456 MB\n",
      "content: ['E-FB15k237', 'A-FB15k237', 'E-WN18RR', 'A-WN18RR']\n",
      "Generation took 4.65 seconds\n",
      "Accumulated time: 12845.18 seconds\n",
      "Paper index: 176\n",
      "Processing paper: Link Prediction with Attention Applied on Multiple Knowledge Graph Embedding Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 19274\n",
      "GPU memory: 5063.242752 MB\n",
      "content: ['FB15k-237', 'NELL-995-h100', 'WN18RR']\n",
      "Generation took 5.86 seconds\n",
      "Accumulated time: 12851.04 seconds\n",
      "Paper index: 177\n",
      "Processing paper: Effects of Locality and Rule Language on Explanations for Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9659\n",
      "GPU memory: 5063.151616 MB\n",
      "content: ['fb15k-237', 'wn18rr', 'yago3-10']\n",
      "Generation took 3.74 seconds\n",
      "Accumulated time: 12854.78 seconds\n",
      "Paper index: 178\n",
      "Processing paper: Cardinality Estimation over Knowledge Graphs with Embeddings and Graph Neural Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 24537\n",
      "GPU memory: 5063.313408 MB\n",
      "content: ['SWDF', 'LUBM', 'YAGO', 'Wikidata']\n",
      "Generation took 6.00 seconds\n",
      "Accumulated time: 12860.78 seconds\n",
      "Paper index: 179\n",
      "Processing paper: Knowledge Graphs: Opportunities and Challenges\n",
      "Number of chunks: 1\n",
      "Input tokens: 24522\n",
      "GPU memory: 5063.432192 MB\n",
      "content: ['FB15K', 'WN18RR', 'WN11', 'ACM', 'KG2E', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', 'TransSparse', 'TransA', 'KBGAN', 'R-GCN', 'ConvKB', 'KGAT', 'Ripp-MKR', 'PCQA', 'KEQA', 'EQFE', 'CKG', 'EDRM', 'Ripplenet', 'KPRN', 'MHPGM', 'RKG', 'SME', 'TRANSE', 'TransH', 'TransR', 'TransD', '\n",
      "Generation took 289.03 seconds\n",
      "Accumulated time: 13149.81 seconds\n",
      "Paper index: 180\n",
      "Processing paper: Enhancing Embedding Representations of Biomedical Data using Logic Knowledge\n",
      "Number of chunks: 1\n",
      "Input tokens: 10421\n",
      "GPU memory: 5063.238656 MB\n",
      "content: ['PharmKG']\n",
      "Generation took 2.66 seconds\n",
      "Accumulated time: 13152.47 seconds\n",
      "Paper index: 181\n",
      "Processing paper: Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database\n",
      "Number of chunks: 1\n",
      "Input tokens: 5896\n",
      "GPU memory: 5063.021056 MB\n",
      "content: ['National Vulnerability Database (NVD)']\n",
      "Generation took 2.30 seconds\n",
      "Accumulated time: 13154.78 seconds\n",
      "Paper index: 182\n",
      "Processing paper: Growing and Serving Large Open-domain Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 8459\n",
      "GPU memory: 5063.026176 MB\n",
      "content: ['GROBID', 'ODKE', 'Saga', 'Semantic Annotation', 'Open Domain Knowledge Extraction', 'Knowledge Graph Embeddings', 'Entity Linking', 'Fact Ranking', 'Fact Verification', 'Related Entities', 'Knowledge Graph', 'Web Documents', 'Personal Knowledge Graph', 'Semantic Annotation Service', 'Open Domain Knowledge Extraction Service', 'Knowledge Graph Embedding', 'Entity Embeddings', 'Fact Extraction', 'Knowledge Graph Enrichment', 'Knowledge Graph Construction', 'Knowledge Graph Synchronization', 'Knowledge Graph Privacy', 'Knowledge Graph Resource Constraints', 'Knowledge Graph Global Enrichment', 'Knowledge Graph On-Device', 'Knowledge Graph Personalization', 'Knowledge Graph Semantic Annotation', 'Knowledge Graph Entity Linking', 'Knowledge Graph Fact Extraction', 'Knowledge Graph Knowledge Enrichment', 'Knowledge Graph Knowledge Construction', 'Knowledge Graph Knowledge Synchronization', 'Knowledge Graph Knowledge Privacy', 'Knowledge Graph Knowledge Resource Constraints', 'Knowledge Graph Knowledge Global Enrichment', 'Knowledge Graph Knowledge On-Device', 'Knowledge Graph Knowledge Personalization', 'Knowledge Graph Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Entity Linking', 'Knowledge Graph Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Entity Linking', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Fact Extraction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Construction', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Synchronization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Privacy', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Resource Constraints', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Global Enrichment', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge On-Device', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Personalization', 'Knowledge Graph Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Knowledge Semantic Annotation', 'Knowledge Graph Knowledge Knowledge Knowledge\n",
      "Generation took 175.82 seconds\n",
      "Accumulated time: 13330.59 seconds\n",
      "Paper index: 183\n",
      "Processing paper: FedHGN: A Federated Framework for Heterogeneous Graph Neural Networks\n",
      "Number of chunks: 1\n",
      "Input tokens: 10698\n",
      "GPU memory: 5063.115264 MB\n",
      "content: ['AIFB', 'MUTAG', 'BGS']\n",
      "Generation took 3.31 seconds\n",
      "Accumulated time: 13333.90 seconds\n",
      "Paper index: 184\n",
      "Processing paper: HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 13474\n",
      "GPU memory: 5063.144448 MB\n",
      "content: ['WN18RR', 'FB15k-237']\n",
      "Generation took 3.66 seconds\n",
      "Accumulated time: 13337.56 seconds\n",
      "Paper index: 185\n",
      "Processing paper: Jointly Learning Propagating Features on the Knowledge Graph for Movie Recommendation\n",
      "Number of chunks: 0\n",
      "Accumulated time: 13337.56 seconds\n",
      "Paper index: 186\n",
      "Processing paper: Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks\n",
      "Number of chunks: 1\n",
      "Input tokens: 12922\n",
      "GPU memory: 5063.157248 MB\n",
      "content: ['BioKG', 'DDI-Efficacy', 'DDI-Minerals', 'DPI-FDA', 'DEP-FDA-EXP']\n",
      "Generation took 4.55 seconds\n",
      "Accumulated time: 13342.11 seconds\n",
      "Paper index: 187\n",
      "Processing paper: What Makes Entities Similar? A Similarity Flooding Perspective for Multi-sourced Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 12920\n",
      "GPU memory: 5063.153152 MB\n",
      "content: ['DBP15K', 'OpenEA']\n",
      "Generation took 3.27 seconds\n",
      "Accumulated time: 13345.38 seconds\n",
      "Paper index: 188\n",
      "Processing paper: Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE\n",
      "Number of chunks: 1\n",
      "Input tokens: 13161\n",
      "GPU memory: 5063.157248 MB\n",
      "content: ['YAGO14k', 'FB15k187', 'DBpedia77k', 'GEval', 'DLCC']\n",
      "Generation took 4.24 seconds\n",
      "Accumulated time: 13349.62 seconds\n",
      "Paper index: 189\n",
      "Processing paper: Leveraging Knowledge Graph Embeddings to Enhance Contextual Representations for Relation Extraction\n",
      "Number of chunks: 1\n",
      "Input tokens: 7488\n",
      "GPU memory: 5063.06816 MB\n",
      "content: ['ChemProt', 'DDI', 'GAD']\n",
      "Generation took 2.43 seconds\n",
      "Accumulated time: 13352.06 seconds\n",
      "Paper index: 190\n",
      "Processing paper: Explainable Representations for Relation Prediction in Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 15010\n",
      "GPU memory: 5063.143424 MB\n",
      "content: ['STRING database', 'DisGeNET knowledge platform', 'Human Phenotype Ontology (HP)', 'GOA database', 'GO Consortium', 'Nucleic Acids Research', 'PPI dataset', 'GDA dataset']\n",
      "Generation took 5.42 seconds\n",
      "Accumulated time: 13357.48 seconds\n",
      "Paper index: 191\n",
      "Processing paper: Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 12122\n",
      "GPU memory: 5063.15776 MB\n",
      "content: ['DBpedia', 'Recipe']\n",
      "Generation took 3.26 seconds\n",
      "Accumulated time: 13360.74 seconds\n",
      "Paper index: 192\n",
      "Processing paper: A Personalized Recommender System Based-on Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 6577\n",
      "GPU memory: 5063.04512 MB\n",
      "content: ['Vehicle purchase/sale domain dataset']\n",
      "Generation took 2.26 seconds\n",
      "Accumulated time: 13363.00 seconds\n",
      "Paper index: 193\n",
      "Processing paper: Benchmark datasets for biomedical knowledge graphs with negative statements\n",
      "Number of chunks: 1\n",
      "Input tokens: 5823\n",
      "GPU memory: 5062.988288 MB\n",
      "content: ['Benchmark datasets for biomedical knowledge graphs with negative statements']\n",
      "Generation took 2.33 seconds\n",
      "Accumulated time: 13365.32 seconds\n",
      "Paper index: 194\n",
      "Processing paper: Rethinking Uncertainly Missing and Ambiguous Visual Modality in Multi-Modal Entity Alignment\n",
      "Number of chunks: 1\n",
      "Input tokens: 19075\n",
      "GPU memory: 5063.195648 MB\n",
      "content: ['MMEA-UMVM', 'DBP15KZH-EN', 'DBP15KJA-EN', 'DBP15KF R-EN', 'OpenEAEN-F R', 'OpenEAEN-DE', 'OpenEAD-W -V 1', 'OpenEAD-W -V 2']\n",
      "Generation took 7.96 seconds\n",
      "Accumulated time: 13373.28 seconds\n",
      "Paper index: 195\n",
      "Processing paper: Biomedical Knowledge Graph Embeddings with Negative Statements\n",
      "Number of chunks: 1\n",
      "Input tokens: 12536\n",
      "GPU memory: 5063.196672 MB\n",
      "content: ['TrueWalks', 'RDF2Vec', 'GOA', 'DisGeNET', 'HP', 'STRING', 'GO', 'OPA2Vec', 'KATY', 'OWL2Vec*', 'PPI', 'GDA', 'HPKG', 'GOKG', 'D330-D338', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the VLDB Endowment', 'PLoS Computational Biology', 'Frontiers in Genetics', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'HLT-NAACL', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI Conference on Artificial Intelligence', 'PLoS Computational Biology', 'BMC Bioinformatics', 'ISMB Annual Meeting -Bio-Ontologies', 'Nucleic Acids Research', 'Bioinformatics', 'Proceedings of the 28th AAAI\n",
      "Generation took 222.76 seconds\n",
      "Accumulated time: 13596.04 seconds\n",
      "Paper index: 196\n",
      "Processing paper: Simple Rule Injection for ComplEx Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 16876\n",
      "GPU memory: 5063.245824 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'YAGO3-10', 'NELL-One', 'FB15k-237-Zero']\n",
      "Generation took 6.03 seconds\n",
      "Accumulated time: 13602.07 seconds\n",
      "Paper index: 197\n",
      "Processing paper: Development of a Knowledge Graph Embeddings Model for Pain\n",
      "Number of chunks: 1\n",
      "Input tokens: 9436\n",
      "GPU memory: 5063.1296 MB\n",
      "content: ['Pain KGE', 'Pain In Mental Health', 'Pain KGE with EHR data', 'Pain KGE with pain concepts and sentences from EHR data']\n",
      "Generation took 4.07 seconds\n",
      "Accumulated time: 13606.14 seconds\n",
      "Paper index: 198\n",
      "Processing paper: Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 7421\n",
      "GPU memory: 5063.03744 MB\n",
      "content: ['GLUE', 'CoLA', 'SST-2', 'MRPC', 'STS-B', 'QQP', 'MNLI', 'RTE', 'QNLI', 'WNLI']\n",
      "Generation took 4.26 seconds\n",
      "Accumulated time: 13610.41 seconds\n",
      "Paper index: 199\n",
      "Processing paper: Large language models converge toward human-like concept organization\n",
      "Number of chunks: 1\n",
      "Input tokens: 9801\n",
      "GPU memory: 5063.059968 MB\n",
      "content: ['WiQueen']\n",
      "Generation took 2.62 seconds\n",
      "Accumulated time: 13613.03 seconds\n",
      "Paper index: 200\n",
      "Processing paper: Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals\n",
      "Number of chunks: 1\n",
      "Input tokens: 7186\n",
      "GPU memory: 5063.036928 MB\n",
      "content: ['kgbench']\n",
      "Generation took 2.03 seconds\n",
      "Accumulated time: 13615.06 seconds\n",
      "Paper index: 201\n",
      "Processing paper: Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports\n",
      "Number of chunks: 1\n",
      "Input tokens: 8718\n",
      "GPU memory: 5063.040512 MB\n",
      "content: ['MIMIC-CXR', 'OpenI', 'PadChest']\n",
      "Generation took 2.83 seconds\n",
      "Accumulated time: 13617.89 seconds\n",
      "Paper index: 202\n",
      "Processing paper: Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14677\n",
      "GPU memory: 5063.148032 MB\n",
      "content: ['ClinicalTrials.gov', 'NVKG', 'CTKG', 'PharmKG', 'Bioteque', 'Drug Repurposing Hub', 'OHDSI Knowledge Graph', 'BiomeDIN', 'DrugBank', 'UMLS', 'PharmGKB', 'Belleau et al.', 'FastText', 'NodePiece', 'ConvKB', 'HRGAT', 'TransE', 'TransR', 'ComplEx', 'GAT', 'R-GCN', 'ConvE', 'ConvKB', 'HRGAT', 'Bioteque', 'Drug Repurposing Hub', 'OHDSI Knowledge Graph', 'BiomeDIN', 'DrugBank', 'UMLS', 'PharmGKB', 'Belleau et al.']\n",
      "Generation took 11.33 seconds\n",
      "Accumulated time: 13629.22 seconds\n",
      "Paper index: 203\n",
      "Processing paper: KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and Knowledge Distillation\n",
      "Number of chunks: 1\n",
      "Input tokens: 9218\n",
      "GPU memory: 5063.109632 MB\n",
      "content: ['FB15K-237', 'WN18RR']\n",
      "Generation took 3.10 seconds\n",
      "Accumulated time: 13632.32 seconds\n",
      "Paper index: 204\n",
      "Processing paper: Accurate prediction of international trade flows: Leveraging knowledge graphs and their embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 14112\n",
      "GPU memory: 5063.142912 MB\n",
      "content: ['UN Comtrade', 'CEPII-BACI', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Comtrade', 'UN Com\n",
      "Generation took 227.89 seconds\n",
      "Accumulated time: 13860.20 seconds\n",
      "Paper index: 205\n",
      "Processing paper: Universal Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 7016\n",
      "GPU memory: 5063.100928 MB\n",
      "content: ['DBpedia', 'Wikidata', 'DBpedia+', 'Wikidata+']\n",
      "Generation took 3.22 seconds\n",
      "Accumulated time: 13863.42 seconds\n",
      "Paper index: 206\n",
      "Processing paper: A Study on Knowledge Graph Embeddings and Graph Neural Networks for Web Of Things\n",
      "Number of chunks: 1\n",
      "Input tokens: 11376\n",
      "GPU memory: 5063.08096 MB\n",
      "content: ['AC', 'Adream', 'C3', 'EPFL', 'Garden', 'Geonames', 'Meylan', 'Poles']\n",
      "Generation took 4.10 seconds\n",
      "Accumulated time: 13867.52 seconds\n",
      "Paper index: 207\n",
      "Processing paper: Faithful Path Language Modeling for Explainable Recommendation over Knowledge Graph\n",
      "Number of chunks: 1\n",
      "Input tokens: 13302\n",
      "GPU memory: 5063.147008 MB\n",
      "content: ['MovieLens1M', 'LFM1M']\n",
      "Generation took 3.33 seconds\n",
      "Accumulated time: 13870.84 seconds\n",
      "Paper index: 208\n",
      "Processing paper: Linked Papers With Code: The Latest in Machine Learning as an RDF Knowledge Graph\n",
      "Number of chunks: 1\n",
      "Input tokens: 2964\n",
      "GPU memory: 5062.997504 MB\n",
      "content: ['Papers with Code', 'SemOpenAlex', 'Wikidata', 'DBLP']\n",
      "Generation took 1.97 seconds\n",
      "Accumulated time: 13872.82 seconds\n",
      "Paper index: 209\n",
      "Processing paper: EXTRACT: Explainable Transparent Control of Bias in Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 9886\n",
      "GPU memory: 5063.025152 MB\n",
      "content: ['MovieLens-1M', 'KG20C']\n",
      "Generation took 2.88 seconds\n",
      "Accumulated time: 13875.69 seconds\n",
      "Paper index: 210\n",
      "Processing paper: Vehicle Lane Change Prediction based on Knowledge Graph Embeddings and Bayesian Inference\n",
      "Number of chunks: 1\n",
      "Input tokens: 16337\n",
      "GPU memory: 5063.183872 MB\n",
      "content: ['HighD dataset']\n",
      "Generation took 3.86 seconds\n",
      "Accumulated time: 13879.55 seconds\n",
      "Paper index: 211\n",
      "Processing paper: RDF-star2Vec: RDF-star Graph Embeddings for Data Mining\n",
      "Number of chunks: 1\n",
      "Input tokens: 13414\n",
      "GPU memory: 5063.18848 MB\n",
      "content: ['KGRC-RDF-star', 'KGRC-RDF', 'QT900', 'PersonObjectPlace']\n",
      "Generation took 4.66 seconds\n",
      "Accumulated time: 13884.21 seconds\n",
      "Paper index: 212\n",
      "Processing paper: BEV-TSR: Text-Scene Retrieval in BEV Space for Autonomous Driving\n",
      "Number of chunks: 1\n",
      "Input tokens: 14174\n",
      "GPU memory: 5063.177216 MB\n",
      "content: ['nuScenes-Retrieval', 'nuScenes-Retrieval Easy', 'nuScenes-Retrieval Hard']\n",
      "Generation took 4.54 seconds\n",
      "Accumulated time: 13888.76 seconds\n",
      "Paper index: 213\n",
      "Processing paper: Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 13360\n",
      "GPU memory: 5063.170048 MB\n",
      "content: ['WN18RR', 'FB15K-237']\n",
      "Generation took 3.89 seconds\n",
      "Accumulated time: 13892.65 seconds\n",
      "Paper index: 214\n",
      "Processing paper: How to Turn Your Knowledge Graph Embeddings into Generative Models\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.443456 MB\n",
      "content: ['ogbl-biokg', 'ogbl-wikikg2', 'FB15k-237', 'WN18RR']\n",
      "Generation took 9.64 seconds\n",
      "Input tokens: 1713\n",
      "GPU memory: 5063.117312 MB\n",
      "content: ['Tractable Probabilistic Knowledge Bases', 'Sum-Product Networks', 'Knowledge Graph Embedding', 'Factor Analysis', 'Tensor-Train Density Estimation', 'Neural Tensor Networks', 'Relational Decision Trees', 'Composite Likelihood Methods', 'Generative Clausal Networks', 'Visualizing Data Using t-SNE', 'Arithmetic Circuits', 'Lifted Probabilistic Inference', 'Negation Can Be Exponentially Powerful', 'Complex Embeddings', 'Probabilistic Inference', 'Tractable Probabilistic Models', 'Tractable Probabilistic Knowledge Bases with Existence Uncertainty', 'Transg', 'A Closer Look at Probability Calibration of Knowledge Graph Embedding']\n",
      "Generation took 14.52 seconds\n",
      "Accumulated time: 13916.81 seconds\n",
      "Paper index: 215\n",
      "Processing paper: Towards Efficient Methods in Medical Question Answering using Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 11044\n",
      "GPU memory: 5063.03488 MB\n",
      "content: ['COVID-QA', 'PubMedQA', 'UMLS', 'Covid-qa', 'Pubmedqa']\n",
      "Generation took 3.54 seconds\n",
      "Accumulated time: 13920.36 seconds\n",
      "Paper index: 216\n",
      "Processing paper: Capturing Knowledge Graphs and Rules with Octagon Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 29933\n",
      "GPU memory: 5063.410176 MB\n",
      "content: ['FB15k-237', 'WN18RR']\n",
      "Generation took 7.17 seconds\n",
      "Accumulated time: 13927.53 seconds\n",
      "Paper index: 217\n",
      "Processing paper: Pre-training and Diagnosing Knowledge Base Completion Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 22264\n",
      "GPU memory: 5063.438336 MB\n",
      "content: ['Doge', 'ReVerb20k', 'ReVerb45k', 'Fb15k237', 'Wn18rr', 'OlpBench']\n",
      "Generation took 6.96 seconds\n",
      "Accumulated time: 13934.49 seconds\n",
      "Paper index: 218\n",
      "Processing paper: Embedding Knowledge Graphs in Degenerate Clifford Algebras\n",
      "Number of chunks: 1\n",
      "Input tokens: 12522\n",
      "GPU memory: 5063.22176 MB\n",
      "content: ['WN18-RR', 'FB15k-237', 'NELL-995-h100', 'NELL-995-h50', 'NELL-995-h75', 'UMLS', 'KINSHIP']\n",
      "Generation took 5.23 seconds\n",
      "Accumulated time: 13939.71 seconds\n",
      "Paper index: 219\n",
      "Processing paper: Empowering machine learning models with contextual knowledge for enhancing the detection of eating disorders in social media posts\n",
      "Number of chunks: 1\n",
      "Input tokens: 20954\n",
      "GPU memory: 5063.279104 MB\n",
      "content: ['Eating disorders', 'Twitter', 'Wikidata', 'BERT', 'CamemBERT', 'DistilBERT', 'FlauBERT', 'RoBERTa', 'TweetBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2Vec', 'KGE', 'CBE', 'ED I', 'ED II', 'ED III', 'ED IV', 'F1-score', 'Accuracy', 'SPARQL', 'EntityLinker', 'Falcon 2.0', 'BERT models', 'KGE models', 'CBE models', 'SPARQL queries', 'Entity recognition', 'Entity linking', 'Word2Vec', 'BERT', 'RoBERTa', 'DistilBERT', 'FlauBERT', 'CamemBERT', 'Albert', 'SIF', 'RDF2\n",
      "Generation took 259.15 seconds\n",
      "Accumulated time: 14198.87 seconds\n",
      "Paper index: 220\n",
      "Processing paper: Improving Molecule Generation and Drug Discovery with a Knowledge-enhanced Generative Model\n",
      "Number of chunks: 1\n",
      "Input tokens: 12719\n",
      "GPU memory: 5063.246848 MB\n",
      "content: ['QM9', 'ZINC', 'BioKG', 'Hetionet', 'PharmKG', 'PrimeKG']\n",
      "Generation took 3.92 seconds\n",
      "Accumulated time: 14202.79 seconds\n",
      "Paper index: 221\n",
      "Processing paper: Federated Neural Graph Databases\n",
      "Number of chunks: 1\n",
      "Input tokens: 17644\n",
      "GPU memory: 5063.227392 MB\n",
      "content: ['FB15k', 'FB15k-237', 'NELL995']\n",
      "Generation took 4.78 seconds\n",
      "Accumulated time: 14207.56 seconds\n",
      "Paper index: 222\n",
      "Processing paper: BloomGML: Graph Machine Learning through the Lens of Bilevel Optimization\n",
      "Number of chunks: 1\n",
      "Input tokens: 22806\n",
      "GPU memory: 5063.34976 MB\n",
      "content: ['Cora', 'Citeseer', 'Pubmed', 'Arxiv', 'WN18RR_v1', 'FB15k-237_v1', 'PNA(T)', 'Sum(T)', 'PNA(D)', 'Sum(D)', 'T', 'D', 'AM', 'MUTAG', 'BGS', 'AIFB', 'HALO', 'NBFNet', 'Roman', 'Amazon', 'Minesweeper', 'Tolokers', 'Questions', 'Platonov_et_al_2023']\n",
      "Generation took 12.17 seconds\n",
      "Accumulated time: 14219.74 seconds\n",
      "Paper index: 223\n",
      "Processing paper: Counterfactual Reasoning with Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 19633\n",
      "GPU memory: 5063.340544 MB\n",
      "content: ['CFKGR-CoDEx-S', 'CFKGR-CoDEx-M', 'CFKGR-CoDEx-L']\n",
      "Generation took 6.25 seconds\n",
      "Accumulated time: 14225.99 seconds\n",
      "Paper index: 224\n",
      "Processing paper: KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation\n",
      "Number of chunks: 1\n",
      "Input tokens: 17573\n",
      "GPU memory: 5063.281664 MB\n",
      "content: ['CommonsenseQA', 'SIQA', 'BIG-Bench Hard', 'WebQuestionSP', 'TriviaQA', 'TruthfulQA']\n",
      "Generation took 5.23 seconds\n",
      "Accumulated time: 14231.21 seconds\n",
      "Paper index: 225\n",
      "Processing paper: Sharing Parameter by Conjugation for Knowledge Graph Embeddings in Complex Space\n",
      "Number of chunks: 1\n",
      "Input tokens: 10117\n",
      "GPU memory: 5063.146496 MB\n",
      "content: ['FB15K-237', 'WN18RR', 'YAGO3-10', 'FB15K', 'WN18']\n",
      "Generation took 3.66 seconds\n",
      "Accumulated time: 14234.87 seconds\n",
      "Paper index: 226\n",
      "Processing paper: RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models\n",
      "Number of chunks: 1\n",
      "Input tokens: 17103\n",
      "GPU memory: 5063.198208 MB\n",
      "content: ['JAAD', 'PSI', 'HighD']\n",
      "Generation took 4.75 seconds\n",
      "Accumulated time: 14239.62 seconds\n",
      "Paper index: 227\n",
      "Processing paper: Towards Knowledge-Infused Automated Disease Diagnosis Assistant\n",
      "Number of chunks: 1\n",
      "Input tokens: 13932\n",
      "GPU memory: 5063.202816 MB\n",
      "content: ['Empathical Dialogue Dataset']\n",
      "Generation took 3.30 seconds\n",
      "Accumulated time: 14242.92 seconds\n",
      "Paper index: 228\n",
      "Processing paper: Untargeted Adversarial Attack on Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 15952\n",
      "GPU memory: 5063.209984 MB\n",
      "content: ['FB15k-237', 'WN18RR']\n",
      "Generation took 4.24 seconds\n",
      "Accumulated time: 14247.15 seconds\n",
      "Paper index: 229\n",
      "Processing paper: From Latent to Lucid: Transforming Knowledge Graph Embeddings into Interpretable Structures with KGEPrisma\n",
      "Number of chunks: 1\n",
      "Input tokens: 22232\n",
      "GPU memory: 5063.32672 MB\n",
      "content: ['FB15k-237', 'WN18RR', 'Kinship']\n",
      "Generation took 5.64 seconds\n",
      "Accumulated time: 14252.79 seconds\n",
      "Paper index: 230\n",
      "Processing paper: Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings\n",
      "Number of chunks: 1\n",
      "Input tokens: 17385\n",
      "GPU memory: 5063.299072 MB\n",
      "content: ['YAGO3', 'Country', 'Hybrid', 'Person']\n",
      "Generation took 4.17 seconds\n",
      "Accumulated time: 14256.97 seconds\n",
      "Paper index: 231\n",
      "Processing paper: Knowledge Base Embeddings: Semantics and Theoretical Properties\n",
      "Number of chunks: 1\n",
      "Input tokens: 26183\n",
      "GPU memory: 5063.401472 MB\n",
      "content: ['GROBID - A machine learning software for extracting information from scholarly documents']\n",
      "Generation took 6.62 seconds\n",
      "Accumulated time: 14263.59 seconds\n",
      "Paper index: 232\n",
      "Processing paper: OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment\n",
      "Number of chunks: 1\n",
      "Input tokens: 11343\n",
      "GPU memory: 5063.23456 MB\n",
      "content: ['Bio-ML datasets']\n",
      "Generation took 2.88 seconds\n",
      "Accumulated time: 14266.47 seconds\n",
      "Paper index: 233\n",
      "Processing paper: Conformalized Answer Set Prediction for Knowledge Graph Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 21718\n",
      "GPU memory: 5063.281664 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15k', 'FB15k237']\n",
      "Generation took 6.29 seconds\n",
      "Accumulated time: 14272.76 seconds\n",
      "Paper index: 234\n",
      "Processing paper: Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction\n",
      "Number of chunks: 1\n",
      "Input tokens: 20331\n",
      "GPU memory: 5063.34208 MB\n",
      "content: ['WN18', 'WN18RR', 'FB15k', 'FB15k-237', 'Nations']\n",
      "Generation took 6.95 seconds\n",
      "Accumulated time: 14279.71 seconds\n",
      "Paper index: 235\n",
      "Processing paper: Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies\n",
      "Number of chunks: 1\n",
      "Input tokens: 4234\n",
      "GPU memory: 5063.074304 MB\n",
      "content: ['MIMIC-III']\n",
      "Generation took 1.89 seconds\n",
      "Accumulated time: 14281.60 seconds\n",
      "Paper index: 236\n",
      "Processing paper: TransBox: EL++-closed Ontology Embedding\n",
      "Number of chunks: 1\n",
      "Input tokens: 20170\n",
      "GPU memory: 5063.200256 MB\n",
      "content: ['GALEN', 'GO', 'ANATOMY']\n",
      "Generation took 4.71 seconds\n",
      "Accumulated time: 14286.31 seconds\n",
      "Paper index: 237\n",
      "Processing paper: Information for Conversation Generation: Proposals Utilising Knowledge Graphs\n",
      "Number of chunks: 1\n",
      "Input tokens: 6733\n",
      "GPU memory: 5063.112704 MB\n",
      "content: ['GROBID - A machine learning software for extracting information from scholarly documents']\n",
      "Generation took 2.51 seconds\n",
      "Accumulated time: 14288.82 seconds\n",
      "Paper index: 238\n",
      "Processing paper: Visual Representation Learning Guided By Multi-modal Prior Knowledge\n",
      "Number of chunks: 1\n",
      "Input tokens: 12110\n",
      "GPU memory: 5063.0912 MB\n",
      "content: ['GTSRB', 'CTSD', 'RTSD', 'DVM-CAR', 'Mini-ImageNet', 'ImageNet-V2', 'ImageNet-R', 'ImageNet-A']\n",
      "Generation took 4.66 seconds\n",
      "Accumulated time: 14293.48 seconds\n",
      "Paper index: 239\n",
      "Processing paper: Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties\n",
      "Number of chunks: 1\n",
      "Input tokens: 20275\n",
      "GPU memory: 5063.264256 MB\n",
      "content: ['KG2E', 'Poincare', 'ManifoldE', 'TorusE', 'ResCAL', 'TransE', 'TransH', 'TransR', 'STransE', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME', 'MuRP', 'ATTH', 'H2E', 'TKRL', 'DyERNIE', 'HyperKA', 'UltraE', 'HAKE', 'PairRE', 'TripleRE', 'RotatE', 'QuatE', 'DualE', 'HRS', 'SimplE', 'KG2E', 'TransD', 'TransF', 'TransA', 'TransM', 'ComplEx', 'HolE', 'SimplE', 'DKRL', 'KG-BERT', 'IKRL', 'RSME',\n",
      "Generation took 249.93 seconds\n",
      "Accumulated time: 14543.41 seconds\n",
      "Paper index: 240\n",
      "Processing paper: Resilience in Knowledge Graph Embeddings\n",
      "Number of chunks: 2\n",
      "Input tokens: 30823\n",
      "GPU memory: 5063.531008 MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 77\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU memory:\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mmemory_allocated() \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e6\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# 4: Generate text from the model\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m generated_ids \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m generated_ids[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;28mlen\u001B[39m(model_inputs\u001B[38;5;241m.\u001B[39minput_ids[\u001B[38;5;241m0\u001B[39m]):]\u001B[38;5;241m.\u001B[39mtolist() \n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# parsing thinking content\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2460\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001B[0m\n\u001B[1;32m   2452\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2453\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2454\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2455\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2456\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2457\u001B[0m     )\n\u001B[1;32m   2459\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2460\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2461\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2463\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2464\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2465\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2466\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2467\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2468\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2470\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2471\u001B[0m     \u001B[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001B[39;00m\n\u001B[1;32m   2472\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2473\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2474\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2475\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2476\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2477\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3417\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3414\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3415\u001B[0m     is_prefill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m-> 3417\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_has_unfinished_sequences\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis_peer_finished\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   3418\u001B[0m     \u001B[38;5;66;03m# prepare model inputs\u001B[39;00m\n\u001B[1;32m   3419\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   3421\u001B[0m     \u001B[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2611\u001B[0m, in \u001B[0;36mGenerationMixin._has_unfinished_sequences\u001B[0;34m(self, this_peer_finished, synced_gpus, device)\u001B[0m\n\u001B[1;32m   2609\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m this_peer_finished_flag\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m   2610\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 2611\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   2613\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# only doing the task part full text\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_tasks = []\n",
    "acuumulated_time = 0\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "counter = 0\n",
    "for paper in papers_list:\n",
    "    print(\"Paper index:\", counter)\n",
    "    counter += 1\n",
    "    \n",
    "    print(\"Processing paper:\", paper['Title'])\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    for i, question in enumerate(questions):\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i != 0:\n",
    "            continue  # skip all except i == 1\n",
    "\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "            # Loop over the chosen chunks\n",
    "            for j, chunk in enumerate(chunks_to_process):\n",
    "                # Build the chat history\n",
    "                chat = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response. \"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"}\n",
    "                ]\n",
    "\n",
    "\n",
    "                chat.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Now, given this question: {question}. Give back the answer only and only in a correct Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "                    )\n",
    "                })\n",
    "\n",
    "\n",
    "                # 2: Apply the chat template\n",
    "                formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=False)\n",
    "                #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "                # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "                model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "                print(\"Input tokens:\", model_inputs.input_ids.shape[-1])\n",
    "                print(\"GPU memory:\", torch.cuda.memory_allocated() / 1e6, \"MB\")\n",
    "\n",
    "\n",
    "                # 4: Generate text from the model\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=4096,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.8,\n",
    "                    top_k=20,\n",
    "                )\n",
    "                output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "                # parsing thinking content\n",
    "                try:\n",
    "                    # rindex finding 151668 (</think>)\n",
    "                    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "                except ValueError:\n",
    "                    index = 0\n",
    "\n",
    "                # thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "                content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "                # print(\"thinking content:\", thinking_content)\n",
    "                print(\"content:\", content)\n",
    "\n",
    "\n",
    "                response.append(content)\n",
    "                print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "                acuumulated_time += (time.time() - start)\n",
    "            responses_tasks.append(response)\n",
    "            print(f\"Accumulated time: {acuumulated_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [responses_authors, responses_dataset, responses_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"E_pred\": predictions\n",
    "}\n",
    "\n",
    "with open(\"../data/test_answers/qa_entities_with_options_grobid_qwen1b_abstract.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the name of datasets used in the paper given?\"\n",
    "question2 = \"What are the tasks that the model in the paper given is trained for?\"\n",
    "question3 = \"Who are the authors in the paper given?\"\n",
    "questions = [question, question2, question3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "\n",
    "client_ollama = Client(host='http://127.0.0.1:11434')  # Default; can omit if using defaults\n",
    "model = \"deepseek-r1:1.5b\"  # replace with an available/pulled model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "max_context_tokens = 128000 - 2048\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "responses_task = []\n",
    "responses_authors = []\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:30]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "    for i, question in enumerate(questions):\n",
    "        \n",
    "        client_ollama = Client(host='http://127.0.0.1:11434')  # Default; can omit if using defaults\n",
    "        model = \"deepseek-r1:1.5b\"  # replace with an available/pulled model\n",
    "        response = []\n",
    "\n",
    "        # Select which chunks to run\n",
    "        if i == 2:\n",
    "            # only chunk 0 when i == 2\n",
    "            chunks_to_process = chunks[:1]\n",
    "        else:\n",
    "            # otherwise all chunks\n",
    "            chunks_to_process = chunks\n",
    "\n",
    "        # Loop over the chosen chunks\n",
    "        for j, chunk in enumerate(chunks_to_process):\n",
    "            # Build the chat history\n",
    "            prompt = f\"You are an assistant for question-answering tasks. Use only the provided context information to form your response. Context chunk: {chunk}\"\n",
    "            # Add the question prompt (with or without task labels)\n",
    "            if i != 1:\n",
    "                prompt += f\"Now, given this question: {question}. Give back the answer only and only in a Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "            \n",
    "            else:\n",
    "                prompt += f\"Now, given this question: {question}, and those possible tasks: {unique_labels}. Give back the answer only and only in a Python list format, for example: ['A','B']. If you don't know the answer, just return an empty list.\"\n",
    "\n",
    "            # 2: Apply the chat template\n",
    "            decoded_output = client_ollama.generate(model=model, prompt=prompt)\n",
    "\n",
    "            response.append(decoded_output)\n",
    "\n",
    "        # Route responses into the right list\n",
    "        if i == 0:\n",
    "            responses_dataset.append(response)\n",
    "        elif i == 1:\n",
    "            responses_task.append(response)\n",
    "        else:\n",
    "            responses_authors.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out who the authors of that particular paper are. The question is straightforward: \"Who are the authors in the paper given? Give back the answer only and only in a Python list format...\" Hmm, wait, but this isn't a real question because the user didn't specify which specific paper they're referring to. That's pretty standard; I remember that without context or specificity, people often ask vague questions.\n",
      "\n",
      "I should probably consider what information they might be asking for. Maybe they want me to explain how to find authors of any given paper? But no, the question is phrased as if it's a specific paper. If it were a specific paper like \"Deep Learning for Scientific Discovery,\" then I could provide that information. But since it's not provided here, I can't answer correctly.\n",
      "\n",
      "I remember from other queries where the user mentioned providing the authors in a list format without any context, I just need to state that I don't have enough information. That makes sense because without knowing which paper they're referring to, I can't give an accurate answer. It's important to be helpful and honest here. Maybe offer further assistance if they provide more details.\n",
      "\n",
      "Wait, let me make sure I'm not missing anything. The user is asking for the authors in a specific paper, but they didn't specify which one. So no, I have to inform them that without context, I can't give an accurate list of authors for any given paper. It's crucial to be clear and concise here.\n",
      "</think>\n",
      "\n",
      "I don't have access to specific information about individual papers or their authors unless you provide the exact title or reference. If you can identify which paper you're referring to, please do so, and I can help find the relevant authors for it.\n"
     ]
    }
   ],
   "source": [
    "for response in responses_authors:\n",
    "    print(response[0]['response'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/test_answers/qa_entities_with_options_grobid_qwen1b_all_dataset.json\", \"r+\") as f:\n",
    "    data = json.load(f)\n",
    "    f.seek(0)\n",
    "    json.dump(data, f, indent=2)\n",
    "    f.truncate()\n",
    "    predictions = data[\"E_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_authors_copy = predictions[0]\n",
    "responses_dataset_copy = predictions[1]\n",
    "responses_task_copy = predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(responses_dataset_copy)):\n",
    "#     for j in range(len(responses_dataset_copy[i])):\n",
    "#         if isinstance(responses_dataset_copy[i][j], str):\n",
    "#             responses_dataset_copy[i][j] = ast.literal_eval(responses_dataset_copy[i][j])\n",
    "#     if len(responses_dataset_copy[i]) > 1:\n",
    "#         merged= list(chain.from_iterable(responses_dataset_copy[i]))\n",
    "#         responses_dataset_copy[i] = deduplicate_fuzzy(merged, threshold=80)\n",
    "#     else:\n",
    "#         responses_dataset_copy[i] = deduplicate_fuzzy(responses_dataset_copy[i][j], threshold=80)\n",
    "\n",
    "\n",
    "# for i in range(len(responses_task_copy)):\n",
    "#     for j in range(len(responses_task_copy[i])):\n",
    "#         if isinstance(responses_task_copy[i][j], str):\n",
    "#             responses_task_copy[i][j] = ast.literal_eval(responses_task_copy[i][j])\n",
    "#     if len(responses_task_copy[i]) > 1:\n",
    "#         merged= list(chain.from_iterable(responses_task_copy[i]))\n",
    "#         deduplicate = deduplicate_fuzzy(merged, threshold=80)\n",
    "#         responses_task_copy[i] = deduplicate_fuzzy(deduplicate, threshold=80)\n",
    "\n",
    "#     else:\n",
    "#         deduplicate = deduplicate_fuzzy(responses_task_copy[i][j], threshold=80)\n",
    "#         responses_task_copy[i] = deduplicate_fuzzy(deduplicate, threshold=80)\n",
    "\n",
    "\n",
    "# # return the first response, because the authors are in the first chunk always\n",
    "# for i, response in enumerate(responses_authors_copy):\n",
    "#         responses_authors_copy[i] = response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(responses_dataset_copy)):\n",
    "    for j in range(len(responses_dataset_copy[i])):\n",
    "        if isinstance(responses_dataset_copy[i][j], str):\n",
    "            responses_dataset_copy[i][j] = ast.literal_eval(responses_dataset_copy[i][j])\n",
    "        if len(responses_dataset_copy[i]) > 1:\n",
    "            merged= list(chain.from_iterable(responses_dataset_copy[i]))\n",
    "            responses_dataset_copy[i] = deduplicate_fuzzy(merged, threshold=80)\n",
    "        else:\n",
    "            responses_dataset_copy[i] = deduplicate_fuzzy(responses_dataset_copy[i][j], threshold=80)\n",
    "\n",
    "\n",
    "for i in range(len(responses_task_copy)):\n",
    "    for j in range(len(responses_task_copy[i])):\n",
    "        if isinstance(responses_task_copy[i][j], str):\n",
    "            responses_task_copy[i][j] = ast.literal_eval(responses_task_copy[i][j])\n",
    "        if len(responses_task_copy[i]) > 1:\n",
    "            merged= list(chain.from_iterable(responses_task_copy[i]))\n",
    "            deduplicate = deduplicate_fuzzy(merged, threshold=80)\n",
    "            responses_task_copy[i] = deduplicate_fuzzy(deduplicate, threshold=80)\n",
    "\n",
    "        else:\n",
    "            deduplicate = deduplicate_fuzzy(responses_task_copy[i][j], threshold=80)\n",
    "            responses_task_copy[i] = deduplicate_fuzzy(deduplicate, threshold=80)\n",
    "\n",
    "\n",
    "# return the first response, because the authors are in the first chunk always\n",
    "# for i, response in enumerate(responses_authors_copy):\n",
    "#         responses_authors_copy[i] = response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the JSON file with paper metadata from paperswithcode\n",
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "# remove if Local PDF Path is None\n",
    "papers_list = [paper for paper in papers_list if paper.get(\"Local PDF Path\") is not None]\n",
    "    \n",
    "papers = papers_list\n",
    "authors = []\n",
    "datasets = []\n",
    "tasks = []\n",
    "\n",
    "# get the authors from papers\n",
    "for i, paper in enumerate(papers):\n",
    "    authors.append(paper['Authors'])\n",
    "    datasets.append(paper['Datasets'])\n",
    "    tasks.append(paper['Tasks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove from the task \n",
    "for i in range(len(tasks)):\n",
    "    for j in range(len(tasks[i])):\n",
    "        tasks[i][j] = deduplicate_fuzzy(tasks[i][j], threshold=80)\n",
    "\n",
    "    tasks[i] = [sublist for sublist in tasks[i] if sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3550\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[1;32mIn[15], line 5\u001B[0m\n    responses_dataset_copy[i][j] = ast.literal_eval(responses_dataset_copy[i][j])\u001B[0m\n",
      "\u001B[0m  File \u001B[1;32m/usr/lib/python3.10/ast.py:64\u001B[0m in \u001B[1;35mliteral_eval\u001B[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001B[0m\n",
      "\u001B[0;36m  File \u001B[0;32m/usr/lib/python3.10/ast.py:50\u001B[0;36m in \u001B[0;35mparse\u001B[0;36m\n\u001B[0;31m    return compile(source, filename, mode, flags,\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m<unknown>:1\u001B[0;36m\u001B[0m\n\u001B[0;31m    ['DBpedia', 'Wikidata', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums', 'Metacritic Movies', 'AAUP', 'Forbes', 'AIFB', 'MUTAG', 'BGS', 'AM', 'Metacritic Albums',\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m '[' was never closed\n"
     ]
    }
   ],
   "source": [
    "responses_dataset_copy = predictions[0]\n",
    "for i in range(len(responses_dataset_copy)):\n",
    "    for j in range(len(responses_dataset_copy[i])):\n",
    "        if isinstance(responses_dataset_copy[i][j], str):\n",
    "            responses_dataset_copy[i][j] = ast.literal_eval(responses_dataset_copy[i][j])\n",
    "        if len(responses_dataset_copy[i]) > 1:\n",
    "            merged= list(chain.from_iterable(responses_dataset_copy[i]))\n",
    "            responses_dataset_copy[i] = deduplicate_fuzzy(merged, threshold=80)\n",
    "        else:\n",
    "            responses_dataset_copy[i] = deduplicate_fuzzy(responses_dataset_copy[i][j], threshold=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [datasets, tasks]\n",
    "predictions = [responses_dataset_copy, responses_task_copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autor_recalls = []\n",
    "dataset_recalls = []\n",
    "task_recalls = []\n",
    "autor_precisions = []\n",
    "dataset_precisions = []\n",
    "task_precisions = []\n",
    "autors_f1s = []\n",
    "dataset_f1s = []\n",
    "task_f1s = []\n",
    "empty_references = {}\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        reference = references[i][j]\n",
    "        prediction = predictions[i][j]\n",
    "\n",
    "        if i != 0:\n",
    "            # Flatten reference list into a single string (first elements or all)\n",
    "            ref_text = [item[0] for item in reference]\n",
    "            pred_text = prediction\n",
    "        else:\n",
    "            ref_text = [name.strip() for name in reference.split(',')]\n",
    "            pred_text = ast.literal_eval(prediction)\n",
    "        if len(ref_text) == 0:\n",
    "            if i not in empty_references:\n",
    "                empty_references[i] = []\n",
    "            empty_references[i].append(j)\n",
    "\n",
    "        if len(ref_text) > 0:\n",
    "            if len(pred_text) == 0:\n",
    "                recall = 0\n",
    "                precision = 0\n",
    "                f1 = 0\n",
    "            else:\n",
    "                # For each reference entity, find the max similarity to predicted entities\n",
    "                max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "                # Apply threshold\n",
    "                threshold = 0.6\n",
    "                tp = (max_similarities >= threshold).sum().item()\n",
    "                fn = len(ref_text) - tp         # false negatives\n",
    "                fp = len(pred_text) - tp    # false positives\n",
    "                def safe_div(num, denom):\n",
    "                    return num / denom if denom else 0.0        # or np.nan\n",
    "                precision=safe_div(tp, tp + fp)\n",
    "                recall=safe_div(tp, tp + fn)\n",
    "                f1=safe_div(2 * precision * recall, precision + recall)\n",
    "            if i == 0:\n",
    "                autor_recalls.append(recall)\n",
    "                autor_precisions.append(precision)\n",
    "                autors_f1s.append(f1)\n",
    "            elif i == 1:\n",
    "                dataset_recalls.append(recall)\n",
    "                dataset_precisions.append(precision)\n",
    "                dataset_f1s.append(f1)\n",
    "            elif i == 2:\n",
    "                task_recalls.append(recall)\n",
    "                task_precisions.append(precision)\n",
    "                task_f1s.append(f1)\n",
    "        # print(f\"Reference: {ref_text}\")\n",
    "        # print(f\"Prediction: {pred_text}\")\n",
    "        # print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing authors from the predictions\n",
    "dataset_recalls = []\n",
    "task_recalls = []\n",
    "dataset_precisions = []\n",
    "task_precisions = []\n",
    "dataset_f1s = []\n",
    "task_f1s = []\n",
    "empty_references = {}\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        reference = references[i][j]\n",
    "        prediction = predictions[i][j]\n",
    "\n",
    "        ref_text = [item[0] for item in reference]\n",
    "        pred_text = prediction\n",
    "        if len(ref_text) == 0:\n",
    "            if i not in empty_references:\n",
    "                empty_references[i] = []\n",
    "            empty_references[i].append(j)\n",
    "\n",
    "        if len(ref_text) > 0:\n",
    "            if len(pred_text) == 0:\n",
    "                recall = 0\n",
    "                precision = 0\n",
    "                f1 = 0\n",
    "            else:\n",
    "                # For each reference entity, find the max similarity to predicted entities\n",
    "                max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "                # Apply threshold\n",
    "                threshold = 0.6\n",
    "                tp = (max_similarities >= threshold).sum().item()\n",
    "                fn = len(ref_text) - tp         # false negatives\n",
    "                fp = len(pred_text) - tp    # false positives\n",
    "                def safe_div(num, denom):\n",
    "                    return num / denom if denom else 0.0        # or np.nan\n",
    "                precision=safe_div(tp, tp + fp)\n",
    "                recall=safe_div(tp, tp + fn)\n",
    "                f1=safe_div(2 * precision * recall, precision + recall)\n",
    "\n",
    "            if i == 0:\n",
    "                dataset_recalls.append(recall)\n",
    "                dataset_precisions.append(precision)\n",
    "                dataset_f1s.append(f1)\n",
    "            elif i == 1:\n",
    "                task_recalls.append(recall)\n",
    "                task_precisions.append(precision)\n",
    "                task_f1s.append(f1)\n",
    "        # print(f\"Reference: {ref_text}\")\n",
    "        # print(f\"Prediction: {pred_text}\")\n",
    "        # print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2, 6, 7, 10, 15, 16, 17, 21, 22, 23, 24, 25, 27, 29]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Adversarial Contrastive Estimation\n",
      "Paper2: []\n",
      "Title: Expeditious Generation of Knowledge Graph Embeddings\n",
      "Paper6: ['AKSW-bib', 'DBpedia 2015-10']\n",
      "Title: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "Paper7: ['Freebase', 'FB15K']\n",
      "Title: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "Paper10: ['FB15k-237']\n",
      "Title: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "Paper15: ['World Bank Climate Change Knowledge Portal Dataset']\n",
      "Title: Embedding Models for Episodic Knowledge Graphs\n",
      "Paper16: ['GDELT', 'ICEWS']\n",
      "Title: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "Paper17: ['NYT', 'ADE', 'Wiki-DBpedia']\n",
      "Title: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "Paper21: ['FB15K-237', 'WN11', 'FB13']\n",
      "Title: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "Paper22: ['movies', 'place-types', 'newsgroups', 'IMDB sentiment']\n",
      "Title: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "Paper23: ['FB15k', 'WN18']\n",
      "Title: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "Paper24: ['SnapCaptionsKB']\n",
      "Title: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "Paper25: ['CADEC']\n",
      "Title: Entity Hierarchy Embedding\n",
      "Paper27: ['Wikipedia snapshot from Jan 12th, 2015', 'INEX 2009 entity ranking track']\n",
      "Title: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Paper29: ['NYT dataset']\n"
     ]
    }
   ],
   "source": [
    "for j in empty_references[1]:\n",
    "    print(f'Title: {papers[j][\"Title\"]}')\n",
    "    print(f'Paper{j}:',predictions[1][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Dataset Recall: 0.1815\n",
      "Mean Task Recall: 0.7202\n",
      "Mean Dataset Precision: 0.3281\n",
      "Mean Task Precision: 0.7124\n",
      "Mean Dataset F1: 0.2116\n",
      "Mean Task F1: 0.6292\n"
     ]
    }
   ],
   "source": [
    "#mean_autor_recall = sum(autor_recalls) / len(autor_recalls)\n",
    "mean_dataset_recall = sum(dataset_recalls) / len(dataset_recalls)\n",
    "mean_task_recall = sum(task_recalls) / len(task_recalls)\n",
    "#mean_autor_precision = sum(autor_precisions) / len(autor_precisions)\n",
    "mean_dataset_precision = sum(dataset_precisions) / len(dataset_precisions)\n",
    "mean_task_precision = sum(task_precisions) / len(task_precisions)\n",
    "#mean_autor_f1 = sum(autors_f1s) / len(autors_f1s)\n",
    "mean_dataset_f1 = sum(dataset_f1s) / len(dataset_f1s)\n",
    "mean_task_f1 = sum(task_f1s) / len(task_f1s)\n",
    "\n",
    "#print(f\"Mean Author Recall: {mean_autor_recall:.4f}\")\n",
    "print(f\"Mean Dataset Recall: {mean_dataset_recall:.4f}\")\n",
    "print(f\"Mean Task Recall: {mean_task_recall:.4f}\")\n",
    "# print(f\"Mean Author Precision: {mean_autor_precision:.4f}\")\n",
    "print(f\"Mean Dataset Precision: {mean_dataset_precision:.4f}\")\n",
    "print(f\"Mean Task Precision: {mean_task_precision:.4f}\")\n",
    "# print(f\"Mean Author F1: {mean_autor_f1:.4f}\")\n",
    "print(f\"Mean Dataset F1: {mean_dataset_f1:.4f}\")\n",
    "print(f\"Mean Task F1: {mean_task_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Author Recall: 0.9422\n",
      "Mean Dataset Recall: 0.8661\n",
      "Mean Task Recall: 0.7821\n",
      "Mean Author Precision: 0.8340\n",
      "Mean Dataset Precision: 0.7542\n",
      "Mean Task Precision: 0.4257\n",
      "Mean Author F1: 0.8482\n",
      "Mean Dataset F1: 0.7307\n",
      "Mean Task F1: 0.4669\n"
     ]
    }
   ],
   "source": [
    "mean_autor_recall = sum(autor_recalls) / len(autor_recalls)\n",
    "mean_dataset_recall = sum(dataset_recalls) / len(dataset_recalls)\n",
    "mean_task_recall = sum(task_recalls) / len(task_recalls)\n",
    "mean_autor_precision = sum(autor_precisions) / len(autor_precisions)\n",
    "mean_dataset_precision = sum(dataset_precisions) / len(dataset_precisions)\n",
    "mean_task_precision = sum(task_precisions) / len(task_precisions)\n",
    "mean_autor_f1 = sum(autors_f1s) / len(autors_f1s)\n",
    "mean_dataset_f1 = sum(dataset_f1s) / len(dataset_f1s)\n",
    "mean_task_f1 = sum(task_f1s) / len(task_f1s)\n",
    "\n",
    "print(f\"Mean Author Recall: {mean_autor_recall:.4f}\")\n",
    "print(f\"Mean Dataset Recall: {mean_dataset_recall:.4f}\")\n",
    "print(f\"Mean Task Recall: {mean_task_recall:.4f}\")\n",
    "print(f\"Mean Author Precision: {mean_autor_precision:.4f}\")\n",
    "print(f\"Mean Dataset Precision: {mean_dataset_precision:.4f}\")\n",
    "print(f\"Mean Task Precision: {mean_task_precision:.4f}\")\n",
    "print(f\"Mean Author F1: {mean_autor_f1:.4f}\")\n",
    "print(f\"Mean Dataset F1: {mean_dataset_f1:.4f}\")\n",
    "print(f\"Mean Task F1: {mean_task_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors grobid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "\n",
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "\n",
    "# remove if Local PDF Path is None\n",
    "papers = [paper for paper in papers_list if paper.get(\"Local PDF Path\") is not None]\n",
    "authors = []\n",
    "datasets = []\n",
    "tasks = []\n",
    "\n",
    "# get the authors from papers\n",
    "for i, paper in enumerate(papers):\n",
    "    authors.append(paper['Authors'])\n",
    "    datasets.append(paper['Datasets'])\n",
    "    tasks.append(paper['Tasks'])\n",
    "references = [authors, datasets, tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "['Yuyu Zhang', 'Hanjun Dai', 'Toraman Kamil', 'Le Song']\n",
      "['Agustinus Kristiadi', 'Mohammad Asif Khan', 'Denis Lukovnikov', 'Jens Lehmann', 'Asja Fischer']\n",
      "['Avishek Joey Bose', 'Huan Ling', 'Yanshuai Cao', 'Borealis Ai']\n",
      "['Liwei Cai', 'William Yang Wang']\n",
      "['Tim Dettmers', 'Pasquale Minervini', 'Pontus Stenetorp', 'Sebastian Riedel']\n",
      "['Daniel OÃ±oro-Rubio', 'Mathias Niepert', 'Alberto GarcÃ­a-DurÃ¡n', 'Roberto GonzÃ¡lez-SÃ¡nchez', 'Roberto J LÃ³pez-Sastre']\n",
      "['Tommaso Soru', 'Stefano Ruberto', 'Diego Moussallem', 'AndrÃ© Valdestilhas', 'Alexander Bigerl', 'Edgard Marx', 'Diego Esteves']\n",
      "['Bhushan Kotnis', 'Vivi Nastase']\n",
      "['Bhushan Kotnis', 'Vivi Nastase']\n",
      "['Wenhan Xiong', 'Thien Hoang', 'William Yang Wang']\n",
      "['Tathagata Sengupta', 'Cibi Pragadeesh', 'Partha Pratim Talukdar']\n",
      "['Armand Joulin', 'Piotr Bojanowski', 'Maximilian Nickel', 'Tomas Mikolov']\n",
      "['ThÃ©o Trouillon', 'Maximilian Nickel']\n",
      "['Muhao Chen', 'Yingtao Tian', 'Mohan Yang', 'Carlo Zaniolo']\n",
      "['He He', 'Anusha Balakrishnan', 'Mihail Eric', 'Percy Liang']\n",
      "['Naoya Takeishi', 'Kosuke Akimoto']\n",
      "['Yunpu Ma', 'Volker Tresp', 'Erik A Daxberger']\n",
      "['Yue Liu', 'Tongtao Zhang', 'Zhicheng Liang', 'Heng Ji', 'Deborah L Mcguinness']\n",
      "['Ivana BalaÅ¾eviÄ', 'Carl Allen', 'Timothy M Hospedales']\n",
      "['Victoria Xi', 'Richard Lin', 'Caiming Socher', 'Xiong']\n",
      "['Hao Yu', 'Vivek Kulkarni', 'William Yang Wang']\n",
      "['Haoyu Wang', 'Vivek Kulkarni', 'William Yang Wang']\n",
      "['Thomas Ager', 'OndÅej KuÅ¾elka', 'Steven Schockaert']\n",
      "['Aditya Sharma', 'Partha Talukdar']\n",
      "['Seungwhan Moon', 'Leonardo Neves', 'Vitor Carvalho']\n",
      "['Gabriel Stanovsky', 'Daniel Gruhl', 'Pablo N Mendes']\n",
      "['Jay Pujara', 'Eriq Augustine', 'Lise Getoor']\n",
      "['Zhiting Hu', 'Poyao Huang', 'Yuntian Deng', 'Yingkai Gao', 'Eric P Xing']\n",
      "['Koki Kishimoto', 'Katsuhiko Hayashi', 'Genki Akai', 'Masashi Shimbo', 'Kazunori Komatani']\n",
      "['Ningyu Zhang', 'Shumin Deng', 'Zhanlin Sun', 'Guanying Wang', 'Xi Chen', 'Wei Zhang', 'Huajun Chen']\n",
      "['Shuai Zhang', 'Yi Tay', 'Lina Yao', 'Qi Liu']\n",
      "['Canran Xu', 'Ruijiang Li']\n",
      "['Deepak Nathani', 'Jatin Chauhan', 'Charu Sharma', 'Manohar Kaul']\n",
      "['Alexander I Cowen-Rivers', 'Pasquale Minervini', 'Tim RocktÃ¤schel', 'Matko BoÅ¡njak', 'Sebastian Riedel', 'Jun Wang']\n",
      "['Robert Bamler', 'Farnood Salehi', 'Stephan Mandt']\n",
      "['Mojtaba Nayyeri', 'Xiaotian Zhou', 'Sahar Vahdati', 'Shariat Hamed', 'Yazdi', 'Jens Lehmann']\n",
      "['Md. Rezaul Karim', 'Michael Cochez', 'Joao Bosco Jares', 'Mamtaz Uddin', 'Oya Beyan', 'Stefan Decker']\n",
      "['Afshin Sadeghi', 'Jens Lehmann']\n",
      "['Freddy Lecue', 'Achim Rettinger', 'Petar Ristoski', 'Jessica Rosati', 'Tommaso Di Noia', 'Renato De Leone', 'Heiko Paulheim']\n",
      "['Prodromos Kolyvakis', 'Alexandros Kalousis', 'Dimitris Kiritsis']\n",
      "['Lianbo Ma', 'Peng Sun', 'Zhiwei Lin', 'Hui Wang']\n",
      "['Malte Ostendorff', 'Peter Bourgonje', 'Maria Berger', 'JuliÃ¡n Moreno-Schneider', 'Georg Rehm', 'Bela Gipp']\n",
      "['Wang-Cheng Kang', 'Mengting Wan', 'Julian Mcauley']\n",
      "['Asefa Genet', 'Gesese', 'Russa Biswas', 'Mehwish Alam', 'Harald Sack']\n",
      "['Swapnil Gupta', 'Sreyash Kenkre', 'Partha Talukdar']\n",
      "['Shikhar Vashishth', 'Soumya Sanyal', 'Vikram Nitin', 'Nilesh Agrawal', 'Partha Talukdar']\n",
      "['Xiaozhi Wang', 'Tianyu Gao', 'Zhaocheng Zhu', 'Zhengyan Zhang', 'Zhiyuan Liu', 'Juanzi Li', 'Jian Tang']\n",
      "['Zhanqiu Zhang', 'Jianyu Cai', 'Yongdong Zhang', 'Jie Wang']\n",
      "['Joseph Fisher', 'Dave Palfrey', 'Christos Christodoulopoulos', 'Arpit Mittal']\n",
      "['Caglar Demir', 'Axel-Cyrille Ngonga']\n",
      "['Mehdi Ali', 'Hajira Jabeen', 'Charles Tapley Hoyt', 'Jens Lehmann']\n",
      "['Rostislav Nedelchev', 'Debanjan Chaudhuri', 'Jens Lehmann', 'Asja Fischer']\n",
      "['Ruwan Wickramarachchi', 'Cory Henson', 'Amit Sheth']\n",
      "['Jan Portisch', 'Michael Hladik', 'Heiko Paulheim']\n",
      "['Tara Safavi', 'Danai Koutra', 'Edgar Meij']\n",
      "['Yuanfei Dai', 'Chenaho Guo', 'Wenzhong Guo', 'Carsten Eickhoff']\n",
      "['Lea Dieudonat', 'Kelvin Han', 'Phyllicia Leavitt', 'Esteban Marquer']\n",
      "['Federico Bianchi', 'Gaetano Rossiello', 'Luca Costabello', 'Matteo Palmonari', 'Pasquale Minervini', 'Bocconi University']\n",
      "['Ines Chami', 'Adva Wolf', 'Da-Cheng Juan', 'Frederic Sala', 'Sujith Ravi', 'Christopher RÃ©']\n",
      "['Ariam Rivas', 'IrlÃ¡n Grangel-GonzÃ¡lez', 'Diego Collarana', 'Jens Lehmann', 'Maria-Esther Vidal']\n",
      "['Mojtaba Nayyeri', 'Sahar Vahdati', 'Can Aykul', 'Jens Lehmann']\n",
      "['Samuel Broscheit', 'Kiril Gashteovski', 'Yanjie Wang', 'Rainer Gemulla']\n",
      "['David Chang', 'Ivana BalaÅ¾eviÄ', 'Carl Allen', 'Daniel Chawla', 'Cynthia Brandt', 'Richard Andrew Taylor']\n",
      "['Mario Arduini', 'Lorenzo Noci', 'Federico Pirovano', 'Ce Zhang', 'Yash Raj Shrestha', 'Bibek Paudel']\n",
      "['Mehdi Ali', 'Max Berrendorf', 'Charles Tapley Hoyt', 'Laurent Vermue', 'Sahand Sharifzadeh', 'Volker Tresp', 'Jens Lehmann']\n",
      "['Caglar Demir', 'Axel-Cyrille Ngonga']\n",
      "['Amine Dadoun', 'Amadeus Sas', 'France Ismail Harrando', 'France Pasquale Lisena', 'Alison Reboud', 'France RaphaÃ«l Troncy']\n",
      "['Daniel Ruffinelli', 'Samuel Broscheit', 'Rainer Gemulla']\n",
      "['Sanxing Chen', 'Xiaodong Liu', 'Jianfeng Gao', 'Jian Jiao', 'Ruofei Zhang', 'Yangfeng Ji']\n",
      "['Andreea Iana', 'Heiko Paulheim', 'Stefan Conrad']\n",
      "['Ashutosh Kumar Tiwari', 'Varma Sandeep', 'Nadimpalli']\n",
      "['Yushan Zhu', 'Wen Zhang', 'Mingyang Chen', 'Hui Chen', 'Xu Cheng', 'Wei Zhang', 'Huajun Chen']\n",
      "['Jan Philipp Portisch']\n",
      "['Dai Quoc Nguyen', 'Thanh Vu', 'Tu Dinh Nguyen', 'Dinh Phung']\n",
      "['Chengjin Xu', 'Mojtaba Nayyeri', 'Yung-Yu Chen', 'Jens Lehmann']\n",
      "['Zequn Sun', 'Muhao Chen', 'Wei Hu', 'Chengming Wang', 'Jian Dai', 'Wei Zhang']\n",
      "['Daniel Daza', 'Michael Cochez', 'Paul Groth']\n",
      "['Rajat Patel', 'Francis Ferraro']\n",
      "['Kai Wang', 'Yu Liu', 'Qian Ma', 'Quan Z Sheng']\n",
      "['Mojtaba Nayyeri', 'Chengjin Xu', 'Jens Lehmann', 'Sahar Vahdati']\n",
      "['Mingyang Chen', 'Wen Zhang', 'Zonggang Yuan', 'Yantao Jia', 'Huajun Chen']\n",
      "['Juan Li', 'Ruoxu Wang', 'Ningyu Zhang', 'Wen Zhang', 'Fan Yang', 'Huajun Chen']\n",
      "['Linlin Chao', 'Jianshan He', 'Taifeng Wang', 'Wei Chu']\n",
      "['Joseph Fisher', 'Arpit Mittal', 'Dave Palfrey', 'Christos Christodoulopoulos']\n",
      "['Sean Macavaney', 'Andrew Yates', 'Arman Cohan', 'Luca Soldaini', 'Kai Hui', 'Nazli Goharian', 'Ophir Frieder']\n",
      "['Kiran Ramnath', 'Mark Hasegawa-Johnson']\n",
      "['Angel Daruna', 'Mehul Gupta', 'Mohan Sridharan', 'Sonia Chernova']\n",
      "['Danushka Bollegala', 'Huda Hakami', 'Yuichi Yoshida', 'Ken-Ichi Kawarabayashi']\n",
      "['Aynur Guluzade', 'Endri Kacupaj', 'Maria Maleshkova']\n",
      "['Damai Dai', 'Hua Zheng', 'Zhifang Sui', 'Baobao Chang']\n",
      "['Kai Wang', 'Yu Liu', 'Dan Lin', 'Quan Z Sheng']\n",
      "['Alexander Renz-Wieland', 'Rainer Gemulla', 'Zoi Kaoudi', 'Volker Markl']\n",
      "['Chengjin Xu', 'Mojtaba Nayyeri', 'Sahar Vahdati', 'Jens Lehmann']\n",
      "['Xutan Peng', 'Guanyi Chen', 'Chenghua Lin', 'Mark Stevenson']\n",
      "['Saed Rezayi', 'Handong Zhao', 'Sungchul Kim', 'Ryan A Rossi', 'Nedim Lipka', 'Sheng Li']\n",
      "['Keyur Faldu', 'Embibe Amit Sheth', 'Prashant Kikani', 'Embibe Hemang', 'Akabari Embibe']\n",
      "['Angel Daruna', 'Lakshmi Nair', 'Weiyu Liu', 'Sonia Chernova']\n",
      "['Susana Nunes', 'Rita T Sousa', 'Catia Pesquita']\n",
      "['Stephen Bonner', 'Ian P Barrett', 'Cheng Ye', 'Rowan Swiers', 'Ola Engkvist', 'Charles Tapley Hoyt', 'William L Hamilton']\n",
      "['Cheng Ye', 'Rowan Swiers', 'Stephen Bonner', 'Ian P Barrett']\n",
      "['Jishnu Jaykumar', 'Ashish Sardana', 'Koustuv Sinha']\n",
      "['Sebastien Montella', 'Lina Rojas-Barahona', 'Johannes Heinecke']\n",
      "['Danushka Bollegala', 'Huda Hakami', 'Yuichi Yoshida', 'Ken-Ichi Kawarabayashi']\n",
      "['Katsuhiko Hayashi']\n",
      "['Chao Feng', 'Shi-Jie Wei']\n",
      "['Camille Bourgaux', 'Ana Ozaki', 'Jeff Z Pan']\n",
      "['Victor Caceres Chian', 'Marcel Hildebrandt', 'Thomas Runkler', 'Dominik Dold']\n",
      "['Daphna Keidar', 'Mian Zhong', 'Ce Zhang', 'Yash Raj Shrestha', 'Bibek Paudel']\n",
      "['Jia Guo', 'Stanley Kok']\n",
      "[]\n",
      "['Yihong Chen', 'Pasquale Minervini', 'Sebastian Riedel']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Michael R Douglas', 'Michael Simkin', 'Omri Ben-Eliezer', 'Tianqi Wu', 'Peter Chin', 'Trung V Dang', 'Andrew Wood']\n",
      "['Guanglin Niu', 'Yang Li', 'Chengguang Tang', 'Zhongkai Hu', 'Shibin Yang', 'Peng Li', 'Chengyu Wang', 'Hao Wang', 'Jian Sun']\n",
      "['Zachary Zhou', 'Jeffery Kline', 'Devin Conathan', 'Glenn Fung']\n",
      "['Valentina Beretta', 'Katarina Boland', 'Luke Lo Seen', 'SÃ©bastien Harispe', 'Konstantin Todorov', 'Andon Tchechmedjiev']\n",
      "['Hitarth Narvala', 'Graham Mcdonald', 'Iadh Ounis']\n",
      "['Mojtaba Nayyeri', 'Chengjin Xu', 'Franca Hoffmann', 'Mirza Mohtashim Alam', 'Jens Lehmann', 'Sahar Vahdati']\n",
      "['Onkar Pandit', 'Pascal Denis', 'Liva Ralaivola']\n",
      "['Nivranshu Pasricha', 'Mihael Arcan', 'Paul Buitelaar']\n",
      "['Peru Bhardwaj', 'John Kelleher', 'Luca Costabello', \"Declan O'sullivan\"]\n",
      "['Peru Bhardwaj', 'John Kelleher', 'Luca Costabello', \"Declan O'sullivan\"]\n",
      "['Archit Parnami', 'Mayuri Deshpande', 'Anant Kumar Mishra', 'Minwoo Lee']\n",
      "['Venkat Karthik', 'Ramanan', 'Balaraman Ravindran']\n",
      "[]\n",
      "['Mian Zhong', 'Tiancheng Hu', 'Ying Jiao', 'Shehzaad Dhuliawala', 'Bipin Singh']\n",
      "['Zhiyuan Zhang', 'Xiaoqian Liu', 'Yi Zhang', 'Qi Su', 'Xu Sun', 'Bin He']\n",
      "[]\n",
      "['Zhiping Luo', 'Wentao Xu', 'Weiqing Liu', 'Jiang Bian', 'Jian Yin', 'Yan Liu']\n",
      "['Erik B Myklebust', 'Ernesto JimÃ©nez-Ruiz', 'Jiaoyan Chen', 'Raoul Wolf', 'Erik Tollefsen']\n",
      "['Stephen Bonner', 'Ufuk Kirik', 'Ola Engkvist', 'Jian Tang', 'Ian P Barrett']\n",
      "['Diego Garcia-Olano', 'Yasumasa Onoe', 'Joydeep Ghosh']\n",
      "['Wen Zhang', 'Mingyang Chen', 'Liang Wang', 'Xiangwen Liu', 'Huajun 2021 Chen', 'Shumin Deng', 'Qiang Chen', 'Feiyu Xiong']\n",
      "['Peyman Baghershahi', 'Reshad Hosseini', 'Hadi Moradi']\n",
      "['Jiaoyan Chen', 'Yuxia Geng', 'Zhuo Chen', 'Jeff Z Pan', 'Yuan He', 'Wen Zhang', 'Ian Horrocks', 'Huajun Chen']\n",
      "['Christopher Lang', 'Alexander Braun', 'Abhinav Valada', 'Robert Bosch Gmbh']\n",
      "['Kai Wang', 'Yu Liu', 'Quan Z Sheng']\n",
      "['Peng Wang', 'Xin Xie', 'Xiaohan Wang', 'Ninyu Zhang']\n",
      "['Cristian Santini', 'Asefa Genet', 'Gesese', 'Silvio Peroni', 'Aldo Gangemi', 'Harald Sack', 'Mehwish Alam']\n",
      "['Zoi Kaoudi', 'Abelardo Carlos', 'Martinez Lorenzo', 'Volker Markl']\n",
      "['Baoxin Wang', 'Qingye Meng', 'Ziyue Wang', 'Honghong Zhao', 'Dayong Wu', 'Wanxiang Che', 'Shijin Wang', 'Zhigang Chen', 'Cong Liu']\n",
      "['Jiaoyan Chen', 'Yuan He', 'Yuxia Geng', 'Ernesto JimÃ©nez-Ruiz', 'Hang Dong', 'Ian Horrocks']\n",
      "['Daniel T Chang']\n",
      "['Rashad Al', 'Hasan Rony', 'Mirza Mohtashim Alam', 'Semab Ali', 'Jens Lehmann', 'Sahar Vahdati']\n",
      "['Jie Wang', 'Zhanqiu Zhang', 'Zhihao Shi', 'Jianyu Cai', 'Feng Wu', 'S â¢ Ji']\n",
      "[]\n",
      "['Wenjie Zheng', 'Wenxue Wang', 'Shu Zhao', 'Fulan Qian']\n",
      "['Caglar Demir', 'Julian Lienen', 'Axel-Cyrille Ngonga Ngomo']\n",
      "['Tara Safavi', 'Doug Downey', 'Tom Hope']\n",
      "['Satvik Garg', 'Dwaipayan Roy']\n",
      "['Bo Xiong', 'Shichao Zhu', 'Mojtaba Nayyeri', 'Chengjin Xu', 'Shirui Pan', 'Chuan Zhou', 'Steffen 2022 Staab']\n",
      "['Johanna JÃ¸sang', 'Ricardo GuimarÃ£es', 'Ana Ozaki']\n",
      "['Zongsheng Cao', 'Qianqian Xu', 'Zhiyong Yang', 'Xiaochun Cao', 'Qingming Huang']\n",
      "['Adrian Kochsiek', 'Fritz Niesel', 'Rainer Gemulla']\n",
      "['Jan Portisch']\n",
      "['Caglar Demir', 'Axel-Cyrille Ngonga']\n",
      "['Xindi Luo', 'Zequn Sun', 'Wei Hu']\n",
      "['Zhaoxuan Tan', 'Zilong Chen', 'Shangbin Feng', 'Qingyue Zhang', 'Qinghua Zheng', 'Jundong Li', 'Minnan Luo']\n",
      "['St Alexander Kalinowski']\n",
      "['Long Yu', 'Zhicong Luo', 'Huanyong Liu', 'Deng Lin', 'Hongzhu Li', 'Yafeng Deng', 'China Qihoo360']\n",
      "['Xin Xie', 'Zhoubo Li', 'Xiaohan Wang', 'Zekun Xi', 'Ningyu Zhang']\n",
      "[]\n",
      "['Jinfa Yang', 'Xianghua Ying', 'Yongjie Shi', 'Xin Tong', 'Ruibin Wang', 'Taiyan Chen', 'Bowei Xing']\n",
      "['Juergen Luettin', 'Sebastian Monka', 'Cory Henson', 'Lavdim Halilaj']\n",
      "['Marios Papachristou', 'Rishab Goel', 'Frank Portman', 'Matthew Miller', 'Rong Jin']\n",
      "['L Siddharth', 'Guangtong Li', 'Jianxi Luo']\n",
      "['Huiru Xiao', 'Xin Liu', 'Yangqiu Song', 'Ginny Y Wong', 'Simon See']\n",
      "['Dominik Filipiak', 'Anna Fensel', 'Agata Filipowska', 'A R T I C L E I N F O']\n",
      "['Denys Amore Bondarenko', 'Roger Ferrod', 'Luigi Di Caro']\n",
      "['Shraddha S Mane', 'Mukta A Paliwal', 'Dattaraj J Rao']\n",
      "['Xiong Liu']\n",
      "['Yinyu Lan', 'Shizhu He', 'Kang Liu', 'Jun Zhao']\n",
      "['Siyuan Cheng', 'Ningyu Zhang', 'Bozhong Tian', 'Xi Chen', 'Qingbin Liu', 'Huajun Chen']\n",
      "['Cosimo Gregucci', 'Mojtaba Nayyeri', 'Daniel HernÃ¡ndez', 'Steffen Staab']\n",
      "['Luis GalÃ¡rraga']\n",
      "['Tim Schwabe', 'Maribel Acosta']\n",
      "['Ciyuan Peng', 'Feng Xia', 'Mehdi Naseriparsa', 'Francesco Osborne']\n",
      "['Michelangelo Diligenti', 'Francesco Giannini', 'Stefano Fioravanti', 'Caterina Graziani', 'Moreno Falaschi', 'Giuseppe Marra']\n",
      "['Anders MÃ¸lmen HÃ¸st', 'Pierre Lison', 'Leon Moonen']\n",
      "['Ihab F Ilyas', 'J P Lacerda', 'Yunyao Li', 'Umar Farooq Minhas', 'Ali Mousavi', 'Jeffrey Pound', 'Theodoros Rekatsinas', 'Chiraag Sumanth']\n",
      "['Xinyu Fu', 'Irwin King']\n",
      "['Honggen Zhang', 'June Zhang', 'Igor Molybog']\n",
      "[]\n",
      "['Aryo Pradipta Gema', 'Dominik Grabarczyk', 'Wolf De Wulf', 'Piyush Borole', 'Javier Antonio Alfaro', 'Pasquale Minervini', 'Antonio Vergari', 'Ajitha Rajan']\n",
      "['Zequn Sun', 'Jiacheng Huang', 'Xiaozhou Xu', 'Qijin Chen', 'Weijun Ren', 'Wei Hu']\n",
      "['Davy Monticolo']\n",
      "['FrÃ©jus A A Laleye', 'LoÃ¯c Rakotoson', 'Sylvain Massip']\n",
      "['Rita T Sousa', 'Sara Silva', 'Catia Pesquita']\n",
      "['Zijie Huang', 'Daheng Wang', 'Binxuan Huang', 'Chenwei Zhang', 'Jingbo Shang', 'Yan Liang', 'Zhengyang Wang', 'Xian Li', 'Christos Faloutsos', 'Yizhou Sun', 'Wei Wang']\n",
      "['Ngoc Le', 'Luyen', 'Marie-HÃ©lÃ¨ne Abel', 'Philippe Gouspillou']\n",
      "['Rita T Sousa', 'Sara Silva', 'Catia Pesquita']\n",
      "['Zhuo Chen', 'Lingbing Guo', 'Yin Fang', 'Yichi Zhang', 'Jiaoyan Chen', 'Jeff Z Pan', 'Yangning Li', 'Huajun Chen', 'Wen Zhang']\n",
      "['Rita T Sousa', 'Sara Silva']\n",
      "['Haodi Ma', 'Yuejie Wang', 'Ali Sadeghian']\n",
      "['Jaya Chaturvedi', 'Tao Wang', 'Sumithra Velupillai', 'Robert Stewart', 'Angus Roberts']\n",
      "['Nancy Tyagi', 'Surjodeep Sarkar', 'Manas Gaur']\n",
      "['Jonathan Gabel Christiansen', 'Mathias Lykke Gammelgaard', 'Anders SÃ¸gaard']\n",
      "['Patryk Preisner', 'Heiko Paulheim']\n",
      "['Tom Van Sonsbeek', 'Xiantong Zhen', 'Marcel Worring']\n",
      "['Murthy V Devarakonda', 'Smita Mohanty', 'Rao Sunkishala', 'Nag Mallampalli', 'Xiong Liu']\n",
      "['Vasileios Baltatzis', 'Luca Costabello']\n",
      "['Diego Rincon-Yanez', 'Chahinez Ounoughi', 'Bassem Sellami', 'Tarmo Kalvet', 'Marek Tiits', 'Sabrina Senatore', 'Ben Yahia']\n",
      "[]\n",
      "['Rohith Teja Mittakola', 'Thomas Hassan']\n",
      "[]\n",
      "['Michael FÃ¤rber', 'David Lamprecht']\n",
      "['Zhijin Guo', 'Zhaozhen Xu', 'Martha Lewis', 'Nello Cristianini']\n",
      "['M Manzour', 'A Ballardini', 'R Izquierdo', 'M A Sotelo']\n",
      "['Shusaku Egami', 'Takanori Ugai', 'Masateru Oota', 'Kyoumoto Matsushita', 'Takahiro Kawamura', 'Kouji Kozaki', 'Ken Fukuda']\n",
      "['Tao Tang', 'Dafeng Wei', 'Zhengyu Jia', 'Tian Gao', 'Changwei Cai', 'Chengkai Hou', 'Peng Jia', 'Kun Zhan', 'Haiyang Sun', 'Jingchen Fan', 'Yixing Zhao', 'Fu Liu', 'Xiaodan Liang', 'Xianpeng Lang', 'Yang Wang']\n",
      "['Yihua Zhu', 'Hidetoshi Shimodaira']\n",
      "['Lorenzo Loconte', 'Nicola Di Mauro', 'Robert Peharz', 'Antonio Vergari']\n",
      "['Saptarshi Sengupta', 'Connor Heaton', 'Suhan Cui', 'Soumalya Sarkar', 'Prasenjit Mitra']\n",
      "['Victor Charpenay', 'Steven Schockaert']\n",
      "['Vid Kocijan', 'Myeongjun Erik Jang', 'Thomas Lukasiewicz']\n",
      "['Louis Mozart', 'Kamdem Teyou', 'Caglar Demir', 'Axel-Cyrille Ngonga']\n",
      "['JosÃ© Alberto BenÃ­tez-Andrades', 'MarÃ­a Teresa GarcÃ­a-OrdÃ¡s', 'Mayra Russo', 'Ahmad Sakor', 'Luis Daniel Fernandes Rotger', 'Maria-Esther Vidal']\n",
      "['Aditya Malusare', 'Vaneet Aggarwal']\n",
      "['Qi Hu', 'Weifeng Jiang', 'Haoran Li', 'Zihao Wang', 'Jiaxin Bai', 'Qianren Mao', 'Yangqiu Song', 'Jianxin Li']\n",
      "['Amber Yijia Zheng', 'Tong He', 'Yixuan Qiu', 'Minjie Wang', 'David Wipf']\n",
      "['Lena Zellinger', 'Andreas Stephan', 'Benjamin Roth']\n",
      "['Xindi Luo', 'Zequn Sun', 'Jing Zhao', 'Zhe Zhao', 'Wei Hu']\n",
      "['Xincan Feng', 'Zhi Qu', 'Yuchang Cheng', 'Taro Watanabe', 'Nobuhiro Yugami']\n",
      "['Mohamed Manzour Hussien', 'Angie Nataly Melo', 'Augusto Luis Ballardini', 'Carlota Salinas Maldonado', 'RubÃ©n Izquierdo', 'Miguel Ãngel', 'Sotelo Fellow']\n",
      "['Mohit Tomar', 'Abhisek Tiwari', 'Sriparna Saha']\n",
      "['Tianzhe Zhao', 'Jiaoyan Chen', 'Yanchi Ru', 'Qika Lin', 'Yuxia Geng', 'Jun Liu']\n",
      "['Christoph Wehner', 'Chrysa Iliopoulou', 'Ute Schmid', 'Tarek R Besold', 'Sony Ai Barcelona']\n",
      "['Yuqicheng Zhu', 'Nico Potyka', 'Bo Xiong', 'Trung-Kien Tran', 'Mojtaba Nayyeri', 'Evgeny Kharlamov', 'Steffen Staab']\n",
      "['Camille Bourgaux', 'Ricardo GuimarÃ£es', 'Raoul Koudijs', 'Victor Lacerda', 'Ana Ozaki']\n",
      "['Sevinj Teymurova', 'Ernesto JimÃ©nez-Ruiz', 'Tillman Weyde', 'Jiaoyan Chen']\n",
      "['Yuqicheng Zhu', 'Nico Potyka', 'Jiarong Pan', 'Bo Xiong', 'Yunjie He', 'Evgeny Kharlamov', 'Steffen Staab']\n",
      "['Yuqicheng Zhu', 'Nico Potyka', 'Mojtaba Nayyeri', 'Bo Xiong', 'Yunjie He', 'Evgeny Kharlamov', 'Steffen Staab']\n",
      "['Christos Theodoropoulos', 'Natasha Mulligan', 'Joao Bettencourt-Silva']\n",
      "['Hui Yang', 'Jiaoyan Chen', 'Uli Sattler']\n",
      "['Alex Clay', 'Ernesto JimÃ©nez-Ruiz']\n",
      "['Hongkuan Zhou', 'Lavdim Halilaj', 'Sebastian Monka', 'Stefan Schmid', 'Yuqicheng Zhu', 'Bo Xiong', 'Steffen Staab']\n",
      "['Guanglin Niu']\n",
      "['Arnab Sharma', \"N ' Dah\", 'Jean Kouagou', 'Axel-Cyrille Ngonga']\n",
      "['Durgesh Nandini', 'Simon BlÃ¶thner', 'Mirco Schoenfeld', 'Mario Larch']\n",
      "['Lucian Li', 'Eryclis Silva']\n",
      "['Gerard Pons', 'Besim Bilalli', 'Anna Queralt']\n",
      "['Laura Cabello', 'Carmen Martin-Turrero', 'Uchenna Akujuobi', 'Anders SÃ¸gaard', 'Carlos Bobed']\n",
      "['Viktoriia Chekalina', 'Anton Razzhigaev', 'Elizaveta Goncharova', 'Andrey Kuznetsov']\n",
      "['Tanaji Shubham', 'Rony Kakde', 'Jasashwi Mitra', 'Manoj Mandal', 'Kumar Tiwari']\n",
      "['Davide Riva', 'Cristina Rossetti']\n",
      "['Jeffrey Sardina', 'John D Kelleher', 'Rd Declan', \"O ' Sullivan\"]\n",
      "['Jeffrey Sardina', 'John D Kelleher', \"Declan O'sullivan\"]\n",
      "[]\n",
      "['Yuhe Bai', 'Hubert Naacke', 'Camelia Constantin']\n",
      "['Dong Hyun Jeon', 'Wenbo Sun', 'Houbing Herbert Song', 'Dongfang Liu', 'Velasquez Alvaro', 'Yixin Chloe Xie', 'Shuteng Niu']\n",
      "['M Manzour', 'A Ballardini', 'R Izquierdo', 'M A Sotelo']\n",
      "['Ioannis Reklos', 'Jacopo De Berardinis', 'Elena Simperl', 'Albert Mero Ão-Pe Ãuela', 'College London']\n",
      "['Md Saidul', 'Hoque Anik', 'Ariful Azad']\n",
      "['Shiqi Wang', 'Zhibo Zhang', 'Libing Fang', 'Cam-Tu Nguyen', 'Wenzhong Li']\n",
      "['Shusaku Egami', 'Kyoumoto Matsushita', 'Takanori Ugai', 'Ken Fukuda']\n",
      "['Joel Barmettler']\n",
      "['Catarina Canastra', 'CÃ¡tia Pesquita']\n",
      "['Yuqicheng Zhu', 'Daniel HernÃ¡ndez', 'Yuan He', 'Zifeng Ding', 'Bo Xiong', 'Evgeny Kharlamov', 'Steffen Staab']\n"
     ]
    }
   ],
   "source": [
    "current_dir = Path(\".\")\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "authors_grobid = []\n",
    "\n",
    "for paper in papers:\n",
    "    pdf_path = str(current_dir / paper[\"Local PDF Path\"])\n",
    "    authors = grobid.extract_authors_from_pdf(pdf_path)\n",
    "    authors_grobid.append(authors)\n",
    "    print(authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autor_grobid_recalls = []\n",
    "autor_grobid_precisions = []\n",
    "autor_grobid_f1s = []\n",
    "\n",
    "\n",
    "for i in range(len(authors_grobid)):\n",
    "    reference = references[0][i]\n",
    "    prediction = authors_grobid[i]\n",
    "\n",
    "\n",
    "    ref_text = [name.strip() for name in reference.split(',')]\n",
    "    pred_text = prediction\n",
    "\n",
    "    if len(ref_text) == 0:\n",
    "        recall = 1\n",
    "        precision = 1\n",
    "    elif len(pred_text) == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    else:\n",
    "        # For each reference entity, find the max similarity to predicted entities\n",
    "        max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "        # Apply threshold\n",
    "        threshold = 0.6\n",
    "        num_matched = (max_similarities >= threshold).sum().item()\n",
    "        recall = num_matched / len(ref_text) \n",
    "        precision = num_matched / len(pred_text)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        autor_grobid_recalls.append(recall)\n",
    "        autor_grobid_precisions.append(precision)\n",
    "        autor_grobid_f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Author Recall: 0.9733\n",
      "Mean Author Precision: 0.9778\n",
      "Mean Author F1: 0.9669\n"
     ]
    }
   ],
   "source": [
    "average_autor_grobid_recall = sum(autor_grobid_recalls) / len(autor_grobid_recalls)\n",
    "average_autor_grobid_precision = sum(autor_grobid_precisions) / len(autor_grobid_precisions)\n",
    "average_autor_grobid_f1 = sum(autor_grobid_f1s) / len(autor_grobid_f1s)\n",
    "print(f\"Mean Author Recall: {average_autor_grobid_recall:.4f}\")\n",
    "print(f\"Mean Author Precision: {average_autor_grobid_precision:.4f}\")\n",
    "print(f\"Mean Author F1: {average_autor_grobid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "pdf_path = str(current_dir /papers_list[11]['Local PDF Path'])\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "raw_text = tei_to_full_raw_text(tei, remove_ref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "dataset_mentions = []\n",
    "with open('./datasets.json', \"r\") as file:\n",
    "    dataset_mentions = json.load(file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Reference: ['ARC (AI2 Reasoning Challenge)', 'SNLI', 'SQuAD']\n",
      "Predicted datasets: ['ARC Challenge Set', 'ARC Challenge', 'AI2 Reasoning Challenge (ARC', 'AI2 Reasoning Challenge (ARC)']\n",
      "Deduplicated predicted datasets: ['ARC Challenge Set', 'AI2 Reasoning Challenge (ARC']\n",
      "recall: 0.3333333333333333\n",
      "precision: 0.5\n",
      "f1: 0.4\n",
      "GROBID server is up and running\n",
      "Reference: ['FB15k-237', 'FB15k']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Adversarial Contrastive Estimation\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Predicted datasets: ['FB15k-237', 'KBGAN', 'DISTMULT', 'WN18', 'WN18RR']\n",
      "Deduplicated predicted datasets: ['FB15k-237', 'KBGAN', 'DISTMULT', 'WN18']\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "GROBID server is up and running\n",
      "Reference: ['YAGO', 'YAGO3-10', 'UMLS', 'WN18RR', 'FB15k', 'FB15k-237', 'WN18']\n",
      "Predicted datasets: ['FB15k datasets', 'WN', 'WN18', 'FB15k']\n",
      "Deduplicated predicted datasets: ['FB15k datasets', 'WN', 'WN18', 'FB15k']\n",
      "recall: 0.5714285714285714\n",
      "precision: 1.0\n",
      "f1: 0.7272727272727273\n",
      "GROBID server is up and running\n",
      "Reference: ['Visual Genome', 'FB15k', 'ImageNet']\n",
      "Predicted datasets: ['ImageGraph']\n",
      "Deduplicated predicted datasets: ['ImageGraph']\n",
      "recall: 0.3333333333333333\n",
      "precision: 1.0\n",
      "f1: 0.5\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "GROBID server is up and running\n",
      "Reference: ['FB15k', 'NELL', 'WN18']\n",
      "Predicted datasets: ['FB', 'WN', 'FB15k']\n",
      "Deduplicated predicted datasets: ['FB', 'WN', 'FB15k']\n",
      "recall: 0.6666666666666666\n",
      "precision: 0.6666666666666666\n",
      "f1: 0.6666666666666666\n",
      "GROBID server is up and running\n",
      "Reference: ['NELL', 'NELL-995']\n",
      "Predicted datasets: ['Never-Ending Language Learning datasets', 'Freebase']\n",
      "Deduplicated predicted datasets: ['Never-Ending Language Learning datasets', 'Freebase']\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k', 'WikiMovies']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "Reference: ['DBP15K', 'MMKG']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Embedding Models for Episodic Knowledge Graphs\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Predicted datasets: ['HypER']\n",
      "Deduplicated predicted datasets: ['HypER']\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Entity Hierarchy Embedding\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k', 'WN18RR']\n",
      "Predicted datasets: ['KGC benchmark datasets']\n",
      "Deduplicated predicted datasets: ['KGC benchmark datasets']\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Mean Recall: 0.2234\n",
      "Mean Precision: 0.3205\n",
      "Mean F1: 0.2534\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:30]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    abstract = extract_abstract(tei)\n",
    "\n",
    "\n",
    "    paper_title =  paper['Title'] \n",
    "    dataset_titles = []\n",
    "    for data in dataset_mentions:\n",
    "        dataset_titles.append(data)\n",
    "    reference = paper['Datasets']\n",
    "    ref_text = [item[0] for item in reference]\n",
    "    if len(ref_text) == 0:\n",
    "        print(f\"No reference datasets found for paper: {paper_title}\")\n",
    "        continue\n",
    "    if len(ref_text) > 1:\n",
    "        print(f\"Reference: {ref_text}\")\n",
    "        #print(f\"Reference: {ref_text}\")\n",
    "\n",
    "        idx = closest_string_index(paper_title, dataset_titles)\n",
    "        pred_text = dataset_mentions[dataset_titles[idx]]\n",
    "        \n",
    "        # if the pred_text is not in the best match section, then we don't have a match\n",
    "        def filter_datasets_in_text(text, dataset_names):\n",
    "            text_lower = text.lower()\n",
    "            return [name for name in dataset_names if name.lower() in text_lower]\n",
    "        pred_datasets = filter_datasets_in_text(abstract, pred_text)\n",
    "        print(f\"Predicted datasets: {pred_datasets}\")\n",
    "        pred_datasets = deduplicate_fuzzy(pred_datasets, threshold=80)\n",
    "        print(f\"Deduplicated predicted datasets: {pred_datasets}\")\n",
    "        #print(f\"Predicted datasets: {pred_datasets}\")\n",
    "        if len(pred_datasets) == 0:\n",
    "            recall = 0\n",
    "            precision = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "\n",
    "            # For each reference entity, find the max similarity to predicted entities\n",
    "            max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "            # Apply threshold\n",
    "            threshold = 0.6\n",
    "            num_matched = (max_similarities >= threshold).sum().item()\n",
    "                \n",
    "            tp = num_matched\n",
    "            fn = len(ref_text) - tp         # false negatives\n",
    "            fp = len(pred_datasets) - tp    # false positives\n",
    "\n",
    "            # helper to avoid zero-division warnings Ã  la scikit-learn\n",
    "            def safe_div(num, denom):\n",
    "                return num / denom if denom else 0.0        # or np.nan\n",
    "\n",
    "            precision = safe_div(tp, tp + fp)\n",
    "            recall    = safe_div(tp, tp + fn)\n",
    "            f1        = safe_div(2 * precision * recall, precision + recall)\n",
    "            \n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        print(f\"recall: {recall}\")\n",
    "        print(f\"precision: {precision}\")\n",
    "        print(f\"f1: {f1}\")\n",
    "mean_recall = sum(recalls) / len(recalls)\n",
    "mean_precision = sum(precisions) / len(precisions)\n",
    "mean_f1 = sum(f1s) / len(f1s)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")    \n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean F1: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Reference: ['ARC (AI2 Reasoning Challenge)', 'SNLI', 'SQuAD']\n",
      "Predicted datasets: ['ARC Challenge Set', 'ARC Challenge', 'ARC Corpus']\n",
      "Deduplicated predicted datasets: ['ARC Challenge Set', 'ARC Corpus']\n",
      "recall: 0.3333333333333333\n",
      "precision: 0.5\n",
      "f1: 0.4\n",
      "GROBID server is up and running\n",
      "Reference: ['FB15k-237', 'FB15k']\n",
      "Predicted datasets: ['15k', 'YAGO3-10', 'Freebase', 'FB15k-237', 'MTKGNN', 'YAGO3 knowledge graph', 'FB15k']\n",
      "Deduplicated predicted datasets: ['15k', 'YAGO3-10', 'Freebase', 'FB15k-237', 'MTKGNN', 'YAGO3 knowledge graph', 'FB15k']\n",
      "recall: 1.0\n",
      "precision: 0.2857142857142857\n",
      "f1: 0.4444444444444445\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Adversarial Contrastive Estimation\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Predicted datasets: ['FB15k-237', 'KBGAN', 'WN18 dataset', 'DISTMULT', 'WN18', 'WN18RR']\n",
      "Deduplicated predicted datasets: ['FB15k-237', 'KBGAN', 'WN18 dataset', 'DISTMULT', 'WN18']\n",
      "recall: 1.0\n",
      "precision: 0.8\n",
      "f1: 0.888888888888889\n",
      "GROBID server is up and running\n",
      "Reference: ['YAGO', 'YAGO3-10', 'UMLS', 'WN18RR', 'FB15k', 'FB15k-237', 'WN18']\n",
      "Predicted datasets: ['YAGO3-10', 'WN', 'Countries', 'Countries dataset', 'WN18', 'FB15k']\n",
      "Deduplicated predicted datasets: ['YAGO3-10', 'WN', 'Countries', 'Countries dataset', 'WN18', 'FB15k']\n",
      "recall: 0.8571428571428571\n",
      "precision: 1.0\n",
      "f1: 0.923076923076923\n",
      "GROBID server is up and running\n",
      "Reference: ['Visual Genome', 'FB15k', 'ImageNet']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "GROBID server is up and running\n",
      "Reference: ['FB15k', 'NELL', 'WN18']\n",
      "Predicted datasets: ['WordNet data', 'FB', 'Freebase', 'wordnet', 'WN', 'WN18 dataset', 'RESCAL', 'WordNet', 'FB15k']\n",
      "Deduplicated predicted datasets: ['WordNet data', 'FB', 'Freebase', 'wordnet', 'WN', 'WN18 dataset', 'RESCAL', 'WordNet', 'FB15k']\n",
      "recall: 0.6666666666666666\n",
      "precision: 0.2222222222222222\n",
      "f1: 0.3333333333333333\n",
      "GROBID server is up and running\n",
      "Reference: ['NELL', 'NELL-995']\n",
      "Predicted datasets: ['NELL dataset', 'NELL']\n",
      "Deduplicated predicted datasets: ['NELL dataset', 'NELL']\n",
      "recall: 1.0\n",
      "precision: 1.0\n",
      "f1: 1.0\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k', 'WikiMovies']\n",
      "Predicted datasets: ['WN18 dataset', 'WordNet']\n",
      "Deduplicated predicted datasets: ['WN18 dataset', 'WordNet']\n",
      "recall: 0.3333333333333333\n",
      "precision: 0.5\n",
      "f1: 0.4\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Predicted datasets: []\n",
      "Deduplicated predicted datasets: []\n",
      "recall: 0\n",
      "precision: 0\n",
      "f1: 0\n",
      "GROBID server is up and running\n",
      "Reference: ['DBP15K', 'MMKG']\n",
      "Predicted datasets: ['ConceptNet', 'CN3l', 'WK']\n",
      "Deduplicated predicted datasets: ['ConceptNet', 'CN3l', 'WK']\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Embedding Models for Episodic Knowledge Graphs\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Predicted datasets: ['HypER']\n",
      "Deduplicated predicted datasets: ['HypER']\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Predicted datasets: ['FB15K', 'FB15K benchmarks', 'NELL165', 'NELL165 dataset', 'NELL', 'FB15K dataset']\n",
      "Deduplicated predicted datasets: ['FB15K', 'FB15K benchmarks', 'NELL165', 'NELL165 dataset', 'NELL', 'FB15K dataset']\n",
      "recall: 0.5\n",
      "precision: 0.16666666666666666\n",
      "f1: 0.25\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Entity Hierarchy Embedding\n",
      "GROBID server is up and running\n",
      "Reference: ['WN18', 'FB15k', 'WN18RR']\n",
      "Predicted datasets: ['FB15k dataset', 'FB15k-237', 'Freebase-music data 6', 'WN18', 'WN18RR', 'FB15k']\n",
      "Deduplicated predicted datasets: ['FB15k dataset', 'FB15k-237', 'Freebase-music data 6', 'WN18', 'FB15k']\n",
      "recall: 1.0\n",
      "precision: 0.6\n",
      "f1: 0.7499999999999999\n",
      "GROBID server is up and running\n",
      "No reference datasets found for paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Mean Recall: 0.5147\n",
      "Mean Precision: 0.3904\n",
      "Mean F1: 0.4146\n"
     ]
    }
   ],
   "source": [
    "# get only the dataset that appears in the section text we want\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "for paper in papers_list[0:30]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    client = GrobidClient(config_path=\"./Grobid/config.json\")       # uses defaults: localhost:8070\n",
    "\n",
    "    tei_xml = client.process_pdf(\n",
    "        service=\"processFulltextDocument\",\n",
    "        pdf_file=pdf_path,\n",
    "        generateIDs        = False,   # was optional, now required\n",
    "        consolidate_header = True,  # same default as server\n",
    "        consolidate_citations = False,\n",
    "        include_raw_citations   = False,\n",
    "        include_raw_affiliations = False,\n",
    "        segment_sentences   = False,\n",
    "        tei_coordinates     = False\n",
    "    )\n",
    "\n",
    "    _, status, tei = tei_xml\n",
    "\n",
    "    sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"]) # get the most similar sections to the queries\n",
    "    best_match_section, best_score = ranked_sections[0]\n",
    "    #print(f\"Best matching section: {best_match_section} with score {best_score:.4f}\")\n",
    "    best_match_section_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    paper_title =  paper['Title'] \n",
    "    dataset_titles = []\n",
    "    for data in dataset_mentions:\n",
    "        dataset_titles.append(data)\n",
    "    reference = paper['Datasets']\n",
    "    ref_text = [item[0] for item in reference]\n",
    "    if len(ref_text) == 0:\n",
    "        print(f\"No reference datasets found for paper: {paper_title}\")\n",
    "        continue\n",
    "    if len(ref_text) > 1:\n",
    "        print(f\"Reference: {ref_text}\")\n",
    "        #print(f\"Reference: {ref_text}\")\n",
    "\n",
    "        idx = closest_string_index(paper_title, dataset_titles)\n",
    "        pred_text = dataset_mentions[dataset_titles[idx]]\n",
    "        \n",
    "        # if the pred_text is not in the best match section, then we don't have a match\n",
    "        def filter_datasets_in_text(text, dataset_names):\n",
    "            text_lower = text.lower()\n",
    "            return [name for name in dataset_names if name.lower() in text_lower]\n",
    "        pred_datasets = filter_datasets_in_text(best_match_section_text, pred_text)\n",
    "        print(f\"Predicted datasets: {pred_datasets}\")\n",
    "        pred_datasets = deduplicate_fuzzy(pred_datasets, threshold=80)\n",
    "        print(f\"Deduplicated predicted datasets: {pred_datasets}\")\n",
    "        #print(f\"Predicted datasets: {pred_datasets}\")\n",
    "        if len(pred_datasets) == 0:\n",
    "            recall = 0\n",
    "            precision = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "\n",
    "            # For each reference entity, find the max similarity to predicted entities\n",
    "            max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "            # Apply threshold\n",
    "            threshold = 0.6\n",
    "            num_matched = (max_similarities >= threshold).sum().item()\n",
    "                \n",
    "            tp = num_matched\n",
    "            fn = len(ref_text) - tp         # false negatives\n",
    "            fp = len(pred_datasets) - tp    # false positives\n",
    "\n",
    "            # helper to avoid zero-division warnings Ã  la scikit-learn\n",
    "            def safe_div(num, denom):\n",
    "                return num / denom if denom else 0.0        # or np.nan\n",
    "\n",
    "            precision = safe_div(tp, tp + fp)\n",
    "            recall    = safe_div(tp, tp + fn)\n",
    "            f1        = safe_div(2 * precision * recall, precision + recall)\n",
    "            \n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1s.append(f1)\n",
    "        print(f\"recall: {recall}\")\n",
    "        print(f\"precision: {precision}\")\n",
    "        print(f\"f1: {f1}\")\n",
    "mean_recall = sum(recalls) / len(recalls)\n",
    "mean_precision = sum(precisions) / len(precisions)\n",
    "mean_f1 = sum(f1s) / len(f1s)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")    \n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean F1: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings: TEI is well-formed.\n",
      "TEI file saved to: /mnt/c/Users/Che/GAP-KGE/tei_sections/KG2_Learning_to_Reason_Science_Exam_Questions_with_Contextual_Knowledge_Graph_Embeddings.xml\n",
      "GROBID server is up and running\n",
      "Incorporating Literals into Knowledge Graph Embeddings: TEI is well-formed.\n",
      "TEI file saved to: /mnt/c/Users/Che/GAP-KGE/tei_sections/Incorporating_Literals_into_Knowledge_Graph_Embeddings.xml\n"
     ]
    }
   ],
   "source": [
    "# get best match section tei\n",
    "\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:2]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "    if status != 200:\n",
    "        print(f\"Error processing {pdf_path}: GROBID returned status {status}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        etree.fromstring(tei.encode(\"utf-8\"))  # or etree.XML(tei)\n",
    "        print(f\"{paper['Title']}: TEI is well-formed.\")\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"{paper['Title']}: TEI is malformed! Error: {e}\")\n",
    "\n",
    "\n",
    "    sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"]) # get the most similar sections to the queries\n",
    "    best_match_section, best_score = ranked_sections[0]\n",
    "    #print(f\"Best matching section: {best_match_section} with score {best_score:.4f}\")\n",
    "    best_match_section_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # save the tei in a file inside a folder \n",
    "    tei_folder = current_dir / \"tei_sections\"\n",
    "    tei_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    safe_title = re.sub(r'[^a-zA-Z0-9_\\- ]+', '', paper['Title']).strip().replace(' ', '_')\n",
    "    tei_file_path = tei_folder / f\"{safe_title}.xml\"\n",
    "\n",
    "    with open(tei_file_path, \"w\", encoding=\"utf-8\") as tei_file:\n",
    "        tei_file.write(tei)\n",
    "    print(f\"TEI file saved to: {tei_file_path}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings',\n",
       " 'Authors': 'Hanjun Dai, Le Song, Kamil Toraman, Yuyu Zhang',\n",
       " 'Abstract': 'The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question\\nanswering (QA) has been recently released. ARC only contains natural science\\nquestions authored for human exams, which are hard to answer and require\\nadvanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art\\nQA systems fail to significantly outperform random baseline, reflecting the\\ndifficult nature of this task. In this paper, we propose a novel framework for\\nanswering science exam questions, which mimics human solving process in an\\nopen-book exam. To address the reasoning challenge, we construct contextual\\nknowledge graphs respectively for the question itself and supporting sentences.\\nOur model learns to reason with neural embeddings of both knowledge graphs.\\nExperiments on the ARC Challenge Set show that our model outperforms the\\nprevious state-of-the-art QA systems.',\n",
       " 'PDF URL': 'http://arxiv.org/pdf/1805.12393v1.pdf',\n",
       " 'Datasets': [['ARC (AI2 Reasoning Challenge)'], ['SNLI'], ['SQuAD']],\n",
       " 'Tasks': [['ARC'],\n",
       "  ['Question Answering'],\n",
       "  ['Knowledge Graphs'],\n",
       "  ['AI2 Reasoning Challenge'],\n",
       "  ['Knowledge Graph Embeddings']],\n",
       " 'Local PDF Path': 'papers_pdfs/KG^2:_Learning_to_Reason_Science_Exam_Questions_with_Contextual_Knowledge_Graph_Embeddings.pdf'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiments'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_match_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def normalize_title(title):\n",
    "    # Normalize by stripping case and numbers like \"2 RELATED WORK\" â \"related work\"\n",
    "    return re.sub(r\"^\\d+\\.?\\s*\", \"\", title.strip().lower())\n",
    "\n",
    "\n",
    "def keep_only_target_section(tei_xml: str, target_title: str) -> str:\n",
    "    soup = BeautifulSoup(tei_xml, \"xml\")\n",
    "\n",
    "    norm_target = normalize_title(target_title)\n",
    "\n",
    "    body = soup.find(\"body\")\n",
    "    if body is None:\n",
    "        raise ValueError(\"TEI does not contain a <body> section.\")\n",
    "\n",
    "    all_divs = body.find_all(\"div\", recursive=False)\n",
    "\n",
    "    collected_divs = []\n",
    "    capture = False\n",
    "    target_prefix = None\n",
    "\n",
    "    for div in all_divs:\n",
    "        head = div.find(\"head\")\n",
    "        if not head:\n",
    "            continue\n",
    "\n",
    "        head_text = head.get_text()\n",
    "        norm_head = normalize_title(head_text)\n",
    "        n_attr = head.get(\"n\")\n",
    "\n",
    "        # Detect start of target section\n",
    "        if not capture and norm_head == norm_target:\n",
    "            collected_divs.append(div)\n",
    "            capture = True\n",
    "            # Get the numeric prefix for nested matching (e.g., \"5\" from \"5.1\")\n",
    "            if n_attr:\n",
    "                target_prefix = n_attr.split(\".\")[0]\n",
    "            continue\n",
    "\n",
    "        # If capturing, collect subsections like \"5.1\", \"5.2\"\n",
    "        if capture:\n",
    "            if n_attr and target_prefix and n_attr.startswith(target_prefix + \".\"):\n",
    "                collected_divs.append(div)\n",
    "            else:\n",
    "                break  # Stop capturing once outside the target section\n",
    "\n",
    "    if not collected_divs:\n",
    "        raise ValueError(f\"No section found with title matching '{target_title}'.\")\n",
    "\n",
    "    body.clear()\n",
    "    for div in collected_divs:\n",
    "        body.append(div)\n",
    "\n",
    "    return soup.prettify()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to output_sections/experiments_section.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_xml = keep_only_target_section(tei, best_match_section)\n",
    "\n",
    "# Define output directory and file\n",
    "output_dir = Path(\"output_sections\")  # use your desired path here\n",
    "output_file = output_dir / \"experiments_section.tei.xml\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write the result to a file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(filtered_xml)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<TEI xml:space=\"preserve\" xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd\">\\n <teiHeader xml:lang=\"en\">\\n  <fileDesc>\\n   <titleStmt>\\n    <title level=\"a\" type=\"main\">\\n     KG 2 : Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\\n    </title>\\n   </titleStmt>\\n   <publicationStmt>\\n    <publisher/>\\n    <availability status=\"unknown\">\\n     <licence/>\\n    </availability>\\n    <date type=\"published\" when=\"2018-05-31\">\\n     31 May 2018\\n    </date>\\n   </publicationStmt>\\n   <sourceDesc>\\n    <biblStruct>\\n     <analytic>\\n      <author>\\n       <persName>\\n        <forename type=\"first\">\\n         Yuyu\\n        </forename>\\n        <surname>\\n         Zhang\\n        </surname>\\n       </persName>\\n       <email>\\n        yuyu.zhang@cc.gatech.edu\\n       </email>\\n       <affiliation key=\"aff0\">\\n        <orgName type=\"department\">\\n         College of Computing\\n        </orgName>\\n        <address>\\n         <country>\\n          Georgia Institute of Technology\\n         </country>\\n        </address>\\n       </affiliation>\\n      </author>\\n      <author>\\n       <persName>\\n        <forename type=\"first\">\\n         Hanjun\\n        </forename>\\n        <surname>\\n         Dai\\n        </surname>\\n       </persName>\\n       <email>\\n        hanjun.dai@cc.gatech.edu\\n       </email>\\n       <affiliation key=\"aff0\">\\n        <orgName type=\"department\">\\n         College of Computing\\n        </orgName>\\n        <address>\\n         <country>\\n          Georgia Institute of Technology\\n         </country>\\n        </address>\\n       </affiliation>\\n      </author>\\n      <author>\\n       <persName>\\n        <forename type=\"first\">\\n         Toraman\\n        </forename>\\n        <surname>\\n         Kamil\\n        </surname>\\n       </persName>\\n       <affiliation key=\"aff1\">\\n        <orgName type=\"institution\">\\n         Korea Advanced Institute of Science and Technology\\n        </orgName>\\n       </affiliation>\\n      </author>\\n      <author>\\n       <persName>\\n        <forename type=\"first\">\\n         Le\\n        </forename>\\n        <surname>\\n         Song\\n        </surname>\\n       </persName>\\n       <email>\\n        lsong@cc.gatech.edu\\n       </email>\\n       <affiliation key=\"aff0\">\\n        <orgName type=\"department\">\\n         College of Computing\\n        </orgName>\\n        <address>\\n         <country>\\n          Georgia Institute of Technology\\n         </country>\\n        </address>\\n       </affiliation>\\n      </author>\\n      <title level=\"a\" type=\"main\">\\n       KG 2 : Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\\n      </title>\\n     </analytic>\\n     <monogr>\\n      <imprint>\\n       <date type=\"published\" when=\"2018-05-31\">\\n        31 May 2018\\n       </date>\\n      </imprint>\\n     </monogr>\\n     <idno type=\"MD5\">\\n      177559F076614A6214436678E9CC6581\\n     </idno>\\n     <idno type=\"arXiv\">\\n      arXiv:1805.12393v1[cs.LG]\\n     </idno>\\n    </biblStruct>\\n   </sourceDesc>\\n  </fileDesc>\\n  <encodingDesc>\\n   <appInfo>\\n    <application ident=\"GROBID\" version=\"0.8.0\" when=\"2025-06-05T11:01+0000\">\\n     <desc>\\n      GROBID - A machine learning software for extracting information from scholarly documents\\n     </desc>\\n     <ref target=\"https://github.com/kermitt2/grobid\"/>\\n    </application>\\n   </appInfo>\\n  </encodingDesc>\\n  <profileDesc>\\n   <abstract>\\n    <div xmlns=\"http://www.tei-c.org/ns/1.0\">\\n     <p>\\n      The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question answering (QA) has been recently released. ARC only contains natural science questions authored for human exams, which are hard to answer and require advanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art QA systems fail to significantly outperform random baseline, reflecting the difficult nature of this task. In this paper, we propose a novel framework for answering science exam questions, which mimics human solving process in an open-book exam. To address the reasoning challenge, we construct contextual knowledge graphs respectively for the question itself and supporting sentences. Our model learns to reason with neural embeddings of both knowledge graphs. Experiments on the ARC Challenge Set show that our model outperforms the previous state-of-the-art QA systems.\\n     </p>\\n    </div>\\n   </abstract>\\n  </profileDesc>\\n </teiHeader>\\n <text xml:lang=\"en\">\\n  <body>\\n   <div xmlns=\"http://www.tei-c.org/ns/1.0\">\\n    <head n=\"5\">\\n     Experiments\\n    </head>\\n    <p>\\n     We compare our method against several recently published baseline models, including state-of-theart neural models from the well-known SQuAD and SNLI tasks.\\n    </p>\\n   </div>\\n  </body>\\n  <back>\\n   <div type=\"annex\">\\n    <div xmlns=\"http://www.tei-c.org/ns/1.0\">\\n     <head>\\n      Appendix A Examples of Knowledge Graphs\\n     </head>\\n     <p>\\n      To illustrate how we construct knowledge graphs from hypothesis and supporting sentences, here we present some examples.\\n     </p>\\n     <p>\\n      We first show a relatively simple example in Figure\\n      <ref type=\"figure\">\\n       2\\n      </ref>\\n      . We see a pair of hypothesis and supporting graphs. The hypothesis is \"seed of oak comes from fruit\", as shown in Figure\\n      <ref type=\"figure\">\\n       2a\\n      </ref>\\n      . Note that the verb \"comes\" is lemmatized and becomes \"come\" in the graph. The supporting knowledge graph is plotted in Figure\\n      <ref type=\"figure\">\\n       2b\\n      </ref>\\n      , where we obtain knowledge including \"fruit contains seed \", \"fruit is part of tree\", and \"oak is kind of tree\". With the supporting knowledge graph, we should be able to infer that the hypothesis is true.\\n     </p>\\n    </div>\\n   </div>\\n   <div type=\"references\">\\n    <listBibl>\\n     <biblStruct xml:id=\"b0\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Open information extraction from the web\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Michele\\n         </forename>\\n         <surname>\\n          Banko\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          J\\n         </forename>\\n         <surname>\\n          Michael\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Stephen\\n         </forename>\\n         <surname>\\n          Cafarella\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Matthew\\n         </forename>\\n         <surname>\\n          Soderland\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Broadhead\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        IJCAI\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2007\">\\n         2007\\n        </date>\\n        <biblScope unit=\"volume\">\\n         7\\n        </biblScope>\\n        <biblScope from=\"2670\" to=\"2676\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b1\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Translating embeddings for modeling multi-relational data\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Antoine\\n         </forename>\\n         <surname>\\n          Bordes\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Nicolas\\n         </forename>\\n         <surname>\\n          Usunier\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Alberto\\n         </forename>\\n         <surname>\\n          Garcia-Duran\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Jason\\n         </forename>\\n         <surname>\\n          Weston\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oksana\\n         </forename>\\n         <surname>\\n          Yakhnenko\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Advances in neural information processing systems\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2013\">\\n         2013\\n        </date>\\n        <biblScope from=\"2787\" to=\"2795\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b2\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        A large annotated corpus for learning natural language inference\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Gabor\\n         </forename>\\n         <surname>\\n          Samuel R Bowman\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Christopher\\n         </forename>\\n         <surname>\\n          Angeli\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Christopher\\n         </forename>\\n         <forename type=\"middle\">\\n          D\\n         </forename>\\n         <surname>\\n          Potts\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <surname>\\n          Manning\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1508.05326\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2015\">\\n         2015\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b3\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        An analysis of open information extraction based on semantic role labeling\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Janara\\n         </forename>\\n         <surname>\\n          Christensen\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Stephen\\n         </forename>\\n         <surname>\\n          Soderland\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Proceedings of the sixth international conference on Knowledge capture\\n       </title>\\n       <meeting>\\n        the sixth international conference on Knowledge capture\\n       </meeting>\\n       <imprint>\\n        <publisher>\\n         ACM\\n        </publisher>\\n        <date type=\"published\" when=\"2011\">\\n         2011\\n        </date>\\n        <biblScope from=\"113\" to=\"120\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b4\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Combining retrieval, statistics, and inference to answer elementary science questions\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oyvind\\n         </forename>\\n         <surname>\\n          Tafjord\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <forename type=\"middle\">\\n          D\\n         </forename>\\n         <surname>\\n          Turney\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Daniel\\n         </forename>\\n         <surname>\\n          Khashabi\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        AAAI\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n        <biblScope from=\"2580\" to=\"2586\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b5\">\\n      <monogr>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Isaac\\n         </forename>\\n         <surname>\\n          Cowhey\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Carissa\\n         </forename>\\n         <surname>\\n          Schoenick\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oyvind\\n         </forename>\\n         <surname>\\n          Tafjord\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1803.05457\\n       </idno>\\n       <title level=\"m\">\\n        Think you have solved question answering? try arc, the ai2 reasoning challenge\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2018\">\\n         2018\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b6\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Discriminative embeddings of latent variable models for structured data\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Hanjun\\n         </forename>\\n         <surname>\\n          Dai\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Bo\\n         </forename>\\n         <surname>\\n          Dai\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Le\\n         </forename>\\n         <surname>\\n          Song\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        International Conference on Machine Learning\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n        <biblScope from=\"2702\" to=\"2711\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b7\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Gake: Graph aware knowledge embedding\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Jun\\n         </forename>\\n         <surname>\\n          Feng\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Minlie\\n         </forename>\\n         <surname>\\n          Huang\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Yang\\n         </forename>\\n         <surname>\\n          Yang\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\\n       </title>\\n       <meeting>\\n        COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\\n       </meeting>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n        <biblScope from=\"641\" to=\"651\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b8\">\\n      <monogr>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Justin\\n         </forename>\\n         <surname>\\n          Gilmer\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          S\\n         </forename>\\n         <surname>\\n          Samuel\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Patrick\\n         </forename>\\n         <forename type=\"middle\">\\n          F\\n         </forename>\\n         <surname>\\n          Schoenholz\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oriol\\n         </forename>\\n         <surname>\\n          Riley\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          George\\n         </forename>\\n         <forename type=\"middle\">\\n          E\\n         </forename>\\n         <surname>\\n          Vinyals\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <surname>\\n          Dahl\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1704.01212\\n       </idno>\\n       <title level=\"m\">\\n        Neural message passing for quantum chemistry\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2017\">\\n         2017\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b9\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Elasticsearch: The Definitive Guide: A Distributed Real-Time Search and Analytics Engine\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Clinton\\n         </forename>\\n         <surname>\\n          Gormley\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Zachary\\n         </forename>\\n         <surname>\\n          Tong\\n         </surname>\\n        </persName>\\n       </author>\\n       <imprint>\\n        <date type=\"published\" when=\"2015\">\\n         2015\\n        </date>\\n        <publisher>\\n         Reilly Media, Inc\\n        </publisher>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b10\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          He\\n         </forename>\\n         <surname>\\n          He\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Anusha\\n         </forename>\\n         <surname>\\n          Balakrishnan\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Mihail\\n         </forename>\\n         <surname>\\n          Eric\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Percy\\n         </forename>\\n         <surname>\\n          Liang\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1704.07130\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2017\">\\n         2017\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b11\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        What\\'s in an explanation? characterizing knowledge and inference requirements for elementary science exams\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Jansen\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Niranjan\\n         </forename>\\n         <surname>\\n          Balasubramanian\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Mihai\\n         </forename>\\n         <surname>\\n          Surdeanu\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\\n       </title>\\n       <meeting>\\n        COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\\n       </meeting>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n        <biblScope from=\"2956\" to=\"2965\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b12\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Question answering via integer programming over semi-structured knowledge\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Daniel\\n         </forename>\\n         <surname>\\n          Khashabi\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Dan\\n         </forename>\\n         <surname>\\n          Roth\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1604.06076\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b13\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Markov logic networks for natural language question answering\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Niranjan\\n         </forename>\\n         <surname>\\n          Balasubramanian\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Eric\\n         </forename>\\n         <surname>\\n          Gribkoff\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oren\\n         </forename>\\n         <surname>\\n          Etzioni\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1507.03045\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2015\">\\n         2015\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b14\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Answering complex questions using open information extraction\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1704.05572\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2017\">\\n         2017\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b15\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Scitail: A textual entailment dataset from science question answering\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Tushar\\n         </forename>\\n         <surname>\\n          Khot\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ashish\\n         </forename>\\n         <surname>\\n          Sabharwal\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Peter\\n         </forename>\\n         <surname>\\n          Clark\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Proceedings of AAAI\\n       </title>\\n       <meeting>\\n        AAAI\\n       </meeting>\\n       <imprint>\\n        <date type=\"published\" when=\"2018\">\\n         2018\\n        </date>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b16\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Demonyms and compound relational nouns in nominal open ie\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Harinder\\n         </forename>\\n         <surname>\\n          Pal\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"m\">\\n        Proceedings of the 5th Workshop on Automated Knowledge Base Construction\\n       </title>\\n       <meeting>\\n        the 5th Workshop on Automated Knowledge Base Construction\\n       </meeting>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n        <biblScope from=\"35\" to=\"39\" unit=\"page\"/>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b17\">\\n      <monogr>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          P\\n         </forename>\\n         <surname>\\n          Ankur\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Oscar\\n         </forename>\\n         <surname>\\n          Parikh\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Dipanjan\\n         </forename>\\n         <surname>\\n          TÃ¤ckstrÃ¶m\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Jakob\\n         </forename>\\n         <surname>\\n          Das\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <surname>\\n          Uszkoreit\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1606.01933\\n       </idno>\\n       <title level=\"m\">\\n        A decomposable attention model for natural language inference\\n       </title>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b18\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Squad: 100,000+ questions for machine comprehension of text\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Pranav\\n         </forename>\\n         <surname>\\n          Rajpurkar\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Jian\\n         </forename>\\n         <surname>\\n          Zhang\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Konstantin\\n         </forename>\\n         <surname>\\n          Lopyrev\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Percy\\n         </forename>\\n         <surname>\\n          Liang\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1606.05250\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b19\">\\n      <analytic>\\n       <title level=\"a\" type=\"main\">\\n        Markov logic networks\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Matthew\\n         </forename>\\n         <surname>\\n          Richardson\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Pedro\\n         </forename>\\n         <surname>\\n          Domingos\\n         </surname>\\n        </persName>\\n       </author>\\n      </analytic>\\n      <monogr>\\n       <title level=\"j\">\\n        Machine learning\\n       </title>\\n       <imprint>\\n        <biblScope unit=\"volume\">\\n         62\\n        </biblScope>\\n        <biblScope unit=\"issue\">\\n         1-2\\n        </biblScope>\\n        <biblScope from=\"107\" to=\"136\" unit=\"page\"/>\\n        <date type=\"published\" when=\"2006\">\\n         2006\\n        </date>\\n       </imprint>\\n      </monogr>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b20\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Bidirectional attention flow for machine comprehension\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Minjoon\\n         </forename>\\n         <surname>\\n          Seo\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Aniruddha\\n         </forename>\\n         <surname>\\n          Kembhavi\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Ali\\n         </forename>\\n         <surname>\\n          Farhadi\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Hannaneh\\n         </forename>\\n         <surname>\\n          Hajishirzi\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1611.01603\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2016\">\\n         2016\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n     <biblStruct xml:id=\"b21\">\\n      <monogr>\\n       <title level=\"m\" type=\"main\">\\n        Variational reasoning for question answering with knowledge graph\\n       </title>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Yuyu\\n         </forename>\\n         <surname>\\n          Zhang\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Hanjun\\n         </forename>\\n         <surname>\\n          Dai\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Zornitsa\\n         </forename>\\n         <surname>\\n          Kozareva\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Alexander\\n         </forename>\\n         <forename type=\"middle\">\\n          J\\n         </forename>\\n         <surname>\\n          Smola\\n         </surname>\\n        </persName>\\n       </author>\\n       <author>\\n        <persName>\\n         <forename type=\"first\">\\n          Le\\n         </forename>\\n         <surname>\\n          Song\\n         </surname>\\n        </persName>\\n       </author>\\n       <idno type=\"arXiv\">\\n        arXiv:1709.04071\\n       </idno>\\n       <imprint>\\n        <date type=\"published\" when=\"2017\">\\n         2017\\n        </date>\\n       </imprint>\\n      </monogr>\\n      <note type=\"report_type\">\\n       arXiv preprint\\n      </note>\\n     </biblStruct>\\n    </listBibl>\\n   </div>\\n  </back>\\n </text>\\n</TEI>\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_tei = keep_only_target_section(tei, best_match_section)\n",
    "mini_tei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Adaptive_Margin_Ranking_Loss_for_Knowledge_Graph_Embeddings_via_a_Correntropy_Objective_Function, Mentions: ['DBpedia', 'NELL', 'Freebase', 'UNSTRUC- TURES', 'WordNet', 'Yago']\n",
      "Dataset: Adversarial_Contrastive_Estimation, Mentions: ['WordSim- 353 dataset', 'Rare word dataset', 'Rare Word and WordSim353 data', 'TransD', 'WN18 dataset', 'WordSim- 353']\n",
      "Dataset: Analysis_of_the_Impact_of_Negative_Sampling_on_Link_Prediction_in_Knowledge_Graphs, Mentions: ['FB15k dataset', 'WordNet data', 'FB', 'WordNet lexi- cal database', 'Freebase', 'wordnet', 'WN', 'FB15K benchmark dataset', 'WN18 dataset', 'RESCAL', 'WordNet', 'train and development', 'Freebase dataset', 'FB15k']\n",
      "Dataset: Answering_Visual-Relational_Queries_in_Web-Extracted_Knowledge_Graphs, Mentions: ['DBpedia', 'ILSVRC2012 data set', 'ImageNet', 'Freebase', 'VisualGenome datasets', 'VisualGenome project', 'ImageGraph', 'WordNet', 'FB15k']\n",
      "Dataset: Augmenting_and_Tuning_Knowledge_Graph_Embeddings, Mentions: ['FB15K', 'WordNet database', 'FB15K data set', 'WN18RR', 'FB15K-237', 'Freebase project', 'popu- lar FB15K data set']\n",
      "Dataset: Binarized_Knowledge_Graph_Embeddings, Mentions: ['FB15k dataset', 'KGC benchmark datasets', 'MNIST', 'FB15k-237', 'Freebase-music data 6', 'CIFAR-10', 'WN18', 'FB15k']\n",
      "Dataset: Complex_and_Holographic_Embeddings_of_Knowledge_Graphsïº_A_Comparison, Mentions: ['WN18', 'FB15K data sets', 'WN18 data set']\n",
      "Dataset: Convolutional_2D_Knowledge_Graph_Embeddings, Mentions: ['FB15k datasets', 'DBpedia', 'YAGO3-10', 'WN', 'Countries', 'FB15k-237', 'Countries dataset', 'WN18', 'FB15k']\n",
      "Dataset: DeepPathïº_A_Reinforcement_Learning_Method_for_Knowledge_Graph_Reasoning, Mentions: ['locationContains', 'Never-Ending Language Learning datasets', 'Freebase', 'placeOfBirth', 'NELL dataset', 'NELL']\n",
      "Dataset: DOLORESïº_Deep_Contextualized_Knowledge_Graph_Embeddings, Mentions: ['WN11', 'FB15K-237 dataset', 'FB13', 'MANIFOLDE', 'LORES knowledge']\n",
      "Dataset: Drug-Drug_Interaction_Prediction_Based_on_Knowledge_Graph_Embeddings_and_Convolutional-LSTM_Network, Mentions: ['DrugBank database', 'billion triples benchmark', 'NDF-RT', 'OFFSIDES database', 'KEGG drug database', 'SemMedDB', 'Kyoto Encyclopedia of', 'DDI', 'conv', 'KEGG', 'DrugBank', 'Phar- mGKB database', 'DDI dataset', 'Conv-LSTM network', 'Twosides', 'DDI corpus', 'DrugBank v4.0 dataset', 'Bio2RDF DrugBank v4 dataset', 'TWOSIDES', 'Conv']\n",
      "Dataset: Embedding_Models_for_Episodic_Knowledge_Graphs, Mentions: ['Integrated Conflict Early Warning System (ICEWS) data set', 'Freebase', 'ICEWS', 'Language and Tone', 'GDELT', 'ICEWS (rare) dataset', 'Wikidata', 'Google KG', 'DBpedia', 'ICEWS dataset', 'Global Database of', 'YAGO', 'GDELT test dataset']\n",
      "Dataset: Entity_Hierarchy_Embedding, Mentions: ['INEX', 'Wikipedia snap- shot', 'Wikipedia', 'KB corpora', 'Youku', 'Tudou', 'KB encyclope- dia articles', 'YinYueTai', 'KB encyclo- pedia']\n",
      "Dataset: Expeditious_Generation_of_Knowledge_Graph_Embeddings, Mentions: ['DBpedia', 'DBpedia knowledge graph', 'Long Short-Term Memories', 'YAGO', 'DB- pedia dataset', 'AKSW-bib dataset', '-bib', 'DBpedia 2016-04', 'KGloVe source code', 'English DBpedia 2016-04 dataset']\n",
      "Dataset: Fast_Linear_Model_for_Knowledge_Graph_Embeddings, Mentions: ['FB15k dataset', 'QA', 'SimpleQuestions dataset', 'SVO dataset', 'FB15k-237', 'WN18 dataset', 'KBC benchmarks', 'WordNet', 'WikiMovies dataset', 'FB15k']\n",
      "Dataset: HyperKGïº_Hyperbolic_Knowledge_Graph_Embeddings_for_Knowledge_Base_Completion, Mentions: ['DBpe- dia', 'YAGO', 'WN18RR )', 'Freebase', 'WD ++', 'WN18RR dataset', 'FB15k-237 datasets', 'WD', 'WD ++ datasets', 'WordNet']\n",
      "Dataset: Hypernetwork_Knowledge_Graph_Embeddings, Mentions: ['YAGO3-10', 'Freebase', 'FB15k-237', 'Google Knowledge Graph', 'WordNet', 'WN18', 'HypER', 'FB15k']\n",
      "Dataset: Incorporating_Literals_into_Knowledge_Graph_Embeddings, Mentions: ['YAGO3-10 dataset', 'DBpedia', '15k', 'YAGO3-10', 'heightCm', 'countryArea', 'Freebase', 'FB15k-237', 'MTKGNN', 'Google Knowledge Graph', 'birthYear', 'YAGO3 knowledge graph', 'FB15k', 'stan- dard datasets']\n",
      "Dataset: Inducing_Interpretability_in_Knowledge_Graph_Embeddings, Mentions: []\n",
      "Dataset: KBGANïº_Adversarial_Learning_for_Knowledge_Graph_Embeddings, Mentions: ['af- ter pre', 'FB15k-237', 'KBGAN', 'WN18 dataset', 'DISTMULT', 'KGE datasets', 'WN18']\n",
      "Dataset: KG^2ïº_Learning_to_Reason_Science_Exam_Questions_with_Contextual_Knowledge_Graph_Embeddings, Mentions: ['ARC Chal- lenge Set', 'ARC Easy Set', 'AI2 Reasoning Challenge (ARC', 'ARC Corpus']\n",
      "Dataset: Knowledge-Based_Distant_Regularization_in_Learning_Probabilistic_Models, Mentions: ['train- ing/validation set', 'Freebase', 'Shift data', 'GeneOntology']\n",
      "Dataset: Learning_Attention-based_Embeddings_for_Relation_Prediction_in_Knowledge_Graphs, Mentions: ['TransE', 'FB15K', 'Unified Medi- cal Language Systems (', 'UMLS)', 'FB15k-237', 'graphic embedding', 'NELL-995', 'Free- base (FB15K-237) dataset', 'WN18', 'Alyawarra Kinship']\n",
      "Dataset: Learning_Knowledge_Graph_Embeddings_with_Type_Regularizer, Mentions: ['Wikipedia', 'Freebase', 'Freebase category data', 'FB15K dataset', 'Freebase FB15K dataset']\n",
      "Dataset: Learning_Symmetric_Collaborative_Dialogue_Agents_with_Dynamic_Knowledge_Graph_Embeddings, Mentions: ['settlers of Catan', 'Wizard-of- Oz data collection', 'StanoNet', 'cards corpus', 'dev set', 'MutualFriends set', 'DynoNet']\n",
      "Dataset: Linking_Physicians_to_Medical_Research_Results_via_Knowledge_Graph_Embeddings_and_Twitter, Mentions: ['Twitter extracted dataset', 'social media dataset', 'FB15K', 'European Union Marie Curie ITN', 'IAIS', 'Twitter', 'WordNet18']\n",
      "Dataset: Long-tail_Relation_Extraction_via_Knowledge_Graph_Embeddings_and_Graph_Convolution_Networks, Mentions: ['New York Times (NYT) dataset', 'NYT dataset']\n",
      "Dataset: Modelling_Salient_Features_as_Directions_in_Fine-Tuned_Semantic_Spaces, Mentions: ['movies dataset', 'IMDB senti- ment dataset', 'national park', '20 newsgroups dataset', 'place-types datasets', 'movies and', 'movies', 'Wikipedia 2014']\n",
      "Dataset: MOHONEïº_Modeling_Higher_Order_Network_Effects_in_KnowledgeGraphs_via_Network_Infused_Embeddings, Mentions: ['MANIFOLDE', 'OpenKE code']\n",
      "Dataset: Multi-Hop_Knowledge_Graph_Reasoning_with_Reward_Shaping, Mentions: ['Kinship', 'UMLS', 'dev', 'Unified Medical Language Systems', 'KGQA', 'test set', 'NELL-995 dataset', 'WN', 'FB15k-237', 'NELL-995', 'dev sets', 'WN18RR 995', 'WN18RR', 'Alyawarra Kinship', 'KG datasets']\n",
      "Dataset: Multilingual_Knowledge_Graph_Embeddings_for_Cross-lingual_Knowledge_Alignment, Mentions: ['ConceptNet', 'Wikipedia', 'CN3l data set', 'CN3l', 'WordNet', 'WK']\n",
      "Dataset: Multimodal_Named_Entity_Disambiguation_for_Noisy_Social_Media_Posts, Mentions: ['MNED', 'New York Story', 'NED datasets', 'Thanksgiving Story', 'ImageNet dataset', 'SnapCaptionsKB dataset', 'Freebase knowledge graph', 'SnapCaptionsKB']\n",
      "Dataset: Neural_Variational_Inference_For_Estimating_Uncertainty_in_Knowledge_Graph_Embeddings, Mentions: ['KB dataset']\n",
      "Dataset: Quaternion_Knowledge_Graph_Embeddings, Mentions: ['framework', 'FB15K', 'FB', 'Freebase', 'WordNet 3', 'WN18 dataset', 'FB15K dataset', 'FB15K-237', 'WN18', 'K-237']\n",
      "Dataset: RDF2Vecïº_RDF_Graph_Embeddings_and_Their_Applications, Mentions: ['AIFB', '2015-10 DBpe- dia dataset', 'dbpedia', 'LOD dataset', 'LibraryThing', 'DBpedia dataset', 'DB', 'Wikidata', 'RDF', 'SPARQL aggregates', 'Linked Open Data', 'DBpedia', 'movielens', 'Forbes dataset', 'DBpedia knowl- edge graph', 'LOD', 'BGS', 'LP50 dataset', 'Movielens dataset', 'Metacritic Movies dataset', 'last', 'LOD\\\\_ML\\\\_Datasets', 'Last.fm datasets', 'KORE dataset', 'AM', 'Last', 'Mark Zuckerberg', 'Wordnet', 'Wikidata dataset', 'MU- TAG', 'LibraryThing dataset', 'RDF datasets', 'AAUP dataset', 'LODrecsys-datasets', 'linked', 'Wikipedia Ontology', 'LOD cloud', 'LOD data sources', 'Last.fm', 'Wikidata entities', 'Movielens 1M', 'RankSys', 'AIFB dataset', 'LinkedMDB', 'Google']\n",
      "Dataset: Recognizing_Mentions_of_Adverse_Drug_Reaction_in_Social_Media_Using_Knowledge-Infused_Recurrent_Models, Mentions: ['CADEC corpus', 'DBpedia', 'ADR Oracle', 'CADEC', 'DBpedia knowledge graph', 'CSIRO Ad- verse Drug Event Corpus (CADEC)', 'CADEC lexicon', \"CADEC's test set\", 'Ask a Patient corpus', 'Penn Treebank', 'Blekko medical corpus', 'CADEC training data', 'train- ing corpus']\n",
      "Dataset: Relation_Embedding_with_Dihedral_Group_in_Knowledge_Graph, Mentions: ['FB15k datasets', 'FB15K', 'WordNet database', 'FB', 'FB15K-237 dataset', 'WN18 dataset', 'WN18']\n",
      "Dataset: Seq2RDFïº_An_end-to-end_application_for_deriving_Triples_from_Natural_Language_Text, Mentions: ['NYT', 'Wiki-DBpedia dataset']\n",
      "Dataset: Sparsity_and_Noiseïº_Where_Knowledge_Graph_Embeddings_Fall_Short, Mentions: ['FB15K', 'Freebase', 'FB15K benchmarks', 'NELL165', 'WordNet', 'NELL165 dataset', 'NELL', 'FB15K dataset']\n",
      "Dataset: Towards_Understanding_the_Geometry_of_Knowledge_Graph_Embeddings, Mentions: ['Freebase', 'FB15K dataset', 'WordNet']\n"
     ]
    }
   ],
   "source": [
    "for i in dataset_mentions:\n",
    "    dataset_mentions[i] = deduplicate_fuzzy(dataset_mentions[i], threshold=80)\n",
    "    print(f\"Dataset: {i}, Mentions: {dataset_mentions[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall: 0.7329\n",
      "Mean Precision: 0.2733\n",
      "Mean F1: 0.3738\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "for i, paper in enumerate(papers_list):\n",
    "    title = paper['Title']\n",
    "    titles.append(title)\n",
    "for data in dataset_mentions:\n",
    "    # find the closest match in the papers_list[i]['title']\n",
    "    idx = closest_string_index(data, titles)\n",
    "    pred_text = dataset_mentions[data]\n",
    "    reference = papers_list[idx]['Datasets']\n",
    "    ref_text = [item[0] for item in reference]\n",
    "    if len(ref_text) == 0:\n",
    "            continue\n",
    "    if len(ref_text) > 0:\n",
    "        if len(pred_text) == 0:\n",
    "            recall = 0\n",
    "            precision = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "\n",
    "            # For each reference entity, find the max similarity to predicted entities\n",
    "            max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "            # Apply threshold\n",
    "            threshold = 0.6\n",
    "            tp = (max_similarities >= threshold).sum().item()\n",
    "            fn = len(ref_text) - tp         # false negatives\n",
    "            fp = len(pred_text) - tp    # false positives\n",
    "            def safe_div(num, denom):\n",
    "                return num / denom if denom else 0.0        # or np.nan\n",
    "            precision=safe_div(tp, tp + fp)\n",
    "            recall=safe_div(tp, tp + fn)\n",
    "            f1=safe_div(2 * precision * recall, precision + recall)\n",
    "            recalls.append(recall)\n",
    "            precisions.append(precision)\n",
    "            f1s.append(f1)\n",
    "mean_recall = sum(recalls) / len(recalls)\n",
    "mean_precision = sum(precisions) / len(precisions)\n",
    "mean_f1 = sum(f1s) / len(f1s)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")    \n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean F1: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Processing paper: KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['ARC Challenge Set', 'ARC Corpus']\n",
      "Reference: ['ARC (AI2 Reasoning Challenge)', 'SNLI', 'SQuAD']\n",
      "Processing paper: Incorporating Literals into Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: ['FB15k-237', 'FB15k']\n",
      "Processing paper: Adversarial Contrastive Estimation\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['WordSim-353', 'Rare word dataset']\n",
      "Reference: []\n",
      "Processing paper: KBGAN: Adversarial Learning for Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['WN18', 'FB15k-237', 'WN', 'FB']\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Processing paper: Convolutional 2D Knowledge Graph Embeddings\n",
      "Best matching section: Experimental Setup with score 0.6321\n",
      "Mentions: []\n",
      "Reference: ['YAGO', 'YAGO3-10', 'UMLS', 'WN18RR', 'FB15k', 'FB15k-237', 'WN18']\n",
      "Processing paper: Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs\n",
      "Best matching section: Introduction with score 0.3817\n",
      "Mentions: []\n",
      "Reference: ['Visual Genome', 'FB15k', 'ImageNet']\n",
      "Processing paper: Expeditious Generation of Knowledge Graph Embeddings\n",
      "Best matching section: Evaluation with score 1.0000\n",
      "Mentions: ['English DBpedia 2016-04 dataset', 'AKSW-bib dataset', 'DBpedia knowledge graph']\n",
      "Reference: []\n",
      "Processing paper: Learning Knowledge Graph Embeddings with Type Regularizer\n",
      "Best matching section: EXPERIMENTS 4.1 Data with score 0.6278\n",
      "Mentions: ['FB15K', 'FB15K dataset']\n",
      "Reference: []\n",
      "Processing paper: Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs\n",
      "Best matching section: EXPERIMENTS 5.1 Implementation with score 0.5489\n",
      "Mentions: []\n",
      "Reference: ['FB15k', 'NELL', 'WN18']\n",
      "Processing paper: DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: ['NELL', 'NELL-995']\n",
      "Processing paper: Inducing Interpretability in Knowledge Graph Embeddings\n",
      "Best matching section: Experiments and Results with score 0.8618\n",
      "Mentions: []\n",
      "Reference: []\n",
      "Processing paper: Fast Linear Model for Knowledge Graph Embeddings\n",
      "Best matching section: Results with score 0.5359\n",
      "Mentions: ['N18 dataset i']\n",
      "Reference: ['WN18', 'FB15k', 'WikiMovies']\n",
      "Processing paper: Complex and Holographic Embeddings of Knowledge Graphs: A Comparison\n",
      "Best matching section: Introduction with score 0.3817\n",
      "Mentions: []\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Processing paper: Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['WK3']\n",
      "Reference: ['DBP15K', 'MMKG']\n",
      "Processing paper: Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: ['MutualFriends']\n",
      "Processing paper: Knowledge-Based Distant Regularization in Learning Probabilistic Models\n",
      "Best matching section: Preliminary Experiments with score 0.7931\n",
      "Mentions: []\n",
      "Reference: []\n",
      "Processing paper: Embedding Models for Episodic Knowledge Graphs\n",
      "Best matching section: Conclusion with score 0.4859\n",
      "Mentions: ['ICEWS dataset']\n",
      "Reference: []\n",
      "Processing paper: Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['Wiki-DBpedia dataset', 'NYT 4', 'ADE']\n",
      "Reference: []\n",
      "Processing paper: Hypernetwork Knowledge Graph Embeddings\n",
      "Best matching section: Results with score 0.5359\n",
      "Mentions: []\n",
      "Reference: ['WN18RR', 'FB15k', 'WN18', 'FB15k-237']\n",
      "Processing paper: Multi-Hop Knowledge Graph Reasoning with Reward Shaping\n",
      "Best matching section: Experiment Setup with score 0.6940\n",
      "Mentions: ['Unified Medical Language Systems']\n",
      "Reference: ['NELL-995']\n",
      "Processing paper: MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via Network Infused Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: ['FB15k-237']\n",
      "Processing paper: DOLORES: Deep Contextualized Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: []\n",
      "Processing paper: Modelling Salient Features as Directions in Fine-Tuned Semantic Spaces\n",
      "Best matching section: Evaluation with score 1.0000\n",
      "Mentions: ['place']\n",
      "Reference: []\n",
      "Processing paper: Towards Understanding the Geometry of Knowledge Graph Embeddings\n",
      "Best matching section: Experimental Setup with score 0.6321\n",
      "Mentions: ['WN18', 'FB15K dataset', 'WordNet', 'Freebase', 'FB15k']\n",
      "Reference: []\n",
      "Processing paper: Multimodal Named Entity Disambiguation for Noisy Social Media Posts\n",
      "Best matching section: Empirical Evaluation with score 0.6921\n",
      "Mentions: ['Thanksgiving', 'New York', 'SnapCaptionsKB dataset']\n",
      "Reference: []\n",
      "Processing paper: Recognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\n",
      "Best matching section: Evaluation with score 1.0000\n",
      "Mentions: ['CADEC corpus']\n",
      "Reference: []\n",
      "Processing paper: Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short\n",
      "Best matching section: Empirical Evaluation with score 0.6921\n",
      "Mentions: ['K benchmarks', 'FB', 'NELL165 dataset']\n",
      "Reference: ['WN18', 'FB15k']\n",
      "Processing paper: Entity Hierarchy Embedding\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: []\n",
      "Reference: []\n",
      "Processing paper: Binarized Knowledge Graph Embeddings\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['18RR', '15k [4', '15k-237 [6]', 'N18']\n",
      "Reference: ['WN18', 'FB15k', 'WN18RR']\n",
      "Processing paper: Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks\n",
      "Best matching section: Experiments with score 1.0000\n",
      "Mentions: ['YT dataset d']\n",
      "Reference: []\n",
      "Mean Recall: 0.2857\n",
      "Mean Precision: 0.2857\n",
      "Mean F1: 0.2816\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "\n",
    "# === Setup ===\n",
    "client = GrobidClient(config_path=\"./Grobid/config.json\")\n",
    "current_dir = Path(os.getcwd())\n",
    "recalls = []\n",
    "precisions = [] \n",
    "f1s = []\n",
    "\n",
    "dataset_files = {}\n",
    "for paper in papers_list[0:30]:\n",
    "    print(f\"Processing paper: {paper['Title']}\")\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    # client.process(\n",
    "    #     \"processFulltextDocument\",                # or \"processHeaderDocument\"\n",
    "    #     str(current_dir /paper['Local PDF Path']),\n",
    "    #     generateIDs=True,                         # adds xml:id attributes\n",
    "    #     consolidate_citations=True                # crossâlinks refs ââ¯bibliography\n",
    "    # )\n",
    "    tei_xml = client.process_pdf(\n",
    "        service=\"processFulltextDocument\",\n",
    "        pdf_file=pdf_path,\n",
    "        generateIDs        = False,   # was optional, now required\n",
    "        consolidate_header = True,  # same default as server\n",
    "        consolidate_citations = False,\n",
    "        include_raw_citations   = False,\n",
    "        include_raw_affiliations = False,\n",
    "        segment_sentences   = False,\n",
    "        tei_coordinates     = False\n",
    "    )\n",
    "\n",
    "    _, status, tei = tei_xml\n",
    "\n",
    "    sections = extract_flat_sections_with_subtext(tei)\n",
    "    ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model)\n",
    "    best_match_section, best_score = ranked_sections[0]\n",
    "    best_match_section_text = str(sections[[sec['title'] for sec in sections].index(best_match_section)]['text'])\n",
    "    # print best text\n",
    "    print(f\"Best matching section: {best_match_section} with score {best_score:.4f}\")\n",
    "    \n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:8060/service/annotateDatasetSentence\",\n",
    "        data={\"text\": best_match_section_text}\n",
    "    )\n",
    "\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        #     f.write(response.text)\n",
    "        data = response.json()\n",
    "        dataset_names = [\n",
    "            mention['normalizedForm']\n",
    "            for mention in data.get('mentions', [])\n",
    "            if mention.get('type') == 'dataset-name'\n",
    "        ]\n",
    "\n",
    "        # optionally, deduplicate\n",
    "        unique_dataset_names = list(set(dataset_names))\n",
    "\n",
    "\n",
    "        unique_dataset_names = deduplicate_fuzzy(unique_dataset_names, threshold=80)\n",
    "        print(f\"Mentions: {unique_dataset_names}\")\n",
    "\n",
    "        pred_text = unique_dataset_names\n",
    "        reference = paper['Datasets']\n",
    "        ref_text = [item[0] for item in reference]\n",
    "        print(f\"Reference: {ref_text}\")\n",
    "        if len(ref_text) == 0:\n",
    "                continue\n",
    "        if len(ref_text) > 0:\n",
    "            if len(pred_text) == 0:\n",
    "                recall = 0\n",
    "                precision = 0\n",
    "                f1 = 0\n",
    "            else:\n",
    "                # For each reference entity, find the max similarity to predicted entities\n",
    "                max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "                # Apply threshold\n",
    "                threshold = 0.6\n",
    "                tp = (max_similarities >= threshold).sum().item()\n",
    "                fn = len(ref_text) - tp         # false negatives\n",
    "                fp = len(pred_text) - tp    # false positives\n",
    "                def safe_div(num, denom):\n",
    "                    return num / denom if denom else 0.0        # or np.nan\n",
    "                precision=safe_div(tp, tp + fp)\n",
    "                recall=safe_div(tp, tp + fn)\n",
    "                f1=safe_div(2 * precision * recall, precision + recall)\n",
    "                recalls.append(recall)\n",
    "                precisions.append(precision)\n",
    "                f1s.append(f1)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "mean_recall = sum(recalls) / len(recalls)\n",
    "mean_precision = sum(precisions) / len(precisions)\n",
    "mean_f1 = sum(f1s) / len(f1s)\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")    \n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean F1: {mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARC Challenge Set', 'ARC Corpus']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "unique_dataset_names = list(set(dataset_names))\n",
    "for i in range(len(unique_dataset_names)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "dataset_mentions = []\n",
    "with open('./datasets.json', \"r\") as file:\n",
    "    dataset_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adaptive_Margin_Ranking_Loss_for_Knowledge_Graph_Embeddings_via_a_Correntropy_Objective_Function': ['DBpedia',\n",
       "  'NELL',\n",
       "  'Freebase',\n",
       "  'UNSTRUC- TURES',\n",
       "  'WordNet',\n",
       "  'Yago'],\n",
       " 'Adversarial_Contrastive_Estimation': ['WordSim- 353 dataset',\n",
       "  'Rare word dataset',\n",
       "  'Rare Word and WordSim353 data',\n",
       "  'TransD',\n",
       "  'WN18 dataset',\n",
       "  'WordSim- 353'],\n",
       " 'Analysis_of_the_Impact_of_Negative_Sampling_on_Link_Prediction_in_Knowledge_Graphs': ['FB15k dataset',\n",
       "  'WordNet data',\n",
       "  'FB',\n",
       "  'WordNet lexi- cal database',\n",
       "  'Freebase',\n",
       "  'wordnet',\n",
       "  'WN',\n",
       "  'WordNet dataset',\n",
       "  'FB15K benchmark dataset',\n",
       "  'WN18 dataset',\n",
       "  'RESCAL',\n",
       "  'WordNet',\n",
       "  'train and development',\n",
       "  'Freebase dataset',\n",
       "  'FB15k'],\n",
       " 'Answering_Visual-Relational_Queries_in_Web-Extracted_Knowledge_Graphs': ['DBpedia',\n",
       "  'ILSVRC2012 data set',\n",
       "  'ImageNet',\n",
       "  'Freebase',\n",
       "  'VisualGenome datasets',\n",
       "  'FreeBase',\n",
       "  'VisualGenome project',\n",
       "  'ImageGraph',\n",
       "  'VisualGenome data',\n",
       "  'WordNet',\n",
       "  'FB15k'],\n",
       " 'Augmenting_and_Tuning_Knowledge_Graph_Embeddings': ['FB15K',\n",
       "  'WordNet database',\n",
       "  'FB15K data set',\n",
       "  'WN18RR',\n",
       "  'FB15K-237',\n",
       "  'Freebase project',\n",
       "  'popu- lar FB15K data set'],\n",
       " 'Binarized_Knowledge_Graph_Embeddings': ['FB15k dataset',\n",
       "  'KGC benchmark datasets',\n",
       "  'MNIST',\n",
       "  'FB15k-237',\n",
       "  'Freebase-music data 6',\n",
       "  'CIFAR-10',\n",
       "  'WN18',\n",
       "  'WN18RR',\n",
       "  'FB15k'],\n",
       " 'Complex_and_Holographic_Embeddings_of_Knowledge_Graphs\\uf03a_A_Comparison': ['WN18',\n",
       "  'FB15K data sets',\n",
       "  'WN18 data set',\n",
       "  'WN18 dataset'],\n",
       " 'Convolutional_2D_Knowledge_Graph_Embeddings': ['FB15k datasets',\n",
       "  'DBpedia',\n",
       "  'YAGO3-10',\n",
       "  'WN',\n",
       "  'Countries',\n",
       "  'FB15k-237',\n",
       "  'Countries dataset',\n",
       "  'WN18',\n",
       "  'FB15k'],\n",
       " 'DeepPath\\uf03a_A_Reinforcement_Learning_Method_for_Knowledge_Graph_Reasoning': ['locationContains',\n",
       "  'Never-Ending Language Learning datasets',\n",
       "  'Freebase',\n",
       "  'Never-Ending Lan- guage Learning dataset',\n",
       "  'placeOfBirth',\n",
       "  'NELL dataset',\n",
       "  'NELL- 995 dataset',\n",
       "  'NELL'],\n",
       " 'DOLORES\\uf03a_Deep_Contextualized_Knowledge_Graph_Embeddings': ['WN11',\n",
       "  'FB15K-237 dataset',\n",
       "  'FB13',\n",
       "  'MANIFOLDE',\n",
       "  'LORES knowledge'],\n",
       " 'Drug-Drug_Interaction_Prediction_Based_on_Knowledge_Graph_Embeddings_and_Convolutional-LSTM_Network': ['DrugBank database',\n",
       "  'billion triples benchmark',\n",
       "  'NDF-RT',\n",
       "  'OFFSIDES database',\n",
       "  'KEGG drug database',\n",
       "  'SemMedDB',\n",
       "  'Kyoto Encyclopedia of',\n",
       "  'KEGG databases',\n",
       "  'DDI',\n",
       "  'conv',\n",
       "  'KEGG',\n",
       "  'DrugBank',\n",
       "  'Phar- mGKB database',\n",
       "  'DDI dataset',\n",
       "  'Conv-LSTM network',\n",
       "  'Twosides',\n",
       "  'DDI corpus',\n",
       "  'DrugBank v4.0 dataset',\n",
       "  'Bio2RDF DrugBank v4 dataset',\n",
       "  'TWOSIDES',\n",
       "  'DrugBank dataset',\n",
       "  'PharmGKB database 1',\n",
       "  'Conv'],\n",
       " 'Embedding_Models_for_Episodic_Knowledge_Graphs': ['Integrated Conflict Early Warning System (ICEWS) data set',\n",
       "  'Freebase',\n",
       "  'ICEWS',\n",
       "  'Language and Tone',\n",
       "  'GDELT',\n",
       "  'ICEWS (rare) dataset',\n",
       "  'Wikidata',\n",
       "  'Google KG',\n",
       "  'DBpedia',\n",
       "  'Language and Tone (',\n",
       "  'ICEWS dataset',\n",
       "  'ICEWS (rare) training dataset',\n",
       "  'Language, and Tone',\n",
       "  'Global Database of',\n",
       "  'YAGO',\n",
       "  'GDELT test dataset',\n",
       "  'Global Database of Events',\n",
       "  'Integrated Conflict Early Warning System (ICEWS) dataset',\n",
       "  'GDELT dataset',\n",
       "  'ICEWS test dataset'],\n",
       " 'Entity_Hierarchy_Embedding': ['INEX',\n",
       "  'Wikipedia snap- shot',\n",
       "  'Wikipedia',\n",
       "  'KB corpora',\n",
       "  'Youku',\n",
       "  'Tudou',\n",
       "  'KB encyclope- dia articles',\n",
       "  'YinYueTai',\n",
       "  'KB encyclo- pedia'],\n",
       " 'Expeditious_Generation_of_Knowledge_Graph_Embeddings': ['DBpedia',\n",
       "  'DBpedia knowledge graph',\n",
       "  'Long Short-Term Memories',\n",
       "  'YAGO',\n",
       "  'DB- pedia dataset',\n",
       "  'AKSW-bib dataset',\n",
       "  'DBpedia dataset',\n",
       "  '-bib',\n",
       "  'DBpedia 2016-04',\n",
       "  'KGloVe source code',\n",
       "  'English DBpedia 2016-04 dataset'],\n",
       " 'Fast_Linear_Model_for_Knowledge_Graph_Embeddings': ['FB15k dataset',\n",
       "  'QA',\n",
       "  'SimpleQuestions dataset',\n",
       "  'SVO dataset',\n",
       "  'FB15k-237',\n",
       "  'WN18 dataset',\n",
       "  'KBC benchmarks',\n",
       "  'WordNet',\n",
       "  'FB15k-237 dataset',\n",
       "  'WikiMovies dataset',\n",
       "  'FB15k'],\n",
       " 'HyperKG\\uf03a_Hyperbolic_Knowledge_Graph_Embeddings_for_Knowledge_Base_Completion': ['DBpe- dia',\n",
       "  'YAGO',\n",
       "  'WN18RR )',\n",
       "  'Freebase',\n",
       "  'WD ++',\n",
       "  'WN18RR dataset',\n",
       "  'FB15k-237 datasets',\n",
       "  'WD',\n",
       "  'WD ++ datasets',\n",
       "  'WordNet',\n",
       "  'FB15k-237 dataset',\n",
       "  'WN18RR'],\n",
       " 'Hypernetwork_Knowledge_Graph_Embeddings': ['YAGO3-10',\n",
       "  'Freebase',\n",
       "  'FB15k-237',\n",
       "  'Google Knowledge Graph',\n",
       "  'WordNet',\n",
       "  'WN18',\n",
       "  'WN18RR',\n",
       "  'HypER',\n",
       "  'FB15k'],\n",
       " 'Incorporating_Literals_into_Knowledge_Graph_Embeddings': ['YAGO3-10 dataset',\n",
       "  'DBpedia',\n",
       "  '15k',\n",
       "  'YAGO3-10',\n",
       "  'heightCm',\n",
       "  'countryArea',\n",
       "  'Freebase',\n",
       "  'FB15k-237',\n",
       "  'MTKGNN',\n",
       "  'Google Knowledge Graph',\n",
       "  'birthYear',\n",
       "  'YAGO3 knowledge graph',\n",
       "  'FB15k',\n",
       "  'stan- dard datasets'],\n",
       " 'Inducing_Interpretability_in_Knowledge_Graph_Embeddings': [],\n",
       " 'KBGAN\\uf03a_Adversarial_Learning_for_Knowledge_Graph_Embeddings': ['af- ter pre',\n",
       "  'FB15k-237',\n",
       "  'KBGAN',\n",
       "  'WN18 dataset',\n",
       "  'DISTMULT',\n",
       "  'KGE datasets',\n",
       "  'WN18',\n",
       "  'WN18RR'],\n",
       " 'KG^2\\uf03a_Learning_to_Reason_Science_Exam_Questions_with_Contextual_Knowledge_Graph_Embeddings': ['ARC Chal- lenge Set',\n",
       "  'ARC Challenge Set',\n",
       "  'ARC Easy Set',\n",
       "  'ARC Challenge',\n",
       "  'AI2 Reasoning Challenge (ARC',\n",
       "  'AI2 Reasoning Challenge (ARC)',\n",
       "  'ARC Corpus'],\n",
       " 'Knowledge-Based_Distant_Regularization_in_Learning_Probabilistic_Models': ['train- ing/validation set',\n",
       "  'Freebase',\n",
       "  'Shift data',\n",
       "  'GeneOntology'],\n",
       " 'Learning_Attention-based_Embeddings_for_Relation_Prediction_in_Knowledge_Graphs': ['TransE',\n",
       "  'FB15K',\n",
       "  'Unified Medi- cal Language Systems (',\n",
       "  'UMLS)',\n",
       "  'FB15k-237',\n",
       "  'graphic embedding',\n",
       "  'NELL-995',\n",
       "  'Free- base (FB15K-237) dataset',\n",
       "  'WN18',\n",
       "  'WN18RR',\n",
       "  'Alyawarra Kinship'],\n",
       " 'Learning_Knowledge_Graph_Embeddings_with_Type_Regularizer': ['Wikipedia',\n",
       "  'Freebase',\n",
       "  'Freebase category data',\n",
       "  'FB15K dataset',\n",
       "  'Freebase FB15K dataset'],\n",
       " 'Learning_Symmetric_Collaborative_Dialogue_Agents_with_Dynamic_Knowledge_Graph_Embeddings': ['settlers of Catan',\n",
       "  'Wizard-of- Oz data collection',\n",
       "  'StanoNet',\n",
       "  'cards corpus',\n",
       "  'dev set',\n",
       "  'MutualFriends set',\n",
       "  'DynoNet'],\n",
       " 'Linking_Physicians_to_Medical_Research_Results_via_Knowledge_Graph_Embeddings_and_Twitter': ['Twitter extracted dataset',\n",
       "  'social media dataset',\n",
       "  'FB15K',\n",
       "  'European Union Marie Curie ITN',\n",
       "  'IAIS',\n",
       "  'Twitter',\n",
       "  'WordNet18'],\n",
       " 'Long-tail_Relation_Extraction_via_Knowledge_Graph_Embeddings_and_Graph_Convolution_Networks': ['New York Times (NYT) dataset',\n",
       "  'NYT dataset'],\n",
       " 'Modelling_Salient_Features_as_Directions_in_Fine-Tuned_Semantic_Spaces': ['movies dataset',\n",
       "  'IMDB senti- ment dataset',\n",
       "  'sentiment datasets',\n",
       "  'national park',\n",
       "  '20 newsgroups dataset',\n",
       "  'IMDB Sen- timent dataset',\n",
       "  'place-types datasets',\n",
       "  'movies and',\n",
       "  'IMDB sentiment dataset',\n",
       "  'place-types dataset',\n",
       "  'movies',\n",
       "  'Wikipedia 2014'],\n",
       " 'MOHONE\\uf03a_Modeling_Higher_Order_Network_Effects_in_KnowledgeGraphs_via_Network_Infused_Embeddings': ['MANIFOLDE',\n",
       "  'OpenKE code'],\n",
       " 'Multi-Hop_Knowledge_Graph_Reasoning_with_Reward_Shaping': ['Kinship',\n",
       "  'UMLS',\n",
       "  'dev',\n",
       "  'Unified Medical Language Systems',\n",
       "  'KGQA',\n",
       "  'test set',\n",
       "  'NELL-995 dataset',\n",
       "  'WN',\n",
       "  'FB15k-237',\n",
       "  'NELL-995',\n",
       "  'dev sets',\n",
       "  'FB15K- 237',\n",
       "  'NELL- 995',\n",
       "  'WN18RR 995',\n",
       "  'NELL-995 dev set',\n",
       "  'WN18RR',\n",
       "  'Alyawarra Kinship',\n",
       "  'KG datasets'],\n",
       " 'Multilingual_Knowledge_Graph_Embeddings_for_Cross-lingual_Knowledge_Alignment': ['ConceptNet',\n",
       "  'Wikipedia',\n",
       "  'CN3l data set',\n",
       "  'Concept- Net',\n",
       "  'MIT ConceptNet',\n",
       "  'CN3l',\n",
       "  'WordNet',\n",
       "  'WK'],\n",
       " 'Multimodal_Named_Entity_Disambiguation_for_Noisy_Social_Media_Posts': ['MNED',\n",
       "  'New York Story',\n",
       "  'NED datasets',\n",
       "  'NED',\n",
       "  'Thanksgiving Story',\n",
       "  'ImageNet dataset',\n",
       "  'SnapCaptionsKB dataset',\n",
       "  'Freebase knowledge graph',\n",
       "  'Snap Captions dataset',\n",
       "  'SnapCaptionsKB'],\n",
       " 'Neural_Variational_Inference_For_Estimating_Uncertainty_in_Knowledge_Graph_Embeddings': ['KB dataset'],\n",
       " 'Quaternion_Knowledge_Graph_Embeddings': ['framework',\n",
       "  'FB15K',\n",
       "  'FB',\n",
       "  'Freebase',\n",
       "  'WordNet 3',\n",
       "  'WN18 dataset',\n",
       "  'FB15K dataset',\n",
       "  'FB15K-237',\n",
       "  'WN18',\n",
       "  'WN18RR',\n",
       "  'K-237'],\n",
       " 'RDF2Vec\\uf03a_RDF_Graph_Embeddings_and_Their_Applications': ['AIFB',\n",
       "  '2015-10 DBpe- dia dataset',\n",
       "  'dbpedia',\n",
       "  'LOD dataset',\n",
       "  'LibraryThing',\n",
       "  'DBpedia dataset',\n",
       "  'DB',\n",
       "  'Wikidata',\n",
       "  'RDF',\n",
       "  'SPARQL aggregates',\n",
       "  'Linked Open Data',\n",
       "  'DBpedia',\n",
       "  'movielens',\n",
       "  'Forbes dataset',\n",
       "  'DBpedia knowl- edge graph',\n",
       "  'LOD',\n",
       "  'BGS',\n",
       "  'LP50 dataset',\n",
       "  'Movielens dataset',\n",
       "  'Metacritic Movies dataset',\n",
       "  'last',\n",
       "  'LOD\\\\_ML\\\\_Datasets',\n",
       "  'Last.fm datasets',\n",
       "  'KORE dataset',\n",
       "  'AM',\n",
       "  'Last',\n",
       "  'Mark Zuckerberg',\n",
       "  'Wordnet',\n",
       "  'Wikidata dataset',\n",
       "  'MU- TAG',\n",
       "  'DBpedia data',\n",
       "  'LibraryThing dataset',\n",
       "  'DB- pedia dataset',\n",
       "  'RDF datasets',\n",
       "  'LOD datasets',\n",
       "  'Wiki- data',\n",
       "  'Metacritic albums dataset',\n",
       "  'AAUP dataset',\n",
       "  'LODrecsys-datasets',\n",
       "  'linked',\n",
       "  'Movielens',\n",
       "  'librarything',\n",
       "  'Wikipedia Ontology',\n",
       "  'LOD cloud',\n",
       "  'wikidata',\n",
       "  'LOD data sources',\n",
       "  'Last.fm',\n",
       "  'Wikidata entities',\n",
       "  'Movielens 1M',\n",
       "  'RankSys',\n",
       "  'AIFB dataset',\n",
       "  'LibraryThing datasets',\n",
       "  'LinkedMDB',\n",
       "  'Movielens 18',\n",
       "  'Linked',\n",
       "  'Google'],\n",
       " 'Recognizing_Mentions_of_Adverse_Drug_Reaction_in_Social_Media_Using_Knowledge-Infused_Recurrent_Models': ['CADEC corpus',\n",
       "  'DBpedia',\n",
       "  'ADR Oracle',\n",
       "  'CADEC',\n",
       "  'DBpedia knowledge graph',\n",
       "  'CSIRO Ad- verse Drug Event Corpus (CADEC)',\n",
       "  'CADEC lexicon',\n",
       "  \"CADEC's test set\",\n",
       "  'Ask a Patient corpus',\n",
       "  'Penn Treebank',\n",
       "  'Blekko medical corpus',\n",
       "  'CADEC training data',\n",
       "  'train- ing corpus',\n",
       "  'CSIRO Adverse Drug Event Corpus (CADEC)',\n",
       "  'DB- pedia'],\n",
       " 'Relation_Embedding_with_Dihedral_Group_in_Knowledge_Graph': ['FB15k datasets',\n",
       "  'FB15K',\n",
       "  'WordNet database',\n",
       "  'FB',\n",
       "  'KB datasets',\n",
       "  'FB15K-237 dataset',\n",
       "  'WN18 dataset',\n",
       "  'FB15K-237 datasets',\n",
       "  'WN18 datasets',\n",
       "  'WN18',\n",
       "  'WN18RR',\n",
       "  'FB15K dataset'],\n",
       " 'Seq2RDF\\uf03a_An_end-to-end_application_for_deriving_Triples_from_Natural_Language_Text': ['NYT',\n",
       "  'Wiki-DBpedia dataset'],\n",
       " 'Sparsity_and_Noise\\uf03a_Where_Knowledge_Graph_Embeddings_Fall_Short': ['FB15K',\n",
       "  'Freebase',\n",
       "  'FB15K benchmarks',\n",
       "  'NELL165',\n",
       "  'WordNet',\n",
       "  'NELL165 dataset',\n",
       "  'NELL',\n",
       "  'FB15K dataset'],\n",
       " 'Towards_Understanding_the_Geometry_of_Knowledge_Graph_Embeddings': ['Freebase',\n",
       "  'FB15K dataset',\n",
       "  'WordNet']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_dataset = []\n",
    "responses_task = []\n",
    "responses_authors = []\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for paper in papers_list[0:30]:\n",
    "    pdf_path = str(current_dir /paper['Local PDF Path'])\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "\n",
    "\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def parse_tei(tei_text):\n",
    "    soup = BeautifulSoup(tei_text, \"xml\")\n",
    "\n",
    "    words = []\n",
    "    sentences = []\n",
    "    sections = []\n",
    "\n",
    "    token_idx = 0\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        sec_start = token_idx\n",
    "        for p in div.find_all(\"p\"):\n",
    "            text = p.get_text()\n",
    "            doc = nlp(text)\n",
    "            for sent in doc.sents:\n",
    "                s_start = token_idx\n",
    "                for token in sent:\n",
    "                    words.append(token.text)\n",
    "                    token_idx += 1\n",
    "                s_end = token_idx\n",
    "                sentences.append([s_start, s_end])\n",
    "        sec_end = token_idx\n",
    "        if sec_end > sec_start:\n",
    "            sections.append([sec_start, sec_end])\n",
    "    \n",
    "    return {\n",
    "        \"doc_id\": soup.find(\"teiHeader\").find(\"idno\").text if soup.find(\"idno\") else \"unknown_doc\",\n",
    "        \"words\": words,\n",
    "        \"sentences\": sentences,\n",
    "        \"sections\": sections\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sections(section_texts, nlp):\n",
    "    words = []\n",
    "    sentences = []\n",
    "    sections = []\n",
    "\n",
    "    token_idx = 0\n",
    "    for text in section_texts:\n",
    "        sec_start = token_idx\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sents:\n",
    "            s_start = token_idx\n",
    "            for token in sent:\n",
    "                words.append(token.text)\n",
    "                token_idx += 1\n",
    "            s_end = token_idx\n",
    "            sentences.append([s_start, s_end])\n",
    "        sec_end = token_idx\n",
    "        if sec_end > sec_start:\n",
    "            sections.append([sec_start, sec_end])\n",
    "\n",
    "    return {\n",
    "        \"doc_id\": \"from_sections\",\n",
    "        \"words\": words,\n",
    "        \"sentences\": sentences,\n",
    "        \"sections\": sections\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = [sec['text'] for sec in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "# === Setup ===\n",
    "client = GrobidClient(config_path=\"./Grobid/config.json\")\n",
    "current_dir = Path(os.getcwd())\n",
    "output_jsonl_path = str(current_dir) + \"/SciREX-master/scirex_format_abstract.jsonl\"\n",
    "\n",
    "\n",
    "# === Processing Loop ===\n",
    "with open(output_jsonl_path, \"w\") as out_f:\n",
    "    for idx, paper in enumerate(papers_list[:30]):\n",
    "        pdf_path = str(current_dir / paper['Local PDF Path'])\n",
    "\n",
    "        try:\n",
    "            tei_xml = client.process_pdf(\n",
    "                service=\"processFulltextDocument\",\n",
    "                pdf_file=pdf_path,\n",
    "                generateIDs=True,  # â this is now required\n",
    "                consolidate_header=True,\n",
    "                consolidate_citations=False,\n",
    "                include_raw_citations=False,\n",
    "                include_raw_affiliations=False,\n",
    "                segment_sentences=True,\n",
    "                tei_coordinates=False\n",
    "            )\n",
    "            _, status, tei = tei_xml\n",
    "            abstract = [extract_abstract(tei)]\n",
    "            parsed = parse_sections(abstract, nlp)\n",
    "\n",
    "            # parsed = parse_tei(tei)\n",
    "            parsed[\"doc_id\"] = f\"doc_{idx:04d}\"  # doc_0000, doc_0001, ...\n",
    "            json.dump(parsed, out_f)\n",
    "            out_f.write(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {pdf_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)\n",
    "\n",
    "# === Setup ===\n",
    "client = GrobidClient(config_path=\"./Grobid/config.json\")\n",
    "current_dir = Path(os.getcwd())\n",
    "output_jsonl_path = str(current_dir) + \"/SciREX-master/scirex_format_experiment.jsonl\"\n",
    "\n",
    "\n",
    "# === Processing Loop ===\n",
    "with open(output_jsonl_path, \"w\") as out_f:\n",
    "    for idx, paper in enumerate(papers_list[:30]):\n",
    "        pdf_path = str(current_dir / paper['Local PDF Path'])\n",
    "\n",
    "        try:\n",
    "            tei_xml = client.process_pdf(\n",
    "                service=\"processFulltextDocument\",\n",
    "                pdf_file=pdf_path,\n",
    "                generateIDs=True,  # â this is now required\n",
    "                consolidate_header=True,\n",
    "                consolidate_citations=False,\n",
    "                include_raw_citations=False,\n",
    "                include_raw_affiliations=False,\n",
    "                segment_sentences=True,\n",
    "                tei_coordinates=False\n",
    "            )\n",
    "            _, status, tei = tei_xml\n",
    "            sections = extract_flat_sections_with_subtext(tei)\n",
    "            ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"])\n",
    "            best_match_section, best_score = ranked_sections[0]\n",
    "            best_match_section_text = [sections[[sec['title'] for sec in sections].index(best_match_section)]['text']]\n",
    "            parsed = parse_sections(best_match_section_text, nlp)\n",
    "\n",
    "            # parsed = parse_tei(tei)\n",
    "            parsed[\"doc_id\"] = f\"doc_{idx:04d}\"  # doc_0000, doc_0001, ...\n",
    "            json.dump(parsed, out_f)\n",
    "            out_f.write(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {pdf_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"papers_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "\n",
    "with open(str(current_dir) + '/SciREX-master/test_outputs/pdfs/ner_predictions_abstract.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Document ID: doc_0000\n",
      "  - Method: neural models\n",
      "  - Material: SQuAD\n",
      "  - Material: SNLI\n"
     ]
    }
   ],
   "source": [
    "first_doc = data[0]\n",
    "\n",
    "doc_id = first_doc[\"doc_id\"]\n",
    "words = first_doc[\"words\"]\n",
    "ner_spans = first_doc.get(\"ner\", [])\n",
    "\n",
    "print(f\"First Document ID: {doc_id}\")\n",
    "for start, end, label in ner_spans:\n",
    "    span_text = \" \".join(words[start:end])\n",
    "    print(f\"  - {label}: {span_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_per_doc = {}\n",
    "\n",
    "for entry in data:\n",
    "    doc_id = entry[\"doc_id\"]\n",
    "    words = entry[\"words\"]\n",
    "    ner_spans = entry.get(\"ner\", [])\n",
    "\n",
    "    tasks = set()\n",
    "    for start, end, label in ner_spans:\n",
    "        if label == \"Task\":\n",
    "            span_text = \" \".join(words[start:end])\n",
    "            tasks.add(span_text)\n",
    "    tasks = list(tasks)\n",
    "\n",
    "    tasks_per_doc[doc_id] = tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tasks_per_doc:\n",
    "    tasks_per_doc[i] = deduplicate_fuzzy(tasks_per_doc[i], threshold=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0000:\n",
      "doc_0001:\n",
      "doc_0002:\n",
      "doc_0003:\n",
      "doc_0004:\n",
      "doc_0005:\n",
      "doc_0006:\n",
      "doc_0007:\n",
      "doc_0008:\n",
      "doc_0009:\n",
      "doc_0010:\n",
      "doc_0011:\n",
      "doc_0012:\n",
      "doc_0013:\n",
      "doc_0014:\n",
      "doc_0015:\n",
      "doc_0016:\n",
      "doc_0017:\n",
      "doc_0018:\n",
      "doc_0019:\n",
      "doc_0020:\n",
      "doc_0021:\n",
      "doc_0022:\n",
      "doc_0023:\n",
      "doc_0024:\n",
      "doc_0025:\n",
      "doc_0026:\n",
      "doc_0027:\n",
      "doc_0028:\n",
      "doc_0029:\n"
     ]
    }
   ],
   "source": [
    "for doc_id, tasks in tasks_per_doc.items():\n",
    "    print(f\"{doc_id}:\")\n",
    "    for task in tasks:\n",
    "        print(f\"  - {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: ['ARC', 'Question Answering', 'Knowledge Graphs', 'AI2 Reasoning Challenge', 'Knowledge Graph Embeddings']\n",
      "Prediction: ['model evaluation', 'multiple - choice QA', 'span prediction QA', 'reasoning', 'sentence - level entailment', 'IR - ARC', 'IR - Google']\n",
      "Recall: 0.2000\n",
      "Precision: 0.1429\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction', 'Entity Embeddings']\n",
      "Prediction: ['link prediction task']\n",
      "Recall: 0.2500\n",
      "Precision: 1.0000\n",
      "Reference: ['Contrastive Learning', 'Knowledge Graphs', 'Knowledge Graph Embeddings', 'Word Embeddings', 'Learning Word Embeddings']\n",
      "Prediction: ['link prediction task', 'MRR', 'knowledge graph embeddings', 'ablation study', 'hypernym prediction task', 'ACE.We', 'order embeddings', 'word similarity tasks']\n",
      "Recall: 0.8000\n",
      "Precision: 0.5000\n",
      "Reference: ['Graph Embedding', 'Knowledge Base Completion', 'Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction', 'Knowledge Graph Embedding']\n",
      "Prediction: ['link prediction task', 'convergence', 'distilling liquids', 'training']\n",
      "Recall: 0.1667\n",
      "Precision: 0.2500\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction']\n",
      "Prediction: ['grid search', '1 - 1 training', 'optimisation']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Retrieval', 'Graph Embedding', 'Image Retrieval', 'Knowledge Graph Embeddings', 'Knowledge Graph Embedding', 'Zero-Shot Learning', 'Representation Learning']\n",
      "Prediction: ['visual - relational queries']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Graph Embedding', 'Question Answering', 'Knowledge Graph Completion', 'Knowledge Graph Embeddings', 'Link Prediction', 'Knowledge Graph Embedding', 'Triplet']\n",
      "Prediction: ['link prediction task', 'embedding knowledge bases', 'fastText embeddings', 'embeddings', 'link prediction evaluation']\n",
      "Recall: 0.7143\n",
      "Precision: 1.0000\n",
      "Reference: ['Knowledge Graph Embeddings', 'Vocal Bursts Type Prediction']\n",
      "Prediction: ['training']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction']\n",
      "Prediction: ['nearest neighbor', 'near miss se ings', 'negative sampling', 'link prediction', 'training']\n",
      "Recall: 0.3333\n",
      "Precision: 0.2000\n",
      "Reference: ['Knowledge Graphs', 'Graph Embedding', 'reinforcement-learning', 'Knowledge Graph Embeddings', 'Diversity', 'Knowledge Graph Embedding', 'Reinforcement Learning', 'Reinforcement Learning (RL)']\n",
      "Prediction: ['KG reasoning tasks', 'link prediction task', 'path finding', 'predicting target entities', 'fact prediction', 'multi - hop reasoning', 'knowledge base completion', 'NELL']\n",
      "Recall: 0.3750\n",
      "Precision: 0.3750\n",
      "Reference: ['Knowledge Graph Embeddings']\n",
      "Prediction: ['regularization', 'entity pairs', 'optimization', 'entity co - occurrences']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graph Embeddings', 'model', 'Question Answering', 'Knowledge Base Completion', 'General Classification']\n",
      "Prediction: ['KB completion']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction', 'Entity Resolution']\n",
      "Prediction: ['knowledge graph embeddings', 'machine learning', 'knowledge graphs', 'machine learning settings', 'relational learning problems', 'entity classification', 'link prediction']\n",
      "Recall: 1.0000\n",
      "Precision: 0.5714\n",
      "Reference: ['Knowledge Graphs', 'Entity Alignment', 'Translation', 'Knowledge Graph Embeddings']\n",
      "Prediction: ['calibration', 'entity matching', 'English - French task', 'candidates of triple matching', 'binary classification problem', 'cross - lingual entity matching', 'orthogonalization', 'relation alignment', 'monolingual and cross - lingual tasks', 'triple classification', 'distinguishing cross - lingual alignment', 'tail prediction', 'monolingual relations', 'crosslingual alignment', 'training', 'relation prediction', 'cross - lingual tasks', 'monolingual tasks', 'triplewise alignment verification', 'knowledge alignment examples', 'characterizing monolingual relations', 'characterization of monolingual knowledge', 'MTransE']\n",
      "Recall: 0.2500\n",
      "Precision: 0.0435\n",
      "Reference: ['Knowledge Graph Embeddings']\n",
      "Prediction: ['human evaluation', 'bot - bot chat', 'bot - human chat', 'selection', 'automatic evaluation', 'language variation', 'third - party evaluation task', 'cooperation', 'node embeddings', 'partner evaluation', 'interactive settings', 'Manual analysis', 'chit - chat', '\\n\\n Third - party Evaluation', 'human - likeness', 'decoding']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graph Embeddings', 'Inductive Bias']\n",
      "Prediction: []\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Inductive Learning']\n",
      "Prediction: ['perception', 'human cognitive episodic memory', 'static knowledge graphs']\n",
      "Recall: 0.6667\n",
      "Precision: 0.6667\n",
      "Reference: ['Knowledge Graph Embeddings', 'Decoder', 'Translation']\n",
      "Prediction: ['triple generation']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Prediction', 'Relation', 'Knowledge Graph Embeddings', 'Link Prediction']\n",
      "Prediction: ['subject entity embeddings', 'knowledge graphs', 'link prediction datasets', 'label smoothing', 'multi - task learning', 'link prediction']\n",
      "Recall: 0.6000\n",
      "Precision: 0.5000\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Reinforcement Learning', 'Reinforcement Learning (RL)']\n",
      "Prediction: ['KG', 'embeddings', 'unique entity predictions', 'Unified Medical Language Systems', 'Query answering', '\\n\\n KG Setup']\n",
      "Recall: 0.2500\n",
      "Precision: 0.1667\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction', 'Knowledge Graph Embedding', 'Graph Embedding']\n",
      "Prediction: ['network embeddings', 'link prediction in Knowledge graphs3', 'link prediction']\n",
      "Recall: 1.0000\n",
      "Precision: 1.6667\n",
      "Reference: ['Knowledge Graphs', 'Triple Classification', 'Prediction', 'Type prediction', 'Relation', 'Knowledge Graph Embeddings', 'Link Prediction']\n",
      "Prediction: ['entity prediction', 'binary classification task', 'sub - tasks', 'knowledge graph completion', 'Triple Classification', 'predictive tasks', 'DOLORES embeddings', 'link prediction tasks', 'Link Prediction', 'classification needs negative triples', 'head and tail link prediction tasks', 'predicting missing relation types', 'predictions']\n",
      "Recall: 0.7143\n",
      "Precision: 0.3846\n",
      "Reference: ['Recommendation Systems', 'Knowledge Graph Embeddings', 'Word Embeddings']\n",
      "Prediction: ['classification problem', 'hyperparameter tuning', 'binary sentiment evaluation', 'binary classification tasks', 'fine - tuning', 'IMDB Sentiment', 'document classification', 'interpretable classifiers', 'unsupervised representations']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Knowledge Graphs', 'Knowledge Graph Embeddings', 'Link Prediction', 'Word Embeddings']\n",
      "Prediction: ['training']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n",
      "Reference: ['Entity Disambiguation', 'Knowledge Graph Embeddings', 'Image Captioning', 'Opinion Mining']\n",
      "Prediction: ['entity disambiguation', 'NED', '\\n\\n Candidates generation', 'entity matching', 'unseen entities', 'disambiguation of mentions', 'entity linking', 'textual captions']\n",
      "Recall: 0.5000\n",
      "Precision: 0.2500\n",
      "Reference: ['Active Learning', 'Knowledge Graph Embeddings']\n",
      "Prediction: ['supervised and annotator development settings', 'nonexpert annotations', 'RASCAL annotation', 'active learning scenario', 'annotation task']\n",
      "Recall: 0.5000\n",
      "Precision: 0.2000\n",
      "Reference: ['Knowledge Graphs', 'Question Answering', 'Knowledge Graph Embeddings']\n",
      "Prediction: ['lackluster', 'real - world scenarios', 'meaningful embeddings', 'embeddings', 'open - world reasoning', 'NELL']\n",
      "Recall: 0.3333\n",
      "Precision: 0.1667\n",
      "Reference: ['Machine Translation', 'Entity Linking', 'Information Retrieval', 'Link Prediction', 'Knowledge Graph Embeddings', 'Metric Learning', 'Sentiment Analysis']\n",
      "Prediction: ['recommendation', 'entity linking task', 'knowledge base completion.3', 'entity search']\n",
      "Recall: 0.1429\n",
      "Precision: 0.2500\n",
      "Reference: ['Quantization', 'Knowledge Graphs', 'Knowledge Graph Completion', 'Knowledge Graph Embeddings', 'Tensor Decomposition']\n",
      "Prediction: ['KGC', 'filtered setting', 'knowledge graph completion', 'ranking']\n",
      "Recall: 0.6000\n",
      "Precision: 0.7500\n",
      "Reference: ['Relation', 'Knowledge Graph Embeddings', 'Relation Extraction']\n",
      "Prediction: ['learning', 'selection of sentences', 'held - out evaluation', 'ablation tests.+KATT', 'long - tails', 'long - tail relations', 'wrong labeling problem', 'knowledge transfer', 'RE', 'evaluation']\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "for i, paper in enumerate(papers_list):\n",
    "    title = paper['Title']\n",
    "    titles.append(title)\n",
    "for idx, data in enumerate(tasks_per_doc):\n",
    "\n",
    "    pred_text = tasks_per_doc[data]\n",
    "    reference = papers_list[idx]['Tasks']\n",
    "    ref_text = [item[0] for item in reference]\n",
    "    if len(ref_text) == 0:\n",
    "        recall = 1\n",
    "    elif len(pred_text) == 0:\n",
    "        recall = 0\n",
    "        precision = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        # For each reference entity, find the max similarity to predicted entities\n",
    "        max_similarities = compute_max_similarity(ref_text, pred_text, sim_model)\n",
    "\n",
    "        # Apply threshold\n",
    "        threshold = 0.6\n",
    "        num_matched = (max_similarities >= threshold).sum().item()\n",
    "        tp = num_matched\n",
    "        fn = len(ref_text) - tp         # false negatives\n",
    "        fp = len(pred_text) - tp    # false positives\n",
    "\n",
    "        # helper to avoid zero-division warnings Ã  la scikit-learn\n",
    "        def safe_div(num, denom):\n",
    "            return num / denom if denom else 0.0        # or np.nan\n",
    "\n",
    "        precision=safe_div(tp, tp + fp)\n",
    "        recall=safe_div(tp, tp + fn)\n",
    "        f1=safe_div(2 * precision * recall, precision + recall)\n",
    "    \n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Reference: {ref_text}\")\n",
    "    print(f\"Prediction: {pred_text}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.3132\n",
      "Average Precision: 0.3028\n",
      "Average F1: 0.2831\n"
     ]
    }
   ],
   "source": [
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_f1 = sum(f1s) / len(f1s)\n",
    "\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average F1: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://arxiv.org/pdf/1901.09590</td>\n",
       "      <td>model_type_pdfs/1901.09590.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://www.cip.ifi.lmu.de/~nickel/data/slides...</td>\n",
       "      <td>model_type_pdfs/slides-icml2011.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://proceedings.neurips.cc/paper/2012/file...</td>\n",
       "      <td>model_type_pdfs/0a1bf96b7165e962e90cb14648c946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://arxiv.org/pdf/1506.00999</td>\n",
       "      <td>model_type_pdfs/1506.00999.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://proceedings.mlr.press/v70/liu17d/liu17...</td>\n",
       "      <td>model_type_pdfs/liu17d.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category  \\\n",
       "0  Semantic matching models   \n",
       "1  Semantic matching models   \n",
       "2  Semantic matching models   \n",
       "3  Semantic matching models   \n",
       "4  Semantic matching models   \n",
       "\n",
       "                                                 url  \\\n",
       "0                   https://arxiv.org/pdf/1901.09590   \n",
       "1  https://www.cip.ifi.lmu.de/~nickel/data/slides...   \n",
       "2  https://proceedings.neurips.cc/paper/2012/file...   \n",
       "3                   https://arxiv.org/pdf/1506.00999   \n",
       "4  https://proceedings.mlr.press/v70/liu17d/liu17...   \n",
       "\n",
       "                                            filename  \n",
       "0                     model_type_pdfs/1901.09590.pdf  \n",
       "1                model_type_pdfs/slides-icml2011.pdf  \n",
       "2  model_type_pdfs/0a1bf96b7165e962e90cb14648c946...  \n",
       "3                     model_type_pdfs/1506.00999.pdf  \n",
       "4                         model_type_pdfs/liu17d.pdf  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"index.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper 0: model_type_pdfs/1901.09590.pdf\n",
      "Paper 1: model_type_pdfs/slides-icml2011.pdf\n",
      "Paper 2: model_type_pdfs/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf\n",
      "Paper 3: model_type_pdfs/1506.00999.pdf\n",
      "Paper 4: model_type_pdfs/liu17d.pdf\n",
      "Paper 5: model_type_pdfs/1412.6575.pdf\n",
      "Paper 6: model_type_pdfs/trouillon16.pdf\n",
      "Paper 7: model_type_pdfs/1802.04868.pdf\n",
      "Paper 8: model_type_pdfs/ds-paper-620.pdf\n",
      "Paper 9: model_type_pdfs/1705.10744.pdf\n",
      "Paper 10: model_type_pdfs/1805.02408.pdf\n",
      "Paper 11: model_type_pdfs/lacroix18a.pdf\n",
      "Paper 12: model_type_pdfs/1912.02686.pdf\n",
      "Paper 13: model_type_pdfs/1904.10281.pdf\n",
      "Paper 14: model_type_pdfs/1910.11583.pdf\n",
      "Paper 15: model_type_pdfs/b337e84de8752b27eda3a12363109e80-Paper.pdf\n",
      "Paper 16: model_type_pdfs/45634.pdf\n",
      "Paper 17: model_type_pdfs/1603.07704.pdf\n",
      "Paper 18: model_type_pdfs/1808.04122.pdf\n",
      "Paper 19: model_type_pdfs/1703.06103.pdf\n",
      "Paper 20: model_type_pdfs/1911.03082.pdf\n",
      "Paper 21: model_type_pdfs/1711.04071.pdf\n",
      "Paper 22: model_type_pdfs/85.pdf\n",
      "Paper 23: model_type_pdfs/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf\n",
      "Paper 24: model_type_pdfs/P15-1067.pdf\n",
      "Paper 25: model_type_pdfs/N16-1105.pdf\n",
      "Paper 26: model_type_pdfs/1801.08641.pdf\n",
      "Paper 27: model_type_pdfs/1606.08140.pdf\n",
      "Paper 28: model_type_pdfs/12887-57589-1-PB.pdf\n",
      "Paper 29: model_type_pdfs/PACLIC_28_Fan.pdf\n",
      "Paper 30: model_type_pdfs/1704.05908.pdf\n",
      "Paper 31: model_type_pdfs/0596.pdf\n",
      "Paper 32: model_type_pdfs/1904.12211.pdf\n",
      "Paper 33: model_type_pdfs/1509.05490.pdf\n",
      "Paper 34: model_type_pdfs/1902.10197.pdf\n",
      "Paper 35: model_type_pdfs/1709.04676.pdf\n",
      "Paper 36: model_type_pdfs/1708.04828.pdf\n",
      "Paper 37: model_type_pdfs/W18-3017.pdf\n",
      "Paper 38: model_type_pdfs/D15-1031.pdf\n",
      "Paper 39: model_type_pdfs/1609.07028.pdf\n",
      "Paper 40: model_type_pdfs/S18-2027.pdf\n",
      "Paper 41: model_type_pdfs/1809.01341.pdf\n",
      "Paper 42: model_type_pdfs/1903.05485.pdf\n",
      "Paper 43: model_type_pdfs/1802.00934.pdf\n",
      "Paper 44: model_type_pdfs/D14-1165.pdf\n",
      "Paper 45: model_type_pdfs/1508.02593.pdf\n",
      "Paper 46: model_type_pdfs/paperID314.pdf\n",
      "Paper 47: model_type_pdfs/P17-2051.pdf\n",
      "Paper 48: model_type_pdfs/download_file.pdf\n",
      "Paper 49: model_type_pdfs/P15-1125.pdf\n",
      "Paper 50: model_type_pdfs/P15-1009.pdf\n",
      "Paper 51: model_type_pdfs/2018.KDD%202018%20Hierarchical%20Taxonomy%20Aware%20Network%20Embedding.pdf\n",
      "Paper 52: model_type_pdfs/1805.09547.pdf\n",
      "Paper 53: model_type_pdfs/P19-1431.pdf\n",
      "Paper 54: model_type_pdfs/1906.01195.pdf\n",
      "Paper 55: model_type_pdfs/1808.09040.pdf\n",
      "Paper 56: model_type_pdfs/1911.04910.pdf\n",
      "Paper 57: model_type_pdfs/document.pdf\n",
      "Paper 58: model_type_pdfs/D11-1049.pdf\n",
      "Paper 59: model_type_pdfs/D15-1173.pdf\n",
      "Paper 60: model_type_pdfs/1504.06662.pdf\n",
      "Paper 61: model_type_pdfs/1506.01094.pdf\n",
      "Paper 62: model_type_pdfs/1607.01426.pdf\n",
      "Paper 63: model_type_pdfs/jiang17a.pdf\n",
      "Paper 64: model_type_pdfs/W17-2608.pdf\n",
      "Paper 65: model_type_pdfs/1806.04523.pdf\n",
      "Paper 66: model_type_pdfs/view.pdf\n",
      "Paper 67: model_type_pdfs/KR2ML_2019_paper_31.pdf\n",
      "Paper 68: model_type_pdfs/P16-1136.pdf\n",
      "Paper 69: model_type_pdfs/s00521-018-3384-6.pdf\n",
      "Paper 70: model_type_pdfs/S19-1016.pdf\n",
      "Paper 71: model_type_pdfs/1909.11864.pdf\n",
      "Paper 72: model_type_pdfs/kuzelka20a.pdf\n",
      "Paper 73: model_type_pdfs/2001.11850.pdf\n",
      "Paper 74: model_type_pdfs/0e55666a4ad822e0e34299df3591d979-Paper.pdf\n",
      "Paper 75: model_type_pdfs/0297.pdf\n",
      "Paper 76: model_type_pdfs/Tim_aitp.pdf\n",
      "Paper 77: model_type_pdfs/1807.08204.pdf\n",
      "Paper 78: model_type_pdfs/0c72cb7ee1512f800abe27823a792d03-Paper.pdf\n",
      "Paper 79: model_type_pdfs/264.pdf\n",
      "Paper 80: model_type_pdfs/ijcai2016.pdf\n",
      "Paper 81: model_type_pdfs/1903.03772.pdf\n",
      "Paper 82: model_type_pdfs/content.pdf\n",
      "Paper 83: model_type_pdfs/1903.08948.pdf\n",
      "Paper 84: model_type_pdfs/13e5ebb0fa112fe1b31a1067962d74a7-Paper.pdf\n",
      "Paper 85: model_type_pdfs/2004.04412.pdf\n",
      "Paper 86: model_type_pdfs/document.pdf\n",
      "Paper 87: model_type_pdfs/download.pdf\n",
      "Paper 88: model_type_pdfs/meilicke18ruleemb.pdf\n",
      "Paper 89: model_type_pdfs/D15-1031.pdf\n",
      "Paper 90: model_type_pdfs/N18-1068.pdf\n",
      "Paper 91: model_type_pdfs/1605.05416.pdf\n",
      "Paper 92: model_type_pdfs/1611.08661.pdf\n",
      "Paper 93: model_type_pdfs/1807.11761.pdf\n",
      "Paper 94: model_type_pdfs/SemaPro_2019_Analogy_inference_on_context_graphsJCM06092019.pdf\n",
      "Paper 95: model_type_pdfs/1909.03193.pdf\n",
      "Paper 96: model_type_pdfs/2004.14781.pdf\n",
      "Paper 97: model_type_pdfs/D16-1260.pdf\n",
      "Paper 98: model_type_pdfs/D18-1225.pdf\n",
      "Paper 99: model_type_pdfs/1807.00228.pdf\n",
      "Paper 100: model_type_pdfs/1809.03202.pdf\n",
      "Paper 101: model_type_pdfs/2004.04926.pdf\n",
      "Paper 102: model_type_pdfs/trivedi17a.pdf\n",
      "Paper 103: model_type_pdfs/1904.05530.pdf\n",
      "Paper 104: model_type_pdfs/2003.13432.pdf\n",
      "Paper 105: model_type_pdfs/2010.03526.pdf\n",
      "Paper 106: model_type_pdfs/1603.07704.pdf\n",
      "Paper 107: model_type_pdfs/P16-1137.pdf\n",
      "Paper 108: model_type_pdfs/K18-1014.pdf\n",
      "Paper 109: model_type_pdfs/1906.05317.pdf\n",
      "Paper 110: model_type_pdfs/2001.04170.pdf\n",
      "Paper 111: model_type_pdfs/1604.08642.pdf\n",
      "Paper 112: model_type_pdfs/rosso2020www_0.pdf\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    paper_filename = df.iloc[i]['filename']\n",
    "    print(f\"Paper {i}: {paper_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993a21e6222947ba85894ae930bc4a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "max_context_tokens = 32768 - 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_question = \"Given the model definitions mentioned before, choose one of the following taxonomy as the taxonomy of the model mentioned in this paper: Semantic matching model, Translation models, Internal side information inside KGs model, External extra information outside KGs or Other KGC Technologies ? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_context = '''The semantic matching models and The translation models only use the structure information of internal facts in KGs. The semantic matching models generally use semantic matching-based scoring functions and further consists of tensor/matrix factorization models and neural network models. The translation models apply distance-based scoring functions.\n",
    "While Internal side information inside KGs and External extra information outside KGs outside KGs cooperate with additional information (the inside or outside information of KGs except for the structure information) to achieve KGC. Internal side information inside KGs involved in KGs, including node attributes information, entity-related information, relation-related information, neighborhood information, relational path information; External extra information outside KGs outside KGs, mainly including two aspects: rule-based KGC and third-party data sources-based KGC. \n",
    "And if it is not any of the previous models, then it is Other KGC technologies.'''\n",
    "# model_context = '''Structure information-based KGC methods: which only use the structure information of internal facts in KGs. For this category, KGC is reviewed under semantic matching models and translation models according to the nature of their scoring functions. The semantic matching models generally use semantic matching-based scoring functions and further consists of tensor/matrix factorization models and neural network models. The translation models apply distance-based scoring function; \n",
    "# Additional information-based KGC methods: which cooperate with additional information (the inside or outside information of KGs except for the structure information) to achieve KGC. For this category, we further propose fine-grained taxonomies respective into two views about the usage of inside information or outside information: Internal side information inside KGs involved in KGs, including node attributes information, entity-related information, relation-related information, neighborhood information, relational path information; External extra information outside KGs outside KGs, mainly including two aspects: rule-based KGC and third-party data sources-based KGC.\n",
    "# And if it is not any of the previous models, then it is Other KGC technologies.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_model = []\n",
    "\n",
    "labels = []\n",
    "answers = []\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for i in range(10): #len(df)\n",
    "    paper_filename = df.iloc[i]['filename']\n",
    "    label = df.iloc[i]['category']\n",
    "    print(\"Processing paper:\", paper_filename)\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir/paper_filename)\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "    print(\"Grobid processing took:\", time.time() - start, \"seconds\")\n",
    "\n",
    "    # raw_text = extract_abstract(tei)\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "\n",
    "    # Example Usage\n",
    "    chunks = chunk_text(raw_text, tokenizer, max_tokens=max_context_tokens, overlap=200)\n",
    "\n",
    "\n",
    "\n",
    "    # Select which chunks to run\n",
    "\n",
    "    chunks_to_process = chunks\n",
    "\n",
    "    # Loop over the chosen chunks\n",
    "    for j, chunk in enumerate(chunks_to_process):\n",
    "        # Build the chat history\n",
    "        chat = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an assistant for question-answering tasks. Use only the provided context information to form your response.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"Context chunk: {chunk}\"\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Now, given this context for model taxonomy: {model_context} Answer this question: {model_question} Give back the answer only and only in a correct Python list format, for example: ['A']. If you don't know the answer, just return an empty list.\"\n",
    "            )\n",
    "            }           \n",
    "        ]\n",
    "\n",
    "        # 2: Apply the chat template\n",
    "        formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True,enable_thinking=True)\n",
    "        #print(\"Formatted chat:\\n\", formatted_chat)\n",
    "\n",
    "        # 3: Tokenize the chat (This can be combined with the previous step using tokenize=True)\n",
    "        model_inputs = tokenizer([formatted_chat], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "        # 4: Generate text from the model\n",
    "            generated_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=2048,\n",
    "                temperature=0.7,\n",
    "                top_p=0.8,\n",
    "                top_k=20,\n",
    "            )\n",
    "        output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "        # parsing thinking content\n",
    "        try:\n",
    "            # rindex finding 151668 (</think>)\n",
    "            index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "        except ValueError:\n",
    "            index = 0\n",
    "\n",
    "        thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "        content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "        print(\"label:\", label)\n",
    "        print(\"content:\", content)\n",
    "        print(\"thinking_content:\", thinking_content)\n",
    "\n",
    "        \n",
    "        labels.append(label)\n",
    "        answers.append(content)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "        del model_inputs, generated_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "        # Route responses into the right list\n",
    "        responses_model.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the responses to a JSON file\n",
    "import json\n",
    "\n",
    "output_file = \"model_taxonomy_responses.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"labels\": labels,\n",
    "        \"answers\": answers,\n",
    "    }, f, ensure_ascii=False, indent=4)\n",
    "# Calculate and print the average metrics   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses: 99\n",
      "Answer for paper 0: []\n",
      "Label for paper 0: Semantic matching models\n",
      "0\n",
      "Recall for paper 0: 0.0000\n",
      "Precision for paper 0: 0.0000\n",
      "F1 for paper 0: 0.0000\n",
      "Answer for paper 1: ['Semantic matching model']\n",
      "Label for paper 1: Semantic matching models\n",
      "1\n",
      "Recall for paper 1: 1.0000\n",
      "Precision for paper 1: 1.0000\n",
      "F1 for paper 1: 1.0000\n",
      "Answer for paper 2: ['Semantic matching model']\n",
      "Label for paper 2: Semantic matching models\n",
      "1\n",
      "Recall for paper 2: 1.0000\n",
      "Precision for paper 2: 1.0000\n",
      "F1 for paper 2: 1.0000\n",
      "Answer for paper 3: ['Semantic matching model']\n",
      "Label for paper 3: Semantic matching models\n",
      "1\n",
      "Recall for paper 3: 1.0000\n",
      "Precision for paper 3: 1.0000\n",
      "F1 for paper 3: 1.0000\n",
      "Answer for paper 4: ['Other KGC Technologies']\n",
      "Label for paper 4: Semantic matching models\n",
      "1\n",
      "Recall for paper 4: 0.0000\n",
      "Precision for paper 4: 0.0000\n",
      "F1 for paper 4: 0.0000\n",
      "Answer for paper 5: ['Semantic matching model']\n",
      "Label for paper 5: Semantic matching models\n",
      "1\n",
      "Recall for paper 5: 1.0000\n",
      "Precision for paper 5: 1.0000\n",
      "F1 for paper 5: 1.0000\n",
      "Answer for paper 6: ['Semantic matching model']\n",
      "Label for paper 6: Semantic matching models\n",
      "1\n",
      "Recall for paper 6: 1.0000\n",
      "Precision for paper 6: 1.0000\n",
      "F1 for paper 6: 1.0000\n",
      "Answer for paper 7: ['Translation models']\n",
      "Label for paper 7: Semantic matching models\n",
      "1\n",
      "Recall for paper 7: 0.0000\n",
      "Precision for paper 7: 0.0000\n",
      "F1 for paper 7: 0.0000\n",
      "Answer for paper 8: ['Other KGC Technologies']\n",
      "Label for paper 8: Semantic matching models\n",
      "1\n",
      "Recall for paper 8: 0.0000\n",
      "Precision for paper 8: 0.0000\n",
      "F1 for paper 8: 0.0000\n",
      "Answer for paper 9: ['Semantic matching model']\n",
      "Label for paper 9: Semantic matching models\n",
      "1\n",
      "Recall for paper 9: 1.0000\n",
      "Precision for paper 9: 1.0000\n",
      "F1 for paper 9: 1.0000\n",
      "Answer for paper 10: ['External extra information outside KGs']\n",
      "Label for paper 10: Semantic matching models\n",
      "1\n",
      "Recall for paper 10: 0.0000\n",
      "Precision for paper 10: 0.0000\n",
      "F1 for paper 10: 0.0000\n",
      "Answer for paper 11: ['Semantic matching models']\n",
      "Label for paper 11: Semantic matching models\n",
      "1\n",
      "Recall for paper 11: 1.0000\n",
      "Precision for paper 11: 1.0000\n",
      "F1 for paper 11: 1.0000\n",
      "Answer for paper 12: ['Semantic matching model']\n",
      "Label for paper 12: Semantic matching models\n",
      "1\n",
      "Recall for paper 12: 1.0000\n",
      "Precision for paper 12: 1.0000\n",
      "F1 for paper 12: 1.0000\n",
      "Answer for paper 13: ['Semantic matching model']\n",
      "Label for paper 13: Semantic matching models\n",
      "1\n",
      "Recall for paper 13: 1.0000\n",
      "Precision for paper 13: 1.0000\n",
      "F1 for paper 13: 1.0000\n",
      "Answer for paper 14: ['Other KGC Technologies']\n",
      "Label for paper 14: Semantic matching models\n",
      "1\n",
      "Recall for paper 14: 0.0000\n",
      "Precision for paper 14: 0.0000\n",
      "F1 for paper 14: 0.0000\n",
      "Answer for paper 15: ['Semantic matching model']\n",
      "Label for paper 15: Semantic matching models\n",
      "1\n",
      "Recall for paper 15: 1.0000\n",
      "Precision for paper 15: 1.0000\n",
      "F1 for paper 15: 1.0000\n",
      "Answer for paper 16: ['Other KGC Technologies']\n",
      "Label for paper 16: Semantic matching models\n",
      "1\n",
      "Recall for paper 16: 0.0000\n",
      "Precision for paper 16: 0.0000\n",
      "F1 for paper 16: 0.0000\n",
      "Answer for paper 17: ['Semantic matching model']\n",
      "Label for paper 17: Semantic matching models\n",
      "1\n",
      "Recall for paper 17: 1.0000\n",
      "Precision for paper 17: 1.0000\n",
      "F1 for paper 17: 1.0000\n",
      "Answer for paper 18: ['Other KGC Technologies']\n",
      "Label for paper 18: Semantic matching models\n",
      "1\n",
      "Recall for paper 18: 0.0000\n",
      "Precision for paper 18: 0.0000\n",
      "F1 for paper 18: 0.0000\n",
      "Answer for paper 19: ['Other KGC Technologies']\n",
      "Label for paper 19: Semantic matching models\n",
      "1\n",
      "Recall for paper 19: 0.0000\n",
      "Precision for paper 19: 0.0000\n",
      "F1 for paper 19: 0.0000\n",
      "Answer for paper 20: ['Internal side information inside KGs model']\n",
      "Label for paper 20: Semantic matching models\n",
      "1\n",
      "Recall for paper 20: 0.0000\n",
      "Precision for paper 20: 0.0000\n",
      "F1 for paper 20: 0.0000\n",
      "Answer for paper 21: ['Other KGC Technologies']\n",
      "Label for paper 21: Semantic matching models\n",
      "1\n",
      "Recall for paper 21: 0.0000\n",
      "Precision for paper 21: 0.0000\n",
      "F1 for paper 21: 0.0000\n",
      "Answer for paper 22: ['Other KGC Technologies']\n",
      "Label for paper 22: Semantic matching models\n",
      "1\n",
      "Recall for paper 22: 0.0000\n",
      "Precision for paper 22: 0.0000\n",
      "F1 for paper 22: 0.0000\n",
      "Answer for paper 23: ['Translation models']\n",
      "Label for paper 23: Translation models\n",
      "1\n",
      "Recall for paper 23: 1.0000\n",
      "Precision for paper 23: 1.0000\n",
      "F1 for paper 23: 1.0000\n",
      "Answer for paper 24: ['Semantic matching model']\n",
      "Label for paper 24: Translation models\n",
      "1\n",
      "Recall for paper 24: 0.0000\n",
      "Precision for paper 24: 0.0000\n",
      "F1 for paper 24: 0.0000\n",
      "Answer for paper 25: ['Translation models']\n",
      "Label for paper 25: Translation models\n",
      "1\n",
      "Recall for paper 25: 1.0000\n",
      "Precision for paper 25: 1.0000\n",
      "F1 for paper 25: 1.0000\n",
      "Answer for paper 26: ['Translation models']\n",
      "Label for paper 26: Translation models\n",
      "1\n",
      "Recall for paper 26: 1.0000\n",
      "Precision for paper 26: 1.0000\n",
      "F1 for paper 26: 1.0000\n",
      "Answer for paper 27: ['Translation models']\n",
      "Label for paper 27: Translation models\n",
      "1\n",
      "Recall for paper 27: 1.0000\n",
      "Precision for paper 27: 1.0000\n",
      "F1 for paper 27: 1.0000\n",
      "Answer for paper 28: ['Translation models']\n",
      "Label for paper 28: Translation models\n",
      "1\n",
      "Recall for paper 28: 1.0000\n",
      "Precision for paper 28: 1.0000\n",
      "F1 for paper 28: 1.0000\n",
      "Answer for paper 29: ['Internal side information inside KGs model']\n",
      "Label for paper 29: Translation models\n",
      "1\n",
      "Recall for paper 29: 0.0000\n",
      "Precision for paper 29: 0.0000\n",
      "F1 for paper 29: 0.0000\n",
      "Answer for paper 30: ['Other KGC Technologies']\n",
      "Label for paper 30: Translation models\n",
      "1\n",
      "Recall for paper 30: 0.0000\n",
      "Precision for paper 30: 0.0000\n",
      "F1 for paper 30: 0.0000\n",
      "Answer for paper 31: ['Translation models']\n",
      "Label for paper 31: Translation models\n",
      "1\n",
      "Recall for paper 31: 1.0000\n",
      "Precision for paper 31: 1.0000\n",
      "F1 for paper 31: 1.0000\n",
      "Answer for paper 32: ['Translation models']\n",
      "Label for paper 32: Translation models\n",
      "1\n",
      "Recall for paper 32: 1.0000\n",
      "Precision for paper 32: 1.0000\n",
      "F1 for paper 32: 1.0000\n",
      "Answer for paper 33: ['Other KGC Technologies']\n",
      "Label for paper 33: Translation models\n",
      "1\n",
      "Recall for paper 33: 0.0000\n",
      "Precision for paper 33: 0.0000\n",
      "F1 for paper 33: 0.0000\n",
      "Answer for paper 34: ['Other KGC Technologies']\n",
      "Label for paper 34: Translation models\n",
      "1\n",
      "Recall for paper 34: 0.0000\n",
      "Precision for paper 34: 0.0000\n",
      "F1 for paper 34: 0.0000\n",
      "Answer for paper 35: ['Other KGC Technologies']\n",
      "Label for paper 35: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 35: 0.0000\n",
      "Precision for paper 35: 0.0000\n",
      "F1 for paper 35: 0.0000\n",
      "Answer for paper 36: ['Other KGC Technologies']\n",
      "Label for paper 36: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 36: 0.0000\n",
      "Precision for paper 36: 0.0000\n",
      "F1 for paper 36: 0.0000\n",
      "Answer for paper 37: ['External extra information outside KGs']\n",
      "Label for paper 37: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 37: 0.0000\n",
      "Precision for paper 37: 0.0000\n",
      "F1 for paper 37: 0.0000\n",
      "Answer for paper 38: ['External extra information outside KGs']\n",
      "Label for paper 38: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 38: 0.0000\n",
      "Precision for paper 38: 0.0000\n",
      "F1 for paper 38: 0.0000\n",
      "Answer for paper 39: ['External extra information outside KGs']\n",
      "Label for paper 39: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 39: 0.0000\n",
      "Precision for paper 39: 0.0000\n",
      "F1 for paper 39: 0.0000\n",
      "Answer for paper 40: ['External extra information outside KGs']\n",
      "Label for paper 40: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 40: 0.0000\n",
      "Precision for paper 40: 0.0000\n",
      "F1 for paper 40: 0.0000\n",
      "Answer for paper 41: ['Other KGC Technologies']\n",
      "Label for paper 41: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 41: 0.0000\n",
      "Precision for paper 41: 0.0000\n",
      "F1 for paper 41: 0.0000\n",
      "Answer for paper 42: ['Semantic matching model']\n",
      "Label for paper 42: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 42: 0.0000\n",
      "Precision for paper 42: 0.0000\n",
      "F1 for paper 42: 0.0000\n",
      "Answer for paper 43: ['Other KGC Technologies']\n",
      "Label for paper 43: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 43: 0.0000\n",
      "Precision for paper 43: 0.0000\n",
      "F1 for paper 43: 0.0000\n",
      "Answer for paper 44: ['Other KGC Technologies']\n",
      "Label for paper 44: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 44: 0.0000\n",
      "Precision for paper 44: 0.0000\n",
      "F1 for paper 44: 0.0000\n",
      "Answer for paper 45: ['Other KGC Technologies']\n",
      "Label for paper 45: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 45: 0.0000\n",
      "Precision for paper 45: 0.0000\n",
      "F1 for paper 45: 0.0000\n",
      "Answer for paper 46: ['Other KGC Technologies']\n",
      "Label for paper 46: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 46: 0.0000\n",
      "Precision for paper 46: 0.0000\n",
      "F1 for paper 46: 0.0000\n",
      "Answer for paper 47: ['Other KGC Technologies']\n",
      "Label for paper 47: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 47: 0.0000\n",
      "Precision for paper 47: 0.0000\n",
      "F1 for paper 47: 0.0000\n",
      "Answer for paper 48: ['External extra information outside KGs']\n",
      "Label for paper 48: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 48: 0.0000\n",
      "Precision for paper 48: 0.0000\n",
      "F1 for paper 48: 0.0000\n",
      "Answer for paper 49: ['Semantic matching model', 'Translation models', 'Internal side information inside KGs model', 'External extra information outside KGs', 'Other KGC Technologies']\n",
      "Label for paper 49: Internal side information inside KGs\n",
      "5\n",
      "Recall for paper 49: 0.0000\n",
      "Precision for paper 49: 0.0000\n",
      "F1 for paper 49: 0.0000\n",
      "Answer for paper 50: ['Semantically Smooth Embedding']\n",
      "Label for paper 50: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 50: 0.0000\n",
      "Precision for paper 50: 0.0000\n",
      "F1 for paper 50: 0.0000\n",
      "Answer for paper 51: ['Other KGC Technologies']\n",
      "Label for paper 51: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 51: 0.0000\n",
      "Precision for paper 51: 0.0000\n",
      "F1 for paper 51: 0.0000\n",
      "Answer for paper 52: ['Other KGC Technologies']\n",
      "Label for paper 52: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 52: 0.0000\n",
      "Precision for paper 52: 0.0000\n",
      "F1 for paper 52: 0.0000\n",
      "Answer for paper 53: ['Other KGC Technologies']\n",
      "Label for paper 53: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 53: 0.0000\n",
      "Precision for paper 53: 0.0000\n",
      "F1 for paper 53: 0.0000\n",
      "Answer for paper 54: ['Other KGC Technologies']\n",
      "Label for paper 54: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 54: 0.0000\n",
      "Precision for paper 54: 0.0000\n",
      "F1 for paper 54: 0.0000\n",
      "Answer for paper 55: ['Internal side information inside KGs model']\n",
      "Label for paper 55: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 55: 1.0000\n",
      "Precision for paper 55: 1.0000\n",
      "F1 for paper 55: 1.0000\n",
      "Answer for paper 56: ['Translation models']\n",
      "Label for paper 56: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 56: 0.0000\n",
      "Precision for paper 56: 0.0000\n",
      "F1 for paper 56: 0.0000\n",
      "Answer for paper 57: ['Semantic matching model']\n",
      "Label for paper 57: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 57: 0.0000\n",
      "Precision for paper 57: 0.0000\n",
      "F1 for paper 57: 0.0000\n",
      "Answer for paper 58: ['Semantic matching model']\n",
      "Label for paper 58: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 58: 0.0000\n",
      "Precision for paper 58: 0.0000\n",
      "F1 for paper 58: 0.0000\n",
      "Answer for paper 59: ['Semantic matching model']\n",
      "Label for paper 59: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 59: 0.0000\n",
      "Precision for paper 59: 0.0000\n",
      "F1 for paper 59: 0.0000\n",
      "Answer for paper 60: ['Compositional Vector Space Models for Knowledge Base Completion']\n",
      "Label for paper 60: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 60: 0.0000\n",
      "Precision for paper 60: 0.0000\n",
      "F1 for paper 60: 0.0000\n",
      "Answer for paper 61: ['Other KGC Technologies']\n",
      "Label for paper 61: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 61: 0.0000\n",
      "Precision for paper 61: 0.0000\n",
      "F1 for paper 61: 0.0000\n",
      "Answer for paper 62: ['Other KGC Technologies']\n",
      "Label for paper 62: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 62: 0.0000\n",
      "Precision for paper 62: 0.0000\n",
      "F1 for paper 62: 0.0000\n",
      "Answer for paper 63: ['Other KGC Technologies']\n",
      "Label for paper 63: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 63: 0.0000\n",
      "Precision for paper 63: 0.0000\n",
      "F1 for paper 63: 0.0000\n",
      "Answer for paper 64: ['Internal side information inside KGs model']\n",
      "Label for paper 64: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 64: 1.0000\n",
      "Precision for paper 64: 1.0000\n",
      "F1 for paper 64: 1.0000\n",
      "Answer for paper 65: ['Internal side information inside KGs model']\n",
      "Label for paper 65: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 65: 1.0000\n",
      "Precision for paper 65: 1.0000\n",
      "F1 for paper 65: 1.0000\n",
      "Answer for paper 66: ['Internal side information inside KGs model']\n",
      "Label for paper 66: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 66: 1.0000\n",
      "Precision for paper 66: 1.0000\n",
      "F1 for paper 66: 1.0000\n",
      "Answer for paper 67: ['Internal side information inside KGs model']\n",
      "Label for paper 67: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 67: 1.0000\n",
      "Precision for paper 67: 1.0000\n",
      "F1 for paper 67: 1.0000\n",
      "Answer for paper 68: ['Internal side information inside KGs model']\n",
      "Label for paper 68: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 68: 1.0000\n",
      "Precision for paper 68: 1.0000\n",
      "F1 for paper 68: 1.0000\n",
      "Answer for paper 69: ['Semantic matching model']\n",
      "Label for paper 69: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 69: 0.0000\n",
      "Precision for paper 69: 0.0000\n",
      "F1 for paper 69: 0.0000\n",
      "Answer for paper 70: ['Other KGC Technologies']\n",
      "Label for paper 70: Internal side information inside KGs\n",
      "1\n",
      "Recall for paper 70: 0.0000\n",
      "Precision for paper 70: 0.0000\n",
      "F1 for paper 70: 0.0000\n",
      "Answer for paper 71: ['Other KGC Technologies']\n",
      "Label for paper 71: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 71: 0.0000\n",
      "Precision for paper 71: 0.0000\n",
      "F1 for paper 71: 0.0000\n",
      "Answer for paper 72: ['Other KGC Technologies']\n",
      "Label for paper 72: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 72: 0.0000\n",
      "Precision for paper 72: 0.0000\n",
      "F1 for paper 72: 0.0000\n",
      "Answer for paper 73: ['Internal side information inside KGs model']\n",
      "Label for paper 73: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 73: 0.0000\n",
      "Precision for paper 73: 0.0000\n",
      "F1 for paper 73: 0.0000\n",
      "Answer for paper 74: ['Semantic matching model']\n",
      "Label for paper 74: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 74: 0.0000\n",
      "Precision for paper 74: 0.0000\n",
      "F1 for paper 74: 0.0000\n",
      "Answer for paper 75: ['Semantic matching model']\n",
      "Label for paper 75: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 75: 0.0000\n",
      "Precision for paper 75: 0.0000\n",
      "F1 for paper 75: 0.0000\n",
      "Answer for paper 76: ['Semantic matching model']\n",
      "Label for paper 76: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 76: 0.0000\n",
      "Precision for paper 76: 0.0000\n",
      "F1 for paper 76: 0.0000\n",
      "Answer for paper 77: ['Other KGC Technologies']\n",
      "Label for paper 77: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 77: 0.0000\n",
      "Precision for paper 77: 0.0000\n",
      "F1 for paper 77: 0.0000\n",
      "Answer for paper 78: ['Other KGC Technologies']\n",
      "Label for paper 78: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 78: 0.0000\n",
      "Precision for paper 78: 0.0000\n",
      "F1 for paper 78: 0.0000\n",
      "Answer for paper 79: ['Internal side information inside KGs model']\n",
      "Label for paper 79: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 79: 0.0000\n",
      "Precision for paper 79: 0.0000\n",
      "F1 for paper 79: 0.0000\n",
      "Answer for paper 80: ['Other KGC Technologies']\n",
      "Label for paper 80: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 80: 0.0000\n",
      "Precision for paper 80: 0.0000\n",
      "F1 for paper 80: 0.0000\n",
      "Answer for paper 81: ['External extra information outside KGs']\n",
      "Label for paper 81: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 81: 1.0000\n",
      "Precision for paper 81: 1.0000\n",
      "F1 for paper 81: 1.0000\n",
      "Answer for paper 82: ['Other KGC Technologies']\n",
      "Label for paper 82: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 82: 0.0000\n",
      "Precision for paper 82: 0.0000\n",
      "F1 for paper 82: 0.0000\n",
      "Answer for paper 83: ['Other KGC Technologies']\n",
      "Label for paper 83: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 83: 0.0000\n",
      "Precision for paper 83: 0.0000\n",
      "F1 for paper 83: 0.0000\n",
      "Answer for paper 84: ['Other KGC Technologies']\n",
      "Label for paper 84: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 84: 0.0000\n",
      "Precision for paper 84: 0.0000\n",
      "F1 for paper 84: 0.0000\n",
      "Answer for paper 85: ['Semantic matching model']\n",
      "Label for paper 85: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 85: 0.0000\n",
      "Precision for paper 85: 0.0000\n",
      "F1 for paper 85: 0.0000\n",
      "Answer for paper 86: ['Other KGC Technologies']\n",
      "Label for paper 86: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 86: 0.0000\n",
      "Precision for paper 86: 0.0000\n",
      "F1 for paper 86: 0.0000\n",
      "Answer for paper 87: ['Other KGC Technologies']\n",
      "Label for paper 87: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 87: 0.0000\n",
      "Precision for paper 87: 0.0000\n",
      "F1 for paper 87: 0.0000\n",
      "Answer for paper 88: ['External extra information outside KGs']\n",
      "Label for paper 88: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 88: 1.0000\n",
      "Precision for paper 88: 1.0000\n",
      "F1 for paper 88: 1.0000\n",
      "Answer for paper 89: ['Other KGC Technologies']\n",
      "Label for paper 89: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 89: 0.0000\n",
      "Precision for paper 89: 0.0000\n",
      "F1 for paper 89: 0.0000\n",
      "Answer for paper 90: ['External extra information outside KGs']\n",
      "Label for paper 90: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 90: 1.0000\n",
      "Precision for paper 90: 1.0000\n",
      "F1 for paper 90: 1.0000\n",
      "Answer for paper 91: ['Other KGC Technologies']\n",
      "Label for paper 91: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 91: 0.0000\n",
      "Precision for paper 91: 0.0000\n",
      "F1 for paper 91: 0.0000\n",
      "Answer for paper 92: ['External extra information outside KGs']\n",
      "Label for paper 92: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 92: 1.0000\n",
      "Precision for paper 92: 1.0000\n",
      "F1 for paper 92: 1.0000\n",
      "Answer for paper 93: ['Semantic matching model']\n",
      "Label for paper 93: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 93: 0.0000\n",
      "Precision for paper 93: 0.0000\n",
      "F1 for paper 93: 0.0000\n",
      "Answer for paper 94: ['External extra information outside KGs']\n",
      "Label for paper 94: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 94: 1.0000\n",
      "Precision for paper 94: 1.0000\n",
      "F1 for paper 94: 1.0000\n",
      "Answer for paper 95: ['Other KGC Technologies']\n",
      "Label for paper 95: External extra information outside KGs\n",
      "1\n",
      "Recall for paper 95: 0.0000\n",
      "Precision for paper 95: 0.0000\n",
      "F1 for paper 95: 0.0000\n",
      "Answer for paper 96: ['Other KGC Technologies']\n",
      "Label for paper 96: Other KGC Technologies\n",
      "1\n",
      "Recall for paper 96: 1.0000\n",
      "Precision for paper 96: 1.0000\n",
      "F1 for paper 96: 1.0000\n",
      "Answer for paper 97: ['Other KGC Technologies']\n",
      "Label for paper 97: Other KGC Technologies\n",
      "1\n",
      "Recall for paper 97: 1.0000\n",
      "Precision for paper 97: 1.0000\n",
      "F1 for paper 97: 1.0000\n",
      "Answer for paper 98: ['Other KGC Technologies']\n",
      "Label for paper 98: Other KGC Technologies\n",
      "1\n",
      "Recall for paper 98: 1.0000\n",
      "Precision for paper 98: 1.0000\n",
      "F1 for paper 98: 1.0000\n",
      "Mean Author Recall: 0.3232\n",
      "Mean Author Precision: 0.3232\n",
      "Mean Author F1: 0.3232\n"
     ]
    }
   ],
   "source": [
    "# Save the responses to a JSON file\n",
    "import json\n",
    "\n",
    "with open(\"model_taxonomy_responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "    \n",
    "labels = responses[\"labels\"]\n",
    "answers = responses[\"answers\"]\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == \"Other models\":\n",
    "        labels[i] = \"Other KGC Technologies\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of responses:\", len(answers))\n",
    "\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(len(answers)):\n",
    "    label = labels[i]\n",
    "    answer = answers[i]\n",
    "    if isinstance(answer, str):\n",
    "        answer = ast.literal_eval(answer)\n",
    "        print (f\"Answer for paper {i}: {answer}\")\n",
    "        print(f\"Label for paper {i}: {label}\")\n",
    "        print(len(answer))\n",
    "    if len(answer) != 1:\n",
    "        recall = 0\n",
    "        precision = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        # For each reference entity, find the max similarity to predicted entities\n",
    "        max_similarities = compute_max_similarity([label], answer, sim_model)\n",
    "\n",
    "        # Apply threshold\n",
    "        threshold = 0.8\n",
    "        num_matched = (max_similarities >= threshold).sum().item()\n",
    "        \n",
    "        tp = num_matched\n",
    "        fn = 1 - tp         # false negatives\n",
    "        fp = 1 - tp\n",
    "           \n",
    "        # helper to avoid zero-division warnings Ã  la scikit-learn\n",
    "        def safe_div(num, denom):\n",
    "            return num / denom if denom else 0.0\n",
    "        precision = safe_div(tp, tp + fp)\n",
    "        recall    = safe_div(tp, tp + fn)\n",
    "        f1        = safe_div(2 * precision * recall, precision + recall)\n",
    "        \n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    print(f\"Recall for paper {i}: {recall:.4f}\")\n",
    "    print(f\"Precision for paper {i}: {precision:.4f}\")\n",
    "    print(f\"F1 for paper {i}: {f1:.4f}\")\n",
    "# Calculate and print the average metrics   \n",
    "average_autor_grobid_recall = sum(recalls) / len(recalls)\n",
    "average_autor_grobid_precision = sum(precisions) / len(precisions)\n",
    "average_autor_grobid_f1 = sum(f1s) / len(f1s)\n",
    "\n",
    "print(f\"Mean Author Recall: {average_autor_grobid_recall:.4f}\")\n",
    "print(f\"Mean Author Precision: {average_autor_grobid_precision:.4f}\")\n",
    "print(f\"Mean Author F1: {average_autor_grobid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the responses to a JSON file\n",
    "import json\n",
    "\n",
    "# open the CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"index.csv\")\n",
    "df.head(5)\n",
    "labels = []\n",
    "# Create a mapping from category names to numerical labels\n",
    "category_mapping = {\n",
    "    \"Semantic matching models\": 0,\n",
    "    \"Translation models\": 1,\n",
    "    \"Internal side information inside KGs\": 2,\n",
    "    \"External extra information outside KGs\": 3,\n",
    "    \"Other models\": 4\n",
    "}\n",
    "# Initialize labels based on the category mapping\n",
    "labels = [category_mapping.get(category, 4) for category in df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://arxiv.org/pdf/1603.07704</td>\n",
       "      <td>model_type_pdfs/1603.07704.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Internal side information inside KGs</td>\n",
       "      <td>https://aclanthology.org/D15-1031.pdf</td>\n",
       "      <td>model_type_pdfs/D15-1031.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>External extra information outside KGs</td>\n",
       "      <td>https://aclanthology.org/D15-1031.pdf</td>\n",
       "      <td>model_type_pdfs/D15-1031.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://arxiv.org/pdf/1603.07704</td>\n",
       "      <td>model_type_pdfs/1603.07704.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   category  \\\n",
       "17                 Semantic matching models   \n",
       "38     Internal side information inside KGs   \n",
       "89   External extra information outside KGs   \n",
       "106                            Other models   \n",
       "\n",
       "                                       url                        filename  \n",
       "17        https://arxiv.org/pdf/1603.07704  model_type_pdfs/1603.07704.pdf  \n",
       "38   https://aclanthology.org/D15-1031.pdf    model_type_pdfs/D15-1031.pdf  \n",
       "89   https://aclanthology.org/D15-1031.pdf    model_type_pdfs/D15-1031.pdf  \n",
       "106       https://arxiv.org/pdf/1603.07704  model_type_pdfs/1603.07704.pdf  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df['url'].duplicated(keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://arxiv.org/pdf/1901.09590</td>\n",
       "      <td>model_type_pdfs/1901.09590.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://www.cip.ifi.lmu.de/~nickel/data/slides...</td>\n",
       "      <td>model_type_pdfs/slides-icml2011.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://proceedings.neurips.cc/paper/2012/file...</td>\n",
       "      <td>model_type_pdfs/0a1bf96b7165e962e90cb14648c946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://arxiv.org/pdf/1506.00999</td>\n",
       "      <td>model_type_pdfs/1506.00999.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semantic matching models</td>\n",
       "      <td>https://proceedings.mlr.press/v70/liu17d/liu17...</td>\n",
       "      <td>model_type_pdfs/liu17d.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://aclanthology.org/K18-1014.pdf</td>\n",
       "      <td>model_type_pdfs/K18-1014.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://arxiv.org/pdf/1906.05317</td>\n",
       "      <td>model_type_pdfs/1906.05317.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://arxiv.org/pdf/2001.04170</td>\n",
       "      <td>model_type_pdfs/2001.04170.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://arxiv.org/pdf/1604.08642</td>\n",
       "      <td>model_type_pdfs/1604.08642.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Other models</td>\n",
       "      <td>https://sonar.ch/documents/325395/files/rosso2...</td>\n",
       "      <td>model_type_pdfs/rosso2020www_0.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category  \\\n",
       "0    Semantic matching models   \n",
       "1    Semantic matching models   \n",
       "2    Semantic matching models   \n",
       "3    Semantic matching models   \n",
       "4    Semantic matching models   \n",
       "..                        ...   \n",
       "108              Other models   \n",
       "109              Other models   \n",
       "110              Other models   \n",
       "111              Other models   \n",
       "112              Other models   \n",
       "\n",
       "                                                   url  \\\n",
       "0                     https://arxiv.org/pdf/1901.09590   \n",
       "1    https://www.cip.ifi.lmu.de/~nickel/data/slides...   \n",
       "2    https://proceedings.neurips.cc/paper/2012/file...   \n",
       "3                     https://arxiv.org/pdf/1506.00999   \n",
       "4    https://proceedings.mlr.press/v70/liu17d/liu17...   \n",
       "..                                                 ...   \n",
       "108              https://aclanthology.org/K18-1014.pdf   \n",
       "109                   https://arxiv.org/pdf/1906.05317   \n",
       "110                   https://arxiv.org/pdf/2001.04170   \n",
       "111                   https://arxiv.org/pdf/1604.08642   \n",
       "112  https://sonar.ch/documents/325395/files/rosso2...   \n",
       "\n",
       "                                              filename  \n",
       "0                       model_type_pdfs/1901.09590.pdf  \n",
       "1                  model_type_pdfs/slides-icml2011.pdf  \n",
       "2    model_type_pdfs/0a1bf96b7165e962e90cb14648c946...  \n",
       "3                       model_type_pdfs/1506.00999.pdf  \n",
       "4                           model_type_pdfs/liu17d.pdf  \n",
       "..                                                 ...  \n",
       "108                       model_type_pdfs/K18-1014.pdf  \n",
       "109                     model_type_pdfs/1906.05317.pdf  \n",
       "110                     model_type_pdfs/2001.04170.pdf  \n",
       "111                     model_type_pdfs/1604.08642.pdf  \n",
       "112                 model_type_pdfs/rosso2020www_0.pdf  \n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ~df['url'].duplicated(keep=False)\n",
    "df_unique_only = df[mask]\n",
    "df_unique_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize labels based on the category mapping\n",
    "labels_unique = [category_mapping.get(category, 4) for category in df_unique_only['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Processing paper: model_type_pdfs/1901.09590.pdf\n",
      "Grobid processing took: 1.5844838619232178 seconds\n",
      "Processing paper: model_type_pdfs/slides-icml2011.pdf\n",
      "Grobid processing took: 1.1370532512664795 seconds\n",
      "No abstract found, skipping.\n",
      "Processing paper: model_type_pdfs/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf\n",
      "Grobid processing took: 1.4528651237487793 seconds\n",
      "Processing paper: model_type_pdfs/1506.00999.pdf\n",
      "Grobid processing took: 1.9051806926727295 seconds\n",
      "Processing paper: model_type_pdfs/liu17d.pdf\n",
      "Grobid processing took: 1.5787098407745361 seconds\n",
      "Processing paper: model_type_pdfs/1412.6575.pdf\n",
      "Grobid processing took: 1.4570648670196533 seconds\n",
      "Processing paper: model_type_pdfs/trouillon16.pdf\n",
      "Grobid processing took: 1.5201945304870605 seconds\n",
      "Processing paper: model_type_pdfs/1802.04868.pdf\n",
      "Grobid processing took: 1.6138768196105957 seconds\n",
      "Processing paper: model_type_pdfs/ds-paper-620.pdf\n",
      "Grobid processing took: 1.6179580688476562 seconds\n",
      "Processing paper: model_type_pdfs/1705.10744.pdf\n",
      "Grobid processing took: 1.309236764907837 seconds\n",
      "Processing paper: model_type_pdfs/1805.02408.pdf\n",
      "Grobid processing took: 1.6971385478973389 seconds\n",
      "Processing paper: model_type_pdfs/lacroix18a.pdf\n",
      "Grobid processing took: 1.5865769386291504 seconds\n",
      "Processing paper: model_type_pdfs/1912.02686.pdf\n",
      "Grobid processing took: 1.7376203536987305 seconds\n",
      "Processing paper: model_type_pdfs/1904.10281.pdf\n",
      "Grobid processing took: 1.568544626235962 seconds\n",
      "Processing paper: model_type_pdfs/1910.11583.pdf\n",
      "Grobid processing took: 1.371065616607666 seconds\n",
      "Processing paper: model_type_pdfs/b337e84de8752b27eda3a12363109e80-Paper.pdf\n",
      "Grobid processing took: 1.4281892776489258 seconds\n",
      "Processing paper: model_type_pdfs/45634.pdf\n",
      "Grobid processing took: 1.670154333114624 seconds\n",
      "Processing paper: model_type_pdfs/1808.04122.pdf\n",
      "Grobid processing took: 1.5540134906768799 seconds\n",
      "Processing paper: model_type_pdfs/1703.06103.pdf\n",
      "Grobid processing took: 1.599712610244751 seconds\n",
      "Processing paper: model_type_pdfs/1911.03082.pdf\n",
      "Grobid processing took: 1.685610294342041 seconds\n",
      "Processing paper: model_type_pdfs/1711.04071.pdf\n",
      "Grobid processing took: 1.45631742477417 seconds\n",
      "Processing paper: model_type_pdfs/85.pdf\n",
      "Grobid processing took: 1.4232416152954102 seconds\n",
      "Processing paper: model_type_pdfs/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf\n",
      "Grobid processing took: 1.4712021350860596 seconds\n",
      "Processing paper: model_type_pdfs/P15-1067.pdf\n",
      "Grobid processing took: 1.5159835815429688 seconds\n",
      "Processing paper: model_type_pdfs/N16-1105.pdf\n",
      "Grobid processing took: 1.4493279457092285 seconds\n",
      "Processing paper: model_type_pdfs/1801.08641.pdf\n",
      "Grobid processing took: 1.3677845001220703 seconds\n",
      "Processing paper: model_type_pdfs/1606.08140.pdf\n",
      "Grobid processing took: 1.4682049751281738 seconds\n",
      "Processing paper: model_type_pdfs/12887-57589-1-PB.pdf\n",
      "Grobid processing took: 1.3070411682128906 seconds\n",
      "Processing paper: model_type_pdfs/PACLIC_28_Fan.pdf\n",
      "Grobid processing took: 1.494537353515625 seconds\n",
      "Processing paper: model_type_pdfs/1704.05908.pdf\n",
      "Grobid processing took: 1.587899923324585 seconds\n",
      "Processing paper: model_type_pdfs/0596.pdf\n",
      "Grobid processing took: 1.4720609188079834 seconds\n",
      "Processing paper: model_type_pdfs/1904.12211.pdf\n",
      "Grobid processing took: 1.26955246925354 seconds\n",
      "Processing paper: model_type_pdfs/1509.05490.pdf\n",
      "Grobid processing took: 1.3787236213684082 seconds\n",
      "Processing paper: model_type_pdfs/1902.10197.pdf\n",
      "Grobid processing took: 1.592134952545166 seconds\n",
      "Processing paper: model_type_pdfs/1709.04676.pdf\n",
      "Grobid processing took: 1.4695889949798584 seconds\n",
      "Processing paper: model_type_pdfs/1708.04828.pdf\n",
      "Grobid processing took: 1.7351438999176025 seconds\n",
      "Processing paper: model_type_pdfs/W18-3017.pdf\n",
      "Grobid processing took: 1.267378807067871 seconds\n",
      "Processing paper: model_type_pdfs/1609.07028.pdf\n",
      "Grobid processing took: 1.4023311138153076 seconds\n",
      "Processing paper: model_type_pdfs/S18-2027.pdf\n",
      "Grobid processing took: 1.4501214027404785 seconds\n",
      "Processing paper: model_type_pdfs/1809.01341.pdf\n",
      "Grobid processing took: 1.5988216400146484 seconds\n",
      "Processing paper: model_type_pdfs/1903.05485.pdf\n",
      "Grobid processing took: 2.446744918823242 seconds\n",
      "Processing paper: model_type_pdfs/1802.00934.pdf\n",
      "Grobid processing took: 1.495962142944336 seconds\n",
      "Processing paper: model_type_pdfs/D14-1165.pdf\n",
      "Grobid processing took: 1.603538990020752 seconds\n",
      "Processing paper: model_type_pdfs/1508.02593.pdf\n",
      "Grobid processing took: 1.4595963954925537 seconds\n",
      "Processing paper: model_type_pdfs/paperID314.pdf\n",
      "Grobid processing took: 1.5214061737060547 seconds\n",
      "Processing paper: model_type_pdfs/P17-2051.pdf\n",
      "Grobid processing took: 1.7376832962036133 seconds\n",
      "Processing paper: model_type_pdfs/download_file.pdf\n",
      "Grobid processing took: 1.2868125438690186 seconds\n",
      "Processing paper: model_type_pdfs/P15-1125.pdf\n",
      "Grobid processing took: 1.4718668460845947 seconds\n",
      "Processing paper: model_type_pdfs/P15-1009.pdf\n",
      "Grobid processing took: 1.59767746925354 seconds\n",
      "Processing paper: model_type_pdfs/2018.KDD%202018%20Hierarchical%20Taxonomy%20Aware%20Network%20Embedding.pdf\n",
      "Grobid processing took: 2.0908496379852295 seconds\n",
      "Processing paper: model_type_pdfs/1805.09547.pdf\n",
      "Grobid processing took: 1.6235792636871338 seconds\n",
      "Processing paper: model_type_pdfs/P19-1431.pdf\n",
      "Grobid processing took: 1.3366777896881104 seconds\n",
      "Processing paper: model_type_pdfs/1906.01195.pdf\n",
      "Grobid processing took: 1.5207021236419678 seconds\n",
      "Processing paper: model_type_pdfs/1808.09040.pdf\n",
      "Grobid processing took: 1.6072556972503662 seconds\n",
      "Processing paper: model_type_pdfs/1911.04910.pdf\n",
      "Grobid processing took: 1.492023229598999 seconds\n",
      "Processing paper: model_type_pdfs/document.pdf\n",
      "Grobid processing took: 2.158905506134033 seconds\n",
      "Processing paper: model_type_pdfs/D11-1049.pdf\n",
      "Grobid processing took: 1.5318610668182373 seconds\n",
      "Processing paper: model_type_pdfs/D15-1173.pdf\n",
      "Grobid processing took: 1.5536062717437744 seconds\n",
      "Processing paper: model_type_pdfs/1504.06662.pdf\n",
      "Grobid processing took: 1.5305752754211426 seconds\n",
      "Processing paper: model_type_pdfs/1506.01094.pdf\n",
      "Grobid processing took: 1.495835542678833 seconds\n",
      "Processing paper: model_type_pdfs/1607.01426.pdf\n",
      "Grobid processing took: 1.399090051651001 seconds\n",
      "Processing paper: model_type_pdfs/jiang17a.pdf\n",
      "Grobid processing took: 1.4925169944763184 seconds\n",
      "Processing paper: model_type_pdfs/W17-2608.pdf\n",
      "Grobid processing took: 1.5723364353179932 seconds\n",
      "Processing paper: model_type_pdfs/1806.04523.pdf\n",
      "Grobid processing took: 1.4226365089416504 seconds\n",
      "Processing paper: model_type_pdfs/view.pdf\n",
      "Grobid processing took: 1.0114996433258057 seconds\n",
      "Error extracting abstract (XMLSyntaxError(\"Start tag expected, '<' not found, line 1, column 1\")), skipping.\n",
      "Processing paper: model_type_pdfs/KR2ML_2019_paper_31.pdf\n",
      "Grobid processing took: 1.3244597911834717 seconds\n",
      "Processing paper: model_type_pdfs/P16-1136.pdf\n",
      "Grobid processing took: 1.5717778205871582 seconds\n",
      "Processing paper: model_type_pdfs/s00521-018-3384-6.pdf\n",
      "Grobid processing took: 5.021697998046875 seconds\n",
      "Processing paper: model_type_pdfs/S19-1016.pdf\n",
      "Grobid processing took: 1.4867048263549805 seconds\n",
      "Processing paper: model_type_pdfs/1909.11864.pdf\n",
      "Grobid processing took: 1.4842474460601807 seconds\n",
      "Processing paper: model_type_pdfs/kuzelka20a.pdf\n",
      "Grobid processing took: 1.5560407638549805 seconds\n",
      "Processing paper: model_type_pdfs/2001.11850.pdf\n",
      "Grobid processing took: 1.7972650527954102 seconds\n",
      "Processing paper: model_type_pdfs/0e55666a4ad822e0e34299df3591d979-Paper.pdf\n",
      "Grobid processing took: 1.4172616004943848 seconds\n",
      "Processing paper: model_type_pdfs/0297.pdf\n",
      "Grobid processing took: 1.46881103515625 seconds\n",
      "Processing paper: model_type_pdfs/Tim_aitp.pdf\n",
      "Grobid processing took: 1.2609376907348633 seconds\n",
      "Processing paper: model_type_pdfs/1807.08204.pdf\n",
      "Grobid processing took: 1.3025784492492676 seconds\n",
      "Processing paper: model_type_pdfs/0c72cb7ee1512f800abe27823a792d03-Paper.pdf\n",
      "Grobid processing took: 1.5250465869903564 seconds\n",
      "Processing paper: model_type_pdfs/264.pdf\n",
      "Grobid processing took: 1.4540278911590576 seconds\n",
      "Processing paper: model_type_pdfs/ijcai2016.pdf\n",
      "Grobid processing took: 1.4764142036437988 seconds\n",
      "Processing paper: model_type_pdfs/1903.03772.pdf\n",
      "Grobid processing took: 2.0391664505004883 seconds\n",
      "Processing paper: model_type_pdfs/content.pdf\n",
      "Grobid processing took: 1.1661806106567383 seconds\n",
      "Processing paper: model_type_pdfs/1903.08948.pdf\n",
      "Grobid processing took: 2.287757635116577 seconds\n",
      "Processing paper: model_type_pdfs/13e5ebb0fa112fe1b31a1067962d74a7-Paper.pdf\n",
      "Grobid processing took: 1.5438449382781982 seconds\n",
      "Processing paper: model_type_pdfs/2004.04412.pdf\n",
      "Grobid processing took: 1.6145811080932617 seconds\n",
      "Processing paper: model_type_pdfs/document.pdf\n",
      "Grobid processing took: 2.122143268585205 seconds\n",
      "Processing paper: model_type_pdfs/download.pdf\n",
      "Grobid processing took: 1.6236584186553955 seconds\n",
      "Processing paper: model_type_pdfs/meilicke18ruleemb.pdf\n",
      "Grobid processing took: 1.4891881942749023 seconds\n",
      "Processing paper: model_type_pdfs/N18-1068.pdf\n",
      "Grobid processing took: 1.534350872039795 seconds\n",
      "Processing paper: model_type_pdfs/1605.05416.pdf\n",
      "Grobid processing took: 1.281937599182129 seconds\n",
      "Processing paper: model_type_pdfs/1611.08661.pdf\n",
      "Grobid processing took: 1.3686182498931885 seconds\n",
      "Processing paper: model_type_pdfs/1807.11761.pdf\n",
      "Grobid processing took: 1.1138794422149658 seconds\n",
      "Processing paper: model_type_pdfs/SemaPro_2019_Analogy_inference_on_context_graphsJCM06092019.pdf\n",
      "Grobid processing took: 1.3204209804534912 seconds\n",
      "Processing paper: model_type_pdfs/1909.03193.pdf\n",
      "Grobid processing took: 1.48309326171875 seconds\n",
      "Processing paper: model_type_pdfs/2004.14781.pdf\n",
      "Grobid processing took: 2.4048361778259277 seconds\n",
      "Processing paper: model_type_pdfs/D16-1260.pdf\n",
      "Grobid processing took: 1.3051815032958984 seconds\n",
      "Processing paper: model_type_pdfs/D18-1225.pdf\n",
      "Grobid processing took: 1.5301589965820312 seconds\n",
      "Processing paper: model_type_pdfs/1807.00228.pdf\n",
      "Grobid processing took: 1.632789134979248 seconds\n",
      "Processing paper: model_type_pdfs/1809.03202.pdf\n",
      "Grobid processing took: 1.2991364002227783 seconds\n",
      "Processing paper: model_type_pdfs/2004.04926.pdf\n",
      "Grobid processing took: 1.3999874591827393 seconds\n",
      "Processing paper: model_type_pdfs/trivedi17a.pdf\n",
      "Grobid processing took: 1.5401232242584229 seconds\n",
      "Processing paper: model_type_pdfs/1904.05530.pdf\n",
      "Grobid processing took: 1.7732055187225342 seconds\n",
      "Processing paper: model_type_pdfs/2003.13432.pdf\n",
      "Grobid processing took: 1.6475379467010498 seconds\n",
      "Processing paper: model_type_pdfs/2010.03526.pdf\n",
      "Grobid processing took: 1.7755155563354492 seconds\n",
      "Processing paper: model_type_pdfs/P16-1137.pdf\n",
      "Grobid processing took: 1.5587451457977295 seconds\n",
      "Processing paper: model_type_pdfs/K18-1014.pdf\n",
      "Grobid processing took: 1.450662612915039 seconds\n",
      "Processing paper: model_type_pdfs/1906.05317.pdf\n",
      "Grobid processing took: 1.736973524093628 seconds\n",
      "Processing paper: model_type_pdfs/2001.04170.pdf\n",
      "Grobid processing took: 1.6013753414154053 seconds\n",
      "Processing paper: model_type_pdfs/1604.08642.pdf\n",
      "Grobid processing took: 1.4929301738739014 seconds\n",
      "Processing paper: model_type_pdfs/rosso2020www_0.pdf\n",
      "Grobid processing took: 2.179642677307129 seconds\n"
     ]
    }
   ],
   "source": [
    "mask = ~df['url'].duplicated(keep=False)\n",
    "df_unique_only = df[mask]\n",
    "df_unique_only\n",
    "# Initialize labels based on the category mapping\n",
    "labels_unique = [category_mapping.get(category, 4) for category in df_unique_only['category']]\n",
    "import time\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_model = []\n",
    "\n",
    "documents = []\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for i in range(len(df_unique_only)): #len(df)\n",
    "    paper_filename = df_unique_only.iloc[i]['filename']\n",
    "    # label = df.iloc[i]['category']\n",
    "\n",
    "    print(\"Processing paper:\", paper_filename)\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir/paper_filename)\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "    print(\"Grobid processing took:\", time.time() - start, \"seconds\")\n",
    "\n",
    "    try:\n",
    "        raw_text = extract_abstract(tei)\n",
    "        # if extract_abstract returns None or an empty string, treat as failure\n",
    "        if not raw_text or not raw_text.strip():\n",
    "            print(\"No abstract found, skipping.\")\n",
    "            labels_unique.pop(i)  # Remove the label for this paper\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting abstract ({e!r}), skipping.\")\n",
    "        labels_unique.pop(i)  # Remove the label for this paper\n",
    "        continue\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    # raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "    documents.append(raw_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234341736694679\n",
      "Test F1: 0.6409803921568626\n",
      "Average Recall: 0.6129\n",
      "Average Precision: 0.7200\n",
      "Average F1: 0.6410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels_unique, stratify=labels_unique, test_size=0.2, random_state=42)\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1,2), max_features=50000),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    ")\n",
    "print(cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean())\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test F1:\", f1_score(y_test, model.predict(X_test), average='macro'))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 85 22\n"
     ]
    }
   ],
   "source": [
    "print(len(documents), len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'logisticregression__C': 1, 'tfidfvectorizer__max_df': 0.7, 'tfidfvectorizer__max_features': 10000, 'tfidfvectorizer__min_df': 1, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
      "Best CV F1: 0.6591758241758241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english'),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tfidfvectorizer__min_df': [1, 3, 5],\n",
    "    'tfidfvectorizer__max_df': [0.7, 0.8, 0.9, 1.0],\n",
    "    'tfidfvectorizer__max_features': [10000, 30000, 50000],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best CV F1:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6194341736694678\n",
      "Test F1: 0.6988888888888889\n",
      "Average Recall: 0.6700\n",
      "Average Precision: 0.8473\n",
      "Average F1: 0.6989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels_unique, stratify=labels_unique, test_size=0.2, random_state=42)\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1,2), max_features=10000, stop_words='english', min_df=1, max_df=0.7),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000,C = 1)\n",
    ")\n",
    "print(cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean())\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test F1:\", f1_score(y_test, model.predict(X_test), average='macro'))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features for class 0:\n",
      "  multi relational     (+0.283)\n",
      "  valued               (+0.260)\n",
      "  standard             (+0.260)\n",
      "  tucker               (+0.252)\n",
      "  baseline             (+0.234)\n",
      "  model                (+0.220)\n",
      "  large                (+0.219)\n",
      "  complex              (+0.219)\n",
      "  relational           (+0.203)\n",
      "  cp                   (+0.200)\n",
      "  negative             (+0.186)\n",
      "  size                 (+0.185)\n",
      "  datasets             (+0.174)\n",
      "  gcns                 (+0.174)\n",
      "  fb15k                (+0.171)\n",
      "\n",
      "Top features for class 1:\n",
      "  translation          (+0.748)\n",
      "  translation based    (+0.480)\n",
      "  projection           (+0.420)\n",
      "  head                 (+0.375)\n",
      "  tail                 (+0.373)\n",
      "  relations            (+0.349)\n",
      "  attention            (+0.340)\n",
      "  entity               (+0.335)\n",
      "  transe               (+0.329)\n",
      "  itransf              (+0.323)\n",
      "  rotate               (+0.314)\n",
      "  relation             (+0.309)\n",
      "  tail entity          (+0.307)\n",
      "  head entity          (+0.305)\n",
      "  scholarly            (+0.270)\n",
      "\n",
      "Top features for class 2:\n",
      "  path                 (+0.307)\n",
      "  information          (+0.239)\n",
      "  multimodal           (+0.219)\n",
      "  images               (+0.209)\n",
      "  feature              (+0.207)\n",
      "  compositional        (+0.202)\n",
      "  mh                   (+0.200)\n",
      "  paths                (+0.199)\n",
      "  features             (+0.191)\n",
      "  types                (+0.189)\n",
      "  numerical            (+0.168)\n",
      "  entity               (+0.162)\n",
      "  kblrn                (+0.157)\n",
      "  numerical features   (+0.155)\n",
      "  kg                   (+0.149)\n",
      "\n",
      "Top features for class 3:\n",
      "  rules                (+0.716)\n",
      "  logic                (+0.588)\n",
      "  rule                 (+0.317)\n",
      "  graph                (+0.292)\n",
      "  triples              (+0.285)\n",
      "  candidate            (+0.280)\n",
      "  homer                (+0.253)\n",
      "  abe                  (+0.253)\n",
      "  textual              (+0.244)\n",
      "  graph embedding      (+0.244)\n",
      "  formulas             (+0.211)\n",
      "  candidate triples    (+0.203)\n",
      "  inference            (+0.198)\n",
      "  markov logic         (+0.188)\n",
      "  markov               (+0.188)\n",
      "\n",
      "Top features for class 4:\n",
      "  temporal             (+1.054)\n",
      "  time                 (+0.684)\n",
      "  commonsense knowledge (+0.459)\n",
      "  commonsense          (+0.459)\n",
      "  static               (+0.333)\n",
      "  generation           (+0.304)\n",
      "  ckb                  (+0.304)\n",
      "  kbc                  (+0.267)\n",
      "  csk                  (+0.254)\n",
      "  temporal knowledge   (+0.241)\n",
      "  transh               (+0.240)\n",
      "  embedding methods    (+0.211)\n",
      "  fold                 (+0.209)\n",
      "  multi fold           (+0.209)\n",
      "  episodic             (+0.208)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Fit if you havenât already\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Grab the components\n",
    "tfidf = model.named_steps['tfidfvectorizer']\n",
    "clf = model.named_steps['logisticregression']\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = clf.coef_                     # shape (n_classes, n_features)\n",
    "\n",
    "# If binary classification, coefs.shape == (1, n_features)\n",
    "# If multiclass, coefs.shape == (n_classes, n_features)\n",
    "\n",
    "n = 15  # how many top terms to show\n",
    "\n",
    "if coefs.shape[0] == 1:\n",
    "    # Binary case: look at single row\n",
    "    sorted_idx = np.argsort(coefs[0])\n",
    "    top_neg   = sorted_idx[:n]      # most negative (class 0 indicators)\n",
    "    top_pos   = sorted_idx[-n:]     # most positive (class 1 indicators]\n",
    "\n",
    "    print(\"Top negative features (strongest for class 0):\")\n",
    "    for i in top_neg:\n",
    "        print(f\"  {feature_names[i]:20s} ({coefs[0][i]:+.3f})\")\n",
    "\n",
    "    print(\"\\nTop positive features (strongest for class 1):\")\n",
    "    for i in reversed(top_pos):\n",
    "        print(f\"  {feature_names[i]:20s} ({coefs[0][i]:+.3f})\")\n",
    "\n",
    "else:\n",
    "    # Multiclass: loop over each class\n",
    "    for class_idx, label in enumerate(clf.classes_):\n",
    "        print(f\"\\nTop features for class {label!r}:\")\n",
    "        sorted_idx = np.argsort(coefs[class_idx])\n",
    "        top = sorted_idx[-n:]\n",
    "        for i in reversed(top):\n",
    "            print(f\"  {feature_names[i]:20s} ({coefs[class_idx][i]:+.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 85, Test size: 22\n",
      "Test macro-F1: 0.7766666666666666\n",
      "Average Recall: 0.7976\n",
      "Average Precision: 0.8000\n",
      "Average F1: 0.7767\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load a pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Helper to encode one document\n",
    "def doc_to_vec(doc):\n",
    "    sentences = sent_tokenize(doc)\n",
    "    sent_embs = embedder.encode(sentences)   # shape: (n_sentences, dim)\n",
    "    return sent_embs.mean(axis=0)           # mean pooling â (dim,)\n",
    "\n",
    "# 3. Prepare embeddings for all docs\n",
    "X = [doc_to_vec(d) for d in documents]\n",
    "y = labels_unique\n",
    "\n",
    "# 4. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# 5. Simple classifier\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test macro-F1:\", f1_score(y_test, clf.predict(X_test), average='macro'))\n",
    "# calculate the average metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 85, Test size: 22\n",
      "Test macro-F1: 0.5914285714285714\n",
      "Average Recall: 0.5395\n",
      "Average Precision: 0.7436\n",
      "Average F1: 0.5914\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Load a pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Helper to encode one document\n",
    "def doc_to_vec(doc):\n",
    "    sentences = sent_tokenize(doc)\n",
    "    sent_embs = embedder.encode(sentences)   # shape: (n_sentences, dim)\n",
    "    return sent_embs.mean(axis=0)           # mean pooling â (dim,)\n",
    "\n",
    "# 3. Prepare embeddings for all docs\n",
    "X = [doc_to_vec(d) for d in documents]\n",
    "y = labels_unique\n",
    "\n",
    "# 4. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# 5. Simple classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test macro-F1:\", f1_score(y_test, clf.predict(X_test), average='macro'))\n",
    "# calculate the average metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the responses to a JSON file\n",
    "import json\n",
    "\n",
    "# open the CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"index.csv\")\n",
    "df.head(5)\n",
    "labels = []\n",
    "# Create a mapping from category names to numerical labels\n",
    "category_mapping = {\n",
    "    \"Semantic matching models\": 0,\n",
    "    \"Translation models\": 1,\n",
    "    \"Internal side information inside KGs\": 2,\n",
    "    \"External extra information outside KGs\": 3,\n",
    "    \"Other models\": 4\n",
    "}\n",
    "# Initialize labels based on the category mapping\n",
    "labels = [category_mapping.get(category, 4) for category in df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~df['url'].duplicated(keep=False)\n",
    "df_unique_only = df[mask]\n",
    "df_unique_only\n",
    "# Initialize labels based on the category mapping\n",
    "labels_unique = [category_mapping.get(category, 4) for category in df_unique_only['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "Processing paper: model_type_pdfs/1901.09590.pdf\n",
      "Grobid processing took: 1.537729263305664 seconds\n",
      "Processing paper: model_type_pdfs/slides-icml2011.pdf\n",
      "Grobid processing took: 1.1344513893127441 seconds\n",
      "No abstract found, skipping.\n",
      "Processing paper: model_type_pdfs/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf\n",
      "Grobid processing took: 1.437873363494873 seconds\n",
      "Processing paper: model_type_pdfs/1506.00999.pdf\n",
      "Grobid processing took: 1.8809728622436523 seconds\n",
      "Processing paper: model_type_pdfs/liu17d.pdf\n",
      "Grobid processing took: 1.6332082748413086 seconds\n",
      "Processing paper: model_type_pdfs/1412.6575.pdf\n",
      "Grobid processing took: 1.4580271244049072 seconds\n",
      "Processing paper: model_type_pdfs/trouillon16.pdf\n",
      "Grobid processing took: 1.6761054992675781 seconds\n",
      "Processing paper: model_type_pdfs/1802.04868.pdf\n",
      "Grobid processing took: 1.5943093299865723 seconds\n",
      "Processing paper: model_type_pdfs/ds-paper-620.pdf\n",
      "Grobid processing took: 1.6394598484039307 seconds\n",
      "Processing paper: model_type_pdfs/1705.10744.pdf\n",
      "Grobid processing took: 1.3208227157592773 seconds\n",
      "Processing paper: model_type_pdfs/1805.02408.pdf\n",
      "Grobid processing took: 1.7351288795471191 seconds\n",
      "Processing paper: model_type_pdfs/lacroix18a.pdf\n",
      "Grobid processing took: 1.565319538116455 seconds\n",
      "Processing paper: model_type_pdfs/1912.02686.pdf\n",
      "Grobid processing took: 1.720581293106079 seconds\n",
      "Processing paper: model_type_pdfs/1904.10281.pdf\n",
      "Grobid processing took: 1.583087682723999 seconds\n",
      "Processing paper: model_type_pdfs/1910.11583.pdf\n",
      "Grobid processing took: 1.3586924076080322 seconds\n",
      "Processing paper: model_type_pdfs/b337e84de8752b27eda3a12363109e80-Paper.pdf\n",
      "Grobid processing took: 1.41965913772583 seconds\n",
      "Processing paper: model_type_pdfs/45634.pdf\n",
      "Grobid processing took: 1.6511609554290771 seconds\n",
      "Processing paper: model_type_pdfs/1808.04122.pdf\n",
      "Grobid processing took: 1.5360970497131348 seconds\n",
      "Processing paper: model_type_pdfs/1703.06103.pdf\n",
      "Grobid processing took: 1.5796420574188232 seconds\n",
      "Processing paper: model_type_pdfs/1911.03082.pdf\n",
      "Grobid processing took: 1.6538996696472168 seconds\n",
      "Processing paper: model_type_pdfs/1711.04071.pdf\n",
      "Grobid processing took: 1.4354197978973389 seconds\n",
      "Processing paper: model_type_pdfs/85.pdf\n",
      "Grobid processing took: 1.3776843547821045 seconds\n",
      "Processing paper: model_type_pdfs/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf\n",
      "Grobid processing took: 1.4360649585723877 seconds\n",
      "Processing paper: model_type_pdfs/P15-1067.pdf\n",
      "Grobid processing took: 1.5018773078918457 seconds\n",
      "Processing paper: model_type_pdfs/N16-1105.pdf\n",
      "Grobid processing took: 1.4563827514648438 seconds\n",
      "Processing paper: model_type_pdfs/1801.08641.pdf\n",
      "Grobid processing took: 1.362851858139038 seconds\n",
      "Processing paper: model_type_pdfs/1606.08140.pdf\n",
      "Grobid processing took: 1.5045225620269775 seconds\n",
      "Processing paper: model_type_pdfs/12887-57589-1-PB.pdf\n",
      "Grobid processing took: 1.336712121963501 seconds\n",
      "Processing paper: model_type_pdfs/PACLIC_28_Fan.pdf\n",
      "Grobid processing took: 1.4893972873687744 seconds\n",
      "Processing paper: model_type_pdfs/1704.05908.pdf\n",
      "Grobid processing took: 1.5717058181762695 seconds\n",
      "Processing paper: model_type_pdfs/0596.pdf\n",
      "Grobid processing took: 1.4658353328704834 seconds\n",
      "Processing paper: model_type_pdfs/1904.12211.pdf\n",
      "Grobid processing took: 1.2685236930847168 seconds\n",
      "Processing paper: model_type_pdfs/1509.05490.pdf\n",
      "Grobid processing took: 1.3620171546936035 seconds\n",
      "Processing paper: model_type_pdfs/1902.10197.pdf\n",
      "Grobid processing took: 1.5724945068359375 seconds\n",
      "Processing paper: model_type_pdfs/1709.04676.pdf\n",
      "Grobid processing took: 1.4909183979034424 seconds\n",
      "Processing paper: model_type_pdfs/1708.04828.pdf\n",
      "Grobid processing took: 1.727928638458252 seconds\n",
      "Processing paper: model_type_pdfs/W18-3017.pdf\n",
      "Grobid processing took: 1.278451681137085 seconds\n",
      "Processing paper: model_type_pdfs/1609.07028.pdf\n",
      "Grobid processing took: 1.397965669631958 seconds\n",
      "Processing paper: model_type_pdfs/S18-2027.pdf\n",
      "Grobid processing took: 1.46980881690979 seconds\n",
      "Processing paper: model_type_pdfs/1809.01341.pdf\n",
      "Grobid processing took: 1.5788683891296387 seconds\n",
      "Processing paper: model_type_pdfs/1903.05485.pdf\n",
      "Grobid processing took: 2.4588189125061035 seconds\n",
      "Processing paper: model_type_pdfs/1802.00934.pdf\n",
      "Grobid processing took: 1.4869933128356934 seconds\n",
      "Processing paper: model_type_pdfs/D14-1165.pdf\n",
      "Grobid processing took: 1.5813243389129639 seconds\n",
      "Processing paper: model_type_pdfs/1508.02593.pdf\n",
      "Grobid processing took: 1.469864845275879 seconds\n",
      "Processing paper: model_type_pdfs/paperID314.pdf\n",
      "Grobid processing took: 1.511763095855713 seconds\n",
      "Processing paper: model_type_pdfs/P17-2051.pdf\n",
      "Grobid processing took: 1.7599952220916748 seconds\n",
      "Processing paper: model_type_pdfs/download_file.pdf\n",
      "Grobid processing took: 1.283195972442627 seconds\n",
      "Processing paper: model_type_pdfs/P15-1125.pdf\n",
      "Grobid processing took: 1.4754135608673096 seconds\n",
      "Processing paper: model_type_pdfs/P15-1009.pdf\n",
      "Grobid processing took: 1.615452527999878 seconds\n",
      "Processing paper: model_type_pdfs/2018.KDD%202018%20Hierarchical%20Taxonomy%20Aware%20Network%20Embedding.pdf\n",
      "Grobid processing took: 2.088085889816284 seconds\n",
      "Processing paper: model_type_pdfs/1805.09547.pdf\n",
      "Grobid processing took: 1.6379203796386719 seconds\n",
      "Processing paper: model_type_pdfs/P19-1431.pdf\n",
      "Grobid processing took: 1.3272414207458496 seconds\n",
      "Processing paper: model_type_pdfs/1906.01195.pdf\n",
      "Grobid processing took: 1.5058472156524658 seconds\n",
      "Processing paper: model_type_pdfs/1808.09040.pdf\n",
      "Grobid processing took: 1.5885357856750488 seconds\n",
      "Processing paper: model_type_pdfs/1911.04910.pdf\n",
      "Grobid processing took: 1.4404618740081787 seconds\n",
      "Processing paper: model_type_pdfs/document.pdf\n",
      "Grobid processing took: 2.169842481613159 seconds\n",
      "Processing paper: model_type_pdfs/D11-1049.pdf\n",
      "Grobid processing took: 1.5453119277954102 seconds\n",
      "Processing paper: model_type_pdfs/D15-1173.pdf\n",
      "Grobid processing took: 1.5291640758514404 seconds\n",
      "Processing paper: model_type_pdfs/1504.06662.pdf\n",
      "Grobid processing took: 1.536635160446167 seconds\n",
      "Processing paper: model_type_pdfs/1506.01094.pdf\n",
      "Grobid processing took: 1.4752161502838135 seconds\n",
      "Processing paper: model_type_pdfs/1607.01426.pdf\n",
      "Grobid processing took: 1.393970012664795 seconds\n",
      "Processing paper: model_type_pdfs/jiang17a.pdf\n",
      "Grobid processing took: 1.4745256900787354 seconds\n",
      "Processing paper: model_type_pdfs/W17-2608.pdf\n",
      "Grobid processing took: 1.5300588607788086 seconds\n",
      "Processing paper: model_type_pdfs/1806.04523.pdf\n",
      "Grobid processing took: 1.4289498329162598 seconds\n",
      "Processing paper: model_type_pdfs/view.pdf\n",
      "Grobid processing took: 1.0108592510223389 seconds\n",
      "Error extracting abstract (XMLSyntaxError(\"Start tag expected, '<' not found, line 1, column 1\")), skipping.\n",
      "Processing paper: model_type_pdfs/KR2ML_2019_paper_31.pdf\n",
      "Grobid processing took: 1.33780837059021 seconds\n",
      "Processing paper: model_type_pdfs/P16-1136.pdf\n",
      "Grobid processing took: 1.543250560760498 seconds\n",
      "Processing paper: model_type_pdfs/s00521-018-3384-6.pdf\n",
      "Grobid processing took: 5.085693836212158 seconds\n",
      "Processing paper: model_type_pdfs/S19-1016.pdf\n",
      "Grobid processing took: 1.4735331535339355 seconds\n",
      "Processing paper: model_type_pdfs/1909.11864.pdf\n",
      "Grobid processing took: 1.5291011333465576 seconds\n",
      "Processing paper: model_type_pdfs/kuzelka20a.pdf\n",
      "Grobid processing took: 1.584033727645874 seconds\n",
      "Processing paper: model_type_pdfs/2001.11850.pdf\n",
      "Grobid processing took: 1.8185129165649414 seconds\n",
      "Processing paper: model_type_pdfs/0e55666a4ad822e0e34299df3591d979-Paper.pdf\n",
      "Grobid processing took: 1.4260997772216797 seconds\n",
      "Processing paper: model_type_pdfs/0297.pdf\n",
      "Grobid processing took: 1.483421802520752 seconds\n",
      "Processing paper: model_type_pdfs/Tim_aitp.pdf\n",
      "Grobid processing took: 1.254607915878296 seconds\n",
      "Processing paper: model_type_pdfs/1807.08204.pdf\n",
      "Grobid processing took: 1.304020643234253 seconds\n",
      "Processing paper: model_type_pdfs/0c72cb7ee1512f800abe27823a792d03-Paper.pdf\n",
      "Grobid processing took: 1.513749122619629 seconds\n",
      "Processing paper: model_type_pdfs/264.pdf\n",
      "Grobid processing took: 1.4717659950256348 seconds\n",
      "Processing paper: model_type_pdfs/ijcai2016.pdf\n",
      "Grobid processing took: 1.4600856304168701 seconds\n",
      "Processing paper: model_type_pdfs/1903.03772.pdf\n",
      "Grobid processing took: 2.0664641857147217 seconds\n",
      "Processing paper: model_type_pdfs/content.pdf\n",
      "Grobid processing took: 1.183600664138794 seconds\n",
      "Processing paper: model_type_pdfs/1903.08948.pdf\n",
      "Grobid processing took: 2.219999074935913 seconds\n",
      "Processing paper: model_type_pdfs/13e5ebb0fa112fe1b31a1067962d74a7-Paper.pdf\n",
      "Grobid processing took: 1.5711236000061035 seconds\n",
      "Processing paper: model_type_pdfs/2004.04412.pdf\n",
      "Grobid processing took: 1.6571741104125977 seconds\n",
      "Processing paper: model_type_pdfs/document.pdf\n",
      "Grobid processing took: 2.177884101867676 seconds\n",
      "Processing paper: model_type_pdfs/download.pdf\n",
      "Grobid processing took: 1.5396299362182617 seconds\n",
      "Processing paper: model_type_pdfs/meilicke18ruleemb.pdf\n",
      "Grobid processing took: 1.489527702331543 seconds\n",
      "Processing paper: model_type_pdfs/N18-1068.pdf\n",
      "Grobid processing took: 1.5311408042907715 seconds\n",
      "Processing paper: model_type_pdfs/1605.05416.pdf\n",
      "Grobid processing took: 1.2818288803100586 seconds\n",
      "Processing paper: model_type_pdfs/1611.08661.pdf\n",
      "Grobid processing took: 1.3714401721954346 seconds\n",
      "Processing paper: model_type_pdfs/1807.11761.pdf\n",
      "Grobid processing took: 1.11672043800354 seconds\n",
      "Processing paper: model_type_pdfs/SemaPro_2019_Analogy_inference_on_context_graphsJCM06092019.pdf\n",
      "Grobid processing took: 1.3283534049987793 seconds\n",
      "Processing paper: model_type_pdfs/1909.03193.pdf\n",
      "Grobid processing took: 1.4775469303131104 seconds\n",
      "Processing paper: model_type_pdfs/2004.14781.pdf\n",
      "Grobid processing took: 2.4036195278167725 seconds\n",
      "Processing paper: model_type_pdfs/D16-1260.pdf\n",
      "Grobid processing took: 1.31117844581604 seconds\n",
      "Processing paper: model_type_pdfs/D18-1225.pdf\n",
      "Grobid processing took: 1.5494005680084229 seconds\n",
      "Processing paper: model_type_pdfs/1807.00228.pdf\n",
      "Grobid processing took: 1.6491613388061523 seconds\n",
      "Processing paper: model_type_pdfs/1809.03202.pdf\n",
      "Grobid processing took: 1.2886748313903809 seconds\n",
      "Processing paper: model_type_pdfs/2004.04926.pdf\n",
      "Grobid processing took: 1.4201936721801758 seconds\n",
      "Processing paper: model_type_pdfs/trivedi17a.pdf\n",
      "Grobid processing took: 1.544818639755249 seconds\n",
      "Processing paper: model_type_pdfs/1904.05530.pdf\n",
      "Grobid processing took: 1.7835557460784912 seconds\n",
      "Processing paper: model_type_pdfs/2003.13432.pdf\n",
      "Grobid processing took: 1.6050817966461182 seconds\n",
      "Processing paper: model_type_pdfs/2010.03526.pdf\n",
      "Grobid processing took: 1.7198731899261475 seconds\n",
      "Processing paper: model_type_pdfs/P16-1137.pdf\n",
      "Grobid processing took: 1.5598347187042236 seconds\n",
      "Processing paper: model_type_pdfs/K18-1014.pdf\n",
      "Grobid processing took: 1.4251832962036133 seconds\n",
      "Processing paper: model_type_pdfs/1906.05317.pdf\n",
      "Grobid processing took: 1.7441246509552002 seconds\n",
      "Processing paper: model_type_pdfs/2001.04170.pdf\n",
      "Grobid processing took: 1.627082109451294 seconds\n",
      "Processing paper: model_type_pdfs/1604.08642.pdf\n",
      "Grobid processing took: 1.5101795196533203 seconds\n",
      "Processing paper: model_type_pdfs/rosso2020www_0.pdf\n",
      "Grobid processing took: 2.161884307861328 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "# Get the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "responses_model = []\n",
    "\n",
    "documents = []\n",
    "grobid = GrobidService(config_path=\"./Grobid/config.json\")\n",
    "for i in range(len(df_unique_only)): #len(df)\n",
    "    paper_filename = df_unique_only.iloc[i]['filename']\n",
    "    # label = df.iloc[i]['category']\n",
    "\n",
    "    print(\"Processing paper:\", paper_filename)\n",
    "    start = time.time()\n",
    "    pdf_path = str(current_dir/paper_filename)\n",
    "\n",
    "    tei = grobid.process_full_text(pdf_path)\n",
    "    print(\"Grobid processing took:\", time.time() - start, \"seconds\")\n",
    "\n",
    "    try:\n",
    "        raw_text = extract_abstract(tei)\n",
    "        # if extract_abstract returns None or an empty string, treat as failure\n",
    "        if not raw_text or not raw_text.strip():\n",
    "            print(\"No abstract found, skipping.\")\n",
    "            labels_unique.pop(i)  # Remove the label for this paper\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting abstract ({e!r}), skipping.\")\n",
    "        labels_unique.pop(i)  # Remove the label for this paper\n",
    "        continue\n",
    "\n",
    "    # sections\n",
    "    # sections = extract_flat_sections_with_subtext(tei) # extract sections with their text in a dictionaty\n",
    "    # ranked_sections = rank_sections_by_semantic_similarity([sec['title'] for sec in sections], [\"Experiments\",\"Evaluation\"],model = sim_model) # get the most similar sections to the queries\n",
    "    # best_match_section, best_score = ranked_sections[0]\n",
    "    # raw_text = sections[[sec['title'] for sec in sections].index(best_match_section)]['text']\n",
    "\n",
    "    # full text\n",
    "    # raw_text = tei_to_full_raw_text(tei, remove_ref=True)\n",
    "    documents.append(raw_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 85\n",
      "Number of test samples: 22\n",
      "0.6234341736694679\n",
      "Test F1: 0.6409803921568626\n",
      "Average Recall: 0.6129\n",
      "Average Precision: 0.7200\n",
      "Average F1: 0.6410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels_unique, stratify=labels_unique, test_size=0.20, random_state=42 )\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))\n",
    "\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1,2), max_features=50000),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    ")\n",
    "print(cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean())\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test F1:\", f1_score(y_test, model.predict(X_test), average='macro'))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 85\n",
      "Number of test samples: 22\n",
      "0.6177858220211161\n",
      "Test F1: 0.65\n",
      "Average Recall: 0.6314\n",
      "Average Precision: 0.7467\n",
      "Average F1: 0.6500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, labels_unique, stratify=labels_unique, test_size=0.2, random_state=42)\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))\n",
    "\n",
    "model = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1,1), max_features=50000, stop_words='english',max_df=0.7, min_df=3),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, C=1)\n",
    ")\n",
    "print(cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean())\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test F1:\", f1_score(y_test, model.predict(X_test), average='macro'))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'logisticregression__C': 0.01, 'tfidfvectorizer__max_df': 1.0, 'tfidfvectorizer__max_features': 10000, 'tfidfvectorizer__min_df': 1, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
      "Best CV F1: 0.6588658008658008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english'),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tfidfvectorizer__min_df': [1, 3, 5],\n",
    "    'tfidfvectorizer__max_df': [0.7, 0.8, 0.9, 1.0],\n",
    "    'tfidfvectorizer__max_features': [10000, 30000, 50000],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best CV F1:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_tfidfvectorizer__max_df</th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__min_df</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.241116</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logisticregression__C': 1, 'tfidfvectorizer_...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.692222</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.349559</td>\n",
       "      <td>0.081402</td>\n",
       "      <td>0.053547</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logisticregression__C': 1, 'tfidfvectorizer_...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.692222</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.281741</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logisticregression__C': 1, 'tfidfvectorizer_...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.692222</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.266290</td>\n",
       "      <td>0.047587</td>\n",
       "      <td>0.071011</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logisticregression__C': 1, 'tfidfvectorizer_...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.692222</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.235920</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.045396</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logisticregression__C': 1, 'tfidfvectorizer_...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.692222</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.796317</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "246       0.241116      0.021403         0.044233        0.004218   \n",
       "255       0.349559      0.081402         0.053547        0.004603   \n",
       "237       0.281741      0.060060         0.068667        0.021182   \n",
       "264       0.266290      0.047587         0.071011        0.024098   \n",
       "219       0.235920      0.023180         0.045396        0.003814   \n",
       "\n",
       "    param_logisticregression__C param_tfidfvectorizer__max_df  \\\n",
       "246                           1                           0.8   \n",
       "255                           1                           0.8   \n",
       "237                           1                           0.7   \n",
       "264                           1                           0.8   \n",
       "219                           1                           0.7   \n",
       "\n",
       "    param_tfidfvectorizer__max_features param_tfidfvectorizer__min_df  \\\n",
       "246                               10000                             3   \n",
       "255                               30000                             3   \n",
       "237                               50000                             3   \n",
       "264                               50000                             3   \n",
       "219                               10000                             3   \n",
       "\n",
       "    param_tfidfvectorizer__ngram_range  \\\n",
       "246                             (1, 1)   \n",
       "255                             (1, 1)   \n",
       "237                             (1, 1)   \n",
       "264                             (1, 1)   \n",
       "219                             (1, 1)   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "246  {'logisticregression__C': 1, 'tfidfvectorizer_...           0.583333   \n",
       "255  {'logisticregression__C': 1, 'tfidfvectorizer_...           0.583333   \n",
       "237  {'logisticregression__C': 1, 'tfidfvectorizer_...           0.583333   \n",
       "264  {'logisticregression__C': 1, 'tfidfvectorizer_...           0.583333   \n",
       "219  {'logisticregression__C': 1, 'tfidfvectorizer_...           0.583333   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "246           0.955556           0.692222           0.819048   \n",
       "255           0.955556           0.692222           0.819048   \n",
       "237           0.955556           0.692222           0.819048   \n",
       "264           0.955556           0.692222           0.819048   \n",
       "219           0.955556           0.692222           0.819048   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "246           0.931429         0.796317        0.141652                1  \n",
       "255           0.931429         0.796317        0.141652                1  \n",
       "237           0.931429         0.796317        0.141652                1  \n",
       "264           0.931429         0.796317        0.141652                1  \n",
       "219           0.931429         0.796317        0.141652                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Turn cv_results_ into a DataFrame\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "# Sort by mean_test_score descending\n",
    "results = results.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "results.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features for class 0:\n",
      "  standard             (+0.521)\n",
      "  valued               (+0.518)\n",
      "  baseline             (+0.508)\n",
      "  model                (+0.441)\n",
      "  relational           (+0.437)\n",
      "  large                (+0.412)\n",
      "  complex              (+0.407)\n",
      "  fb15k                (+0.368)\n",
      "  datasets             (+0.352)\n",
      "  negative             (+0.350)\n",
      "  size                 (+0.336)\n",
      "  tensor               (+0.335)\n",
      "  bilinear             (+0.331)\n",
      "  multiple             (+0.319)\n",
      "  expressive           (+0.309)\n",
      "\n",
      "Top features for class 1:\n",
      "  translation          (+1.195)\n",
      "  projection           (+0.702)\n",
      "  transe               (+0.661)\n",
      "  attention            (+0.658)\n",
      "  head                 (+0.628)\n",
      "  tail                 (+0.625)\n",
      "  relations            (+0.554)\n",
      "  entity               (+0.541)\n",
      "  relation             (+0.509)\n",
      "  flexible             (+0.395)\n",
      "  patterns             (+0.385)\n",
      "  various              (+0.379)\n",
      "  mechanism            (+0.347)\n",
      "  related              (+0.347)\n",
      "  specific             (+0.344)\n",
      "\n",
      "Top features for class 2:\n",
      "  path                 (+0.568)\n",
      "  information          (+0.441)\n",
      "  images               (+0.404)\n",
      "  feature              (+0.403)\n",
      "  paths                (+0.374)\n",
      "  compositional        (+0.369)\n",
      "  types                (+0.360)\n",
      "  features             (+0.349)\n",
      "  numerical            (+0.325)\n",
      "  kg                   (+0.323)\n",
      "  entity               (+0.318)\n",
      "  better               (+0.270)\n",
      "  hop                  (+0.268)\n",
      "  capture              (+0.263)\n",
      "  type                 (+0.260)\n",
      "\n",
      "Top features for class 3:\n",
      "  rules                (+1.114)\n",
      "  logic                (+0.943)\n",
      "  triples              (+0.523)\n",
      "  textual              (+0.481)\n",
      "  graph                (+0.478)\n",
      "  rule                 (+0.473)\n",
      "  inference            (+0.334)\n",
      "  text                 (+0.319)\n",
      "  markov               (+0.313)\n",
      "  missing              (+0.263)\n",
      "  probabilistic        (+0.248)\n",
      "  rank                 (+0.245)\n",
      "  order                (+0.238)\n",
      "  language             (+0.236)\n",
      "  process              (+0.235)\n",
      "\n",
      "Top features for class 4:\n",
      "  temporal             (+1.683)\n",
      "  time                 (+1.116)\n",
      "  commonsense          (+1.112)\n",
      "  static               (+0.567)\n",
      "  base                 (+0.435)\n",
      "  like                 (+0.375)\n",
      "  study                (+0.371)\n",
      "  canonical            (+0.342)\n",
      "  fact                 (+0.332)\n",
      "  present              (+0.319)\n",
      "  graphs               (+0.304)\n",
      "  prevalent            (+0.304)\n",
      "  new                  (+0.292)\n",
      "  ranking              (+0.285)\n",
      "  predicts             (+0.267)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Fit if you havenât already\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Grab the components\n",
    "tfidf: TfidfVectorizer        = model.named_steps['tfidfvectorizer']\n",
    "clf:  LogisticRegression      = model.named_steps['logisticregression']\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = clf.coef_                     # shape (n_classes, n_features)\n",
    "\n",
    "# If binary classification, coefs.shape == (1, n_features)\n",
    "# If multiclass, coefs.shape == (n_classes, n_features)\n",
    "\n",
    "n = 15  # how many top terms to show\n",
    "\n",
    "if coefs.shape[0] == 1:\n",
    "    # Binary case: look at single row\n",
    "    sorted_idx = np.argsort(coefs[0])\n",
    "    top_neg   = sorted_idx[:n]      # most negative (class 0 indicators)\n",
    "    top_pos   = sorted_idx[-n:]     # most positive (class 1 indicators]\n",
    "\n",
    "    print(\"Top negative features (strongest for class 0):\")\n",
    "    for i in top_neg:\n",
    "        print(f\"  {feature_names[i]:20s} ({coefs[0][i]:+.3f})\")\n",
    "\n",
    "    print(\"\\nTop positive features (strongest for class 1):\")\n",
    "    for i in reversed(top_pos):\n",
    "        print(f\"  {feature_names[i]:20s} ({coefs[0][i]:+.3f})\")\n",
    "\n",
    "else:\n",
    "    # Multiclass: loop over each class\n",
    "    for class_idx, label in enumerate(clf.classes_):\n",
    "        print(f\"\\nTop features for class {label!r}:\")\n",
    "        sorted_idx = np.argsort(coefs[class_idx])\n",
    "        top = sorted_idx[-n:]\n",
    "        for i in reversed(top):\n",
    "            print(f\"  {feature_names[i]:20s} ({coefs[class_idx][i]:+.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.7976\n",
      "Average Precision: 0.8000\n",
      "Average F1: 0.7767\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load a pre-trained sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Helper to encode one document\n",
    "def doc_to_vec(doc):\n",
    "    sentences = sent_tokenize(doc)\n",
    "    sent_embs = embedder.encode(sentences)   # shape: (n_sentences, dim)\n",
    "    return sent_embs.mean(axis=0)           # mean pooling â (dim,)\n",
    "\n",
    "# 3. Prepare embeddings for all docs\n",
    "X = [doc_to_vec(d) for d in documents]\n",
    "y = labels_unique\n",
    "\n",
    "# 4. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=42)\n",
    "\n",
    "# 5. Simple classifier\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "# calculate the average metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "average_recall = recall_score(y_test, y_pred, average='macro')\n",
    "average_precision = precision_score(y_test, y_pred, average='macro')\n",
    "average_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average F1: {average_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
