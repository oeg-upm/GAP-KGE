{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd22231",
   "metadata": {},
   "source": [
    "## Extracción de tablas:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0823f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T11:56:29.120461300Z",
     "start_time": "2026-02-18T11:55:35.667688500Z"
    }
   },
   "source": [
    "import json\n",
    "import deepdoctection as dd\n",
    "import time\n",
    "\n",
    "config_overwrite = [\"USE_OCR=False\", \"USE_PDF_MINER=True\"]\n",
    "analyzer = dd.get_dd_analyzer(config_overwrite=config_overwrite)\n",
    "path_pdf = r\"pdfs_prueba/HyperKG- Hyperbolic Knowledge Graph Embeddings for Knowledge Base Completion.pdf\"\n",
    "\n",
    "# Pruebas\\pdfs_prueba\\\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = analyzer.analyze(path=path_pdf)\n",
    "df.reset_state()\n",
    "\n",
    "results_data = []\n",
    "\n",
    "for dp in df:\n",
    "    print(f\"\\n--- Processing page {dp.page_number} ---\")\n",
    "    \n",
    "    if len(dp.tables) > 0:\n",
    "        print(f\"{len(dp.tables)} tables found\")\n",
    "    else:\n",
    "        print(\"No tables found\")\n",
    "\n",
    "    table_content = []\n",
    "    for table in dp.tables:\n",
    "        table_content.append({\n",
    "            \"csv\": table.csv,\n",
    "            \"html\": table.html\n",
    "        })\n",
    "    \n",
    "    if table_content:\n",
    "        page_data = {\n",
    "            \"page\": dp.page_number + 1,\n",
    "            \"tables\": table_content\n",
    "        }\n",
    "        results_data.append(page_data)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTotal time: {total_time:.2f} seconds\")\n",
    "\n",
    "final_output = {\n",
    "    \"file_name\": path_pdf,\n",
    "    \"runtime_seconds\": round(total_time, 2),\n",
    "    \"total_num_tables\": sum(len(p[\"tables\"]) for p in results_data),\n",
    "    \"results\": results_data\n",
    "}\n",
    "\n",
    "with open(\"deepdoctection_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Data saved in 'deepdoctection_output.json'\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Profesor\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001B[32m[0218 12:56.21 @dd.py:119]\u001B[0m  \u001B[32mINF\u001B[0m  \u001B[97mConfig: \n",
      " {'CELL': {'FILTER': None,\n",
      "          'PAD': {'BOTTOM': 60, 'LEFT': 60, 'RIGHT': 60, 'TOP': 60},\n",
      "          'PADDING': False,\n",
      "          'WEIGHTS': 'cell/d2_model_1849999_cell_inf_only.pt',\n",
      "          'WEIGHTS_TS': 'cell/d2_model_1849999_cell_inf_only.ts'},\n",
      " 'DEVICE': device(type='cpu'),\n",
      " 'ENFORCE_WEIGHTS': {'CELL': True, 'ITEM': True, 'LAYOUT': True},\n",
      " 'ITEM': {'FILTER': ['table'],\n",
      "          'PAD': {'BOTTOM': 60, 'LEFT': 60, 'RIGHT': 60, 'TOP': 60},\n",
      "          'PADDING': False,\n",
      "          'WEIGHTS': 'deepdoctection/tatr_tab_struct_v2/model.safetensors',\n",
      "          'WEIGHTS_TS': 'item/d2_model_1639999_item_inf_only.ts'},\n",
      " 'LANGUAGE': None,\n",
      " 'LAYOUT': {'FILTER': None,\n",
      "            'PAD': {'BOTTOM': 0, 'LEFT': 0, 'RIGHT': 0, 'TOP': 0},\n",
      "            'PADDING': False,\n",
      "            'WEIGHTS': 'Aryn/deformable-detr-DocLayNet/model.safetensors',\n",
      "            'WEIGHTS_TS': 'layout/d2_model_0829999_layout_inf_only.ts'},\n",
      " 'LAYOUT_LINK': {'CHILD_CATEGORIES': [<LayoutType.CAPTION>],\n",
      "                 'PARENTAL_CATEGORIES': [<LayoutType.FIGURE>, <LayoutType.TABLE>]},\n",
      " 'LAYOUT_NMS_PAIRS': {'COMBINATIONS': [[<LayoutType.TABLE>, <LayoutType.TITLE>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.TEXT>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.KEY_VALUE_AREA>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.LIST>],\n",
      "                                       [<LayoutType.TABLE>, <LayoutType.FIGURE>],\n",
      "                                       [<LayoutType.TITLE>, <LayoutType.TEXT>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.KEY_VALUE_AREA>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.TEXT>, <LayoutType.CAPTION>],\n",
      "                                       [<LayoutType.KEY_VALUE_AREA>, <LayoutType.LIST_ITEM>],\n",
      "                                       [<LayoutType.FIGURE>, <LayoutType.CAPTION>]],\n",
      "                      'PRIORITY': [<LayoutType.TABLE>, <LayoutType.TABLE>, <LayoutType.TABLE>,\n",
      "                                   <LayoutType.TABLE>, <LayoutType.TABLE>, <LayoutType.TABLE>,\n",
      "                                   <LayoutType.TEXT>, <LayoutType.TEXT>, None, <LayoutType.CAPTION>,\n",
      "                                   <LayoutType.KEY_VALUE_AREA>, <LayoutType.FIGURE>],\n",
      "                      'THRESHOLDS': [0.001, 0.01, 0.01, 0.001, 0.01, 0.01, 0.05, 0.01, 0.01, 0.01,\n",
      "                                     0.01, 0.001]},\n",
      " 'LIB': 'PT',\n",
      " 'LM_LANGUAGE_DETECT_CLASS': {'WEIGHTS': None},\n",
      " 'LM_SEQUENCE_CLASS': {'USE_OTHER_AS_DEFAULT_CATEGORY': False, 'WEIGHTS': None},\n",
      " 'LM_TOKEN_CLASS': {'SEGMENT_POSITIONS': None,\n",
      "                    'SLIDING_WINDOW_STRIDE': 0,\n",
      "                    'USE_OTHER_AS_DEFAULT_CATEGORY': False,\n",
      "                    'WEIGHTS': None},\n",
      " 'OCR': {'CONFIG': {'TESSERACT': 'dd/conf_tesseract.yaml'},\n",
      "         'USE_DOCTR': True,\n",
      "         'USE_TESSERACT': False,\n",
      "         'USE_TEXTRACT': False,\n",
      "         'WEIGHTS': {'DOCTR_RECOGNITION': 'doctr/crnn_vgg16_bn/crnn_vgg16_bn-0417f351.pt',\n",
      "                     'DOCTR_WORD': 'doctr/db_resnet50/db_resnet50-ac60cadc.pt'}},\n",
      " 'PDF_MINER': {'X_TOLERANCE': 3, 'Y_TOLERANCE': 3},\n",
      " 'ROTATOR': {'MODEL': 'tesseract'},\n",
      " 'SEGMENTATION': {'ASSIGNMENT_RULE': 'ioa',\n",
      "                  'CELL_NAMES': [<CellType.COLUMN_HEADER>, <CellType.BODY>, <LayoutType.CELL>],\n",
      "                  'FULL_TABLE_TILING': True,\n",
      "                  'ITEM_NAMES': [<LayoutType.ROW>, <LayoutType.COLUMN>],\n",
      "                  'PUBTABLES_CELL_NAMES': [<LayoutType.CELL>],\n",
      "                  'PUBTABLES_ITEM_HEADER_CELL_NAMES': [<CellType.COLUMN_HEADER>,\n",
      "                                                       <CellType.ROW_HEADER>,\n",
      "                                                       <CellType.PROJECTED_ROW_HEADER>],\n",
      "                  'PUBTABLES_ITEM_HEADER_THRESHOLDS': [0.6, 0.0001],\n",
      "                  'PUBTABLES_ITEM_NAMES': [<LayoutType.ROW>, <LayoutType.COLUMN>],\n",
      "                  'PUBTABLES_SPANNING_CELL_NAMES': [<CellType.SPANNING>],\n",
      "                  'PUBTABLES_SUB_ITEM_NAMES': [<CellType.ROW_NUMBER>, <CellType.COLUMN_NUMBER>],\n",
      "                  'REMOVE_IOU_THRESHOLD_COLS': 0.2,\n",
      "                  'REMOVE_IOU_THRESHOLD_ROWS': 0.2,\n",
      "                  'STRETCH_RULE': 'equal',\n",
      "                  'SUB_ITEM_NAMES': [<CellType.ROW_NUMBER>, <CellType.COLUMN_NUMBER>],\n",
      "                  'TABLE_NAME': <LayoutType.TABLE>,\n",
      "                  'THRESHOLD_COLS': 0.4,\n",
      "                  'THRESHOLD_ROWS': 0.4},\n",
      " 'TEXT_CONTAINER': <LayoutType.WORD>,\n",
      " 'TEXT_ORDERING': {'BROKEN_LINE_TOLERANCE': 0.003,\n",
      "                   'FLOATING_TEXT_BLOCK_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                                      <LayoutType.LIST>,\n",
      "                                                      <LayoutType.KEY_VALUE_AREA>),\n",
      "                   'HEIGHT_TOLERANCE': 2.0,\n",
      "                   'INCLUDE_RESIDUAL_TEXT_CONTAINER': True,\n",
      "                   'PARAGRAPH_BREAK': 0.035,\n",
      "                   'STARTING_POINT_TOLERANCE': 0.005,\n",
      "                   'TEXT_BLOCK_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                             <LayoutType.LIST_ITEM>, <LayoutType.LIST>,\n",
      "                                             <LayoutType.CAPTION>, <LayoutType.PAGE_HEADER>,\n",
      "                                             <LayoutType.PAGE_FOOTER>, <LayoutType.PAGE_NUMBER>,\n",
      "                                             <LayoutType.MARK>, <LayoutType.KEY_VALUE_AREA>,\n",
      "                                             <LayoutType.FIGURE>, <CellType.SPANNING>,\n",
      "                                             <LayoutType.CELL>)},\n",
      " 'USE_LAYOUT': True,\n",
      " 'USE_LAYOUT_LINK': False,\n",
      " 'USE_LAYOUT_NMS': True,\n",
      " 'USE_LINE_MATCHER': False,\n",
      " 'USE_LM_LANGUAGE_DETECTION': False,\n",
      " 'USE_LM_SEQUENCE_CLASS': False,\n",
      " 'USE_LM_TOKEN_CLASS': False,\n",
      " 'USE_OCR': False,\n",
      " 'USE_PDF_MINER': True,\n",
      " 'USE_ROTATOR': False,\n",
      " 'USE_TABLE_REFINEMENT': False,\n",
      " 'USE_TABLE_SEGMENTATION': True,\n",
      " 'WORD_MATCHING': {'MAX_PARENT_ONLY': True,\n",
      "                   'PARENTAL_CATEGORIES': (<LayoutType.TEXT>, <LayoutType.TITLE>,\n",
      "                                           <LayoutType.LIST_ITEM>, <LayoutType.LIST>,\n",
      "                                           <LayoutType.CAPTION>, <LayoutType.PAGE_HEADER>,\n",
      "                                           <LayoutType.PAGE_FOOTER>, <LayoutType.PAGE_NUMBER>,\n",
      "                                           <LayoutType.MARK>, <LayoutType.KEY_VALUE_AREA>,\n",
      "                                           <LayoutType.FIGURE>, <CellType.SPANNING>,\n",
      "                                           <LayoutType.CELL>),\n",
      "                   'RULE': 'ioa',\n",
      "                   'THRESHOLD': 0.3}}\u001B[0m\n",
      "C:\\Users\\Profesor\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: The `force_filename` parameter is deprecated as a new caching system, which keeps the filenames as they are on the Hub, is now in place.\n",
      "  warnings.warn(\n",
      "\u001B[32m[0218 12:56.26 @model.py:444]\u001B[0m  \u001B[4m\u001B[5m\u001B[31mERR\u001B[0m  \u001B[97mFile downloaded from Aryn/deformable-detr-DocLayNet does not match the expected size! You may have downloaded a broken file, or the upstream may have modified the file.\u001B[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nDeformableDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[0;32m      5\u001B[0m config_overwrite \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSE_OCR=False\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSE_PDF_MINER=True\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 6\u001B[0m analyzer \u001B[38;5;241m=\u001B[39m \u001B[43mdd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dd_analyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig_overwrite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_overwrite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m path_pdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpdfs_prueba/HyperKG- Hyperbolic Knowledge Graph Embeddings for Knowledge Base Completion.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Pruebas\\pdfs_prueba\\\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\analyzer\\dd.py:121\u001B[0m, in \u001B[0;36mget_dd_analyzer\u001B[1;34m(load_default_config_file, config_overwrite, path_config_file)\u001B[0m\n\u001B[0;32m    118\u001B[0m config_sanity_checks()\n\u001B[0;32m    119\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(LoggingRecord(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConfig: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(cfg)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, cfg\u001B[38;5;241m.\u001B[39mto_dict()))  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mServiceFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_analyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\analyzer\\factory.py:1726\u001B[0m, in \u001B[0;36mServiceFactory.build_analyzer\u001B[1;34m(config)\u001B[0m\n\u001B[0;32m   1723\u001B[0m     pipe_component_list\u001B[38;5;241m.\u001B[39mappend(transform_service)\n\u001B[0;32m   1725\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mUSE_LAYOUT:\n\u001B[1;32m-> 1726\u001B[0m     layout_detector \u001B[38;5;241m=\u001B[39m \u001B[43mServiceFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_layout_detector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLAYOUT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1727\u001B[0m     layout_service \u001B[38;5;241m=\u001B[39m ServiceFactory\u001B[38;5;241m.\u001B[39mbuild_layout_service(config, detector\u001B[38;5;241m=\u001B[39mlayout_detector, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLAYOUT\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1728\u001B[0m     pipe_component_list\u001B[38;5;241m.\u001B[39mappend(layout_service)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\analyzer\\factory.py:210\u001B[0m, in \u001B[0;36mServiceFactory.build_layout_detector\u001B[1;34m(config, mode)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;124;03mBuilding a layout detector according to the config.\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m    mode: Either `LAYOUT`, `CELL`, or `ITEM`.\u001B[39;00m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    209\u001B[0m layout_detector_kwargs \u001B[38;5;241m=\u001B[39m ServiceFactory\u001B[38;5;241m.\u001B[39m_get_layout_detector_kwargs_from_config(config, mode)\n\u001B[1;32m--> 210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ServiceFactory\u001B[38;5;241m.\u001B[39m_build_layout_detector(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mlayout_detector_kwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\analyzer\\factory.py:185\u001B[0m, in \u001B[0;36mServiceFactory._build_layout_detector\u001B[1;34m(weights, filter_categories, profile, device, lib)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m profile\u001B[38;5;241m.\u001B[39mmodel_wrapper \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHFDetrDerivedDetector\u001B[39m\u001B[38;5;124m\"\u001B[39m,):\n\u001B[0;32m    184\u001B[0m     preprocessor_config \u001B[38;5;241m=\u001B[39m ModelCatalog\u001B[38;5;241m.\u001B[39mget_full_path_preprocessor_configs(weights)\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mHFDetrDerivedDetector\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_config_json\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_feature_extractor_config_json\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreprocessor_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategories\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilter_categories\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilter_categories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have chosen profile.model_wrapper: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprofile\u001B[38;5;241m.\u001B[39mmodel_wrapper\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m which is not allowed. Please check \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompatability with your deep learning framework\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\extern\\hfdetr.py:229\u001B[0m, in \u001B[0;36mHFDetrDerivedDetector.__init__\u001B[1;34m(self, path_config_json, path_weights, path_feature_extractor_config_json, categories, device, filter_categories)\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_id()\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config(path_config_json)\n\u001B[1;32m--> 229\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhf_detr_predictor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_extractor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_pre_processor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_feature_extractor_config, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig)\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m get_torch_device(device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\deepdoctection\\extern\\hfdetr.py:277\u001B[0m, in \u001B[0;36mHFDetrDerivedDetector.get_model\u001B[1;34m(path_weights, config)\u001B[0m\n\u001B[0;32m    273\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m TableTransformerForObjectDetection\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    274\u001B[0m             pretrained_model_name_or_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mfspath(path_weights), config\u001B[38;5;241m=\u001B[39mconfig\n\u001B[0;32m    275\u001B[0m         )\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDeformableDetrForObjectDetection\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39marchitectures:\n\u001B[1;32m--> 277\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDeformableDetrForObjectDetection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel architecture \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39marchitectures\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not eligible. Please use either \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTableTransformerForObjectDetection or DeformableDetrForObjectDetection.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    283\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\modeling_utils.py:277\u001B[0m, in \u001B[0;36mrestore_default_dtype.<locals>._wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m old_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mget_default_dtype()\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    279\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_default_dtype(old_dtype)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\modeling_utils.py:4971\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   4968\u001B[0m config \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(config)  \u001B[38;5;66;03m# We do not want to modify the config inplace in from_pretrained.\u001B[39;00m\n\u001B[0;32m   4969\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(model_init_context):\n\u001B[0;32m   4970\u001B[0m     \u001B[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001B[39;00m\n\u001B[1;32m-> 4971\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(config, \u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m   4973\u001B[0m \u001B[38;5;66;03m# Make sure to tie the weights correctly\u001B[39;00m\n\u001B[0;32m   4974\u001B[0m model\u001B[38;5;241m.\u001B[39mtie_weights()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\models\\deformable_detr\\modeling_deformable_detr.py:1715\u001B[0m, in \u001B[0;36mDeformableDetrForObjectDetection.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[0;32m   1714\u001B[0m \u001B[38;5;66;03m# Deformable DETR encoder-decoder model\u001B[39;00m\n\u001B[1;32m-> 1715\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mDeformableDetrModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1716\u001B[0m \u001B[38;5;66;03m# Detection heads on top\u001B[39;00m\n\u001B[0;32m   1717\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_embed \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(config\u001B[38;5;241m.\u001B[39md_model, config\u001B[38;5;241m.\u001B[39mnum_labels)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\models\\deformable_detr\\modeling_deformable_detr.py:1302\u001B[0m, in \u001B[0;36mDeformableDetrModel.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;66;03m# Create backbone + positional encoding\u001B[39;00m\n\u001B[1;32m-> 1302\u001B[0m backbone \u001B[38;5;241m=\u001B[39m \u001B[43mDeformableDetrConvEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1303\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m build_position_encoding(config)\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone \u001B[38;5;241m=\u001B[39m DeformableDetrConvModel(backbone, position_embeddings)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\models\\deformable_detr\\modeling_deformable_detr.py:330\u001B[0m, in \u001B[0;36mDeformableDetrConvEncoder.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    326\u001B[0m \u001B[38;5;66;03m# For backwards compatibility we have to use the timm library directly instead of the AutoBackbone API\u001B[39;00m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39muse_timm_backbone:\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;66;03m# We default to values which were previously hard-coded. This enables configurability from the config\u001B[39;00m\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;66;03m# using backbone arguments, while keeping the default behavior the same.\u001B[39;00m\n\u001B[1;32m--> 330\u001B[0m     \u001B[43mrequires_backends\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtimm\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    331\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackbone_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[0;32m    332\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {} \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mcopy()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\gap-kge\\lib\\site-packages\\transformers\\utils\\import_utils.py:2143\u001B[0m, in \u001B[0;36mrequires_backends\u001B[1;34m(obj, backends)\u001B[0m\n\u001B[0;32m   2140\u001B[0m         failed\u001B[38;5;241m.\u001B[39mappend(msg\u001B[38;5;241m.\u001B[39mformat(name))\n\u001B[0;32m   2142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[1;32m-> 2143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(failed))\n",
      "\u001B[1;31mImportError\u001B[0m: \nDeformableDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e5088ba6",
   "metadata": {},
   "source": [
    "#### Posibles modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ba4b3",
   "metadata": {},
   "source": [
    "## Extracción de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2df7e",
   "metadata": {},
   "source": [
    "## Extracción de datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e587f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WN18', 'FB15k', 'WD']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "FOLDER_ROOT = Path.cwd()\n",
    "TABLES_JSON = FOLDER_ROOT / \"deepdoctection_output.json\"\n",
    "\n",
    "DATASET_LIST = [\"WN18\",\"Dataset-B1\",\"FB15k\", \"Dataset_A2\", \"WD\"]\n",
    "found_datasets = []\n",
    "\n",
    "with open(TABLES_JSON, \"r\", encoding=\"utf-8\") as j:\n",
    "    tables_json = json.load(j)\n",
    "\n",
    "tables_html = []\n",
    "\n",
    "for page_data in tables_json['results']:\n",
    "    for table in page_data['tables']:\n",
    "        tables_html.append(table['html'])\n",
    "\n",
    "def search_datasets_in_tables_html(html_list = tables_html):\n",
    "    possible_datasets =  DATASET_LIST.copy()\n",
    "\n",
    "    for html in html_list:\n",
    "        for dataset_name in possible_datasets:\n",
    "            clean_dataset_name = \"\".join(filter(str.isalnum, dataset_name))\n",
    "            regex_pattern = r\"[\\W_]*\".join(re.escape(c) for c in clean_dataset_name)\n",
    "            final_pattern = r\"\\b\" + regex_pattern\n",
    "            \n",
    "            if re.search(final_pattern, html, re.IGNORECASE) and dataset_name not in found_datasets:\n",
    "                found_datasets.append(dataset_name)\n",
    "\n",
    "found_datasets = []\n",
    "search_datasets_in_tables_html()\n",
    "print(found_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005f2e0",
   "metadata": {},
   "source": [
    "We evaluate our HyperKG model on the task of KBC using\n",
    "two sets of experiments. We conduct experiments on the\n",
    "WN18RR (Dettmers et al. 2018) and FB15k-237 (Toutanova\n",
    "and Chen 2015) datasets. We also construct two datasets\n",
    "whose statistical regularities can be expressed as QC rules to\n",
    "test our model’s performance in their presence. WN18RR and\n",
    "FB15k-237 constitute refined subsets of WN18 and FB15K\n",
    "that were introduced by Bordes et al . (2013). Toutanova and\n",
    "Chen (2015) identified that WN18 and FB15K contained a lot\n",
    "of reversible relations, enabling, thus, various KB embedding\n",
    "models to generalise easily. Exploiting this fact, Dettmers et\n",
    "al . (2018) obtained state-of-the-art results only by using a\n",
    "simple reversal rule. WN18RR and FB15k-237 were carefully\n",
    "created to alleviate this leakage of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbd372",
   "metadata": {},
   "source": [
    "Al leer JSON usar .get si el dato no es obligatorio/puede no estar y [] si el dato es obligatorio, pues el script fallará si no lo encuentra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4979335",
   "metadata": {},
   "source": [
    "## Extracción de métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista objetivo: ['Accuracy', 'MRR', 'Hits@1', 'Hits@3', 'Hits@10', 'F1-Score']\n",
      "Encontradas en tabla: ['Hits@3', 'MRR', 'Hits@10', 'Hits@1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "\n",
    "METRICS_LIST = [\"Accuracy\", \"MRR\", \"Hits@1\", \"Hits@3\", \"Hits@10\", \"F1-Score\"]\n",
    "\n",
    "PATRONES = {\n",
    "    \"Accuracy\": re.compile(r\"\\b(?:acc(?:uracy)?|c\\.?a\\.?)\\b\", re.IGNORECASE),\n",
    "    \"MRR\": re.compile(r\"\\b(?:mrr|mean\\s+reciprocal\\s+rank)\\b\", re.IGNORECASE),\n",
    "    \"F1-Score\": re.compile(r\"\\bf-?1(?:-?(?:score|measure))?\\b\", re.IGNORECASE),\n",
    "    \n",
    "}\n",
    "REGEX_HITS = re.compile(r\"\\b(?:hits?|h)(?:\\s*@\\s*|\\s+at\\s+|\\s*)(\\d{1,3})\\b\", re.IGNORECASE)\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"Convierte texto sucio ('H@ 10') en métrica canónica ('Hits@10').\"\"\"\n",
    "    texto = str(texto).strip()\n",
    "    \n",
    "    \n",
    "    match = REGEX_HITS.search(texto)\n",
    "    if match:\n",
    "        return f\"Hits@{match.group(1)}\"\n",
    "    \n",
    "    \n",
    "    for nombre_canonico, patron in PATRONES.items():\n",
    "        if patron.search(texto):\n",
    "            return nombre_canonico\n",
    "            \n",
    "    return None\n",
    "\n",
    "def detectar_metricas_en_tabla(html_str, lista_objetivo):\n",
    "    metricas_encontradas = set()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dfs = pd.read_html(io.StringIO(html_str), header=[0, 1, 2])\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    if not dfs: return []\n",
    "    df = dfs[0]\n",
    "\n",
    "    for col_tuple in df.columns:\n",
    "        texto_cabecera = \" \".join([str(x) for x in col_tuple if \"Unnamed\" not in str(x) and str(x) != \"nan\"])\n",
    "        \n",
    "        metrica = normalizar_texto(texto_cabecera)\n",
    "        if metrica:\n",
    "            metricas_encontradas.add(metrica)\n",
    "\n",
    "    try:\n",
    "        primera_columna = df.iloc[:, 0].astype(str).tolist()\n",
    "        for celda in primera_columna:\n",
    "            metrica = normalizar_texto(celda)\n",
    "            if metrica:\n",
    "                metricas_encontradas.add(metrica)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    metricas_presentes = list(metricas_encontradas.intersection(set(lista_objetivo)))\n",
    "    \n",
    "    return metricas_presentes\n",
    "\n",
    "html_complejo = \"\"\"\n",
    "<table><tr><td rowspan=3>Models</td><td colspan=4>WN18RR</td></tr><tr><td rowspan=2>MRR</td><td colspan=3>Hits@</td></tr><tr><td>1</td><td>3</td><td>10</td></tr><tr><td>DistMult</td><td>43.0</td><td>39.0</td><td>44.0</td><td>49.0</td></tr></table>\n",
    "\"\"\"\n",
    "\n",
    "resultado = detectar_metricas_en_tabla(html_complejo, METRICS_LIST)\n",
    "\n",
    "print(f\"Lista objetivo: {METRICS_LIST}\")\n",
    "print(f\"Encontradas en tabla: {resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce509fed",
   "metadata": {},
   "source": [
    "## Extracción de valores de las tablas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68111ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <table><tr><td rowspan=3>Models</td><td colspan=4>WN18</td><td colspan=4>FB15k</td></tr><tr><td rowspan=2>MRR</td><td colspan=3>Hits@</td><td rowspan=2>MRR</td><td colspan=3>Hits@</td></tr><tr><td>1</td><td>3</td><td>10</td><td>1</td><td>3</td><td>10</td></tr><tr><td>TransE*</td><td>45.4</td><td>8.9</td><td>82.3</td><td>93.4</td><td>38.0</td><td>23.1</td><td>47.2</td><td>64.1</td></tr><tr><td>DistMult*</td><td>82.2</td><td>72.8</td><td>91.4</td><td>93.6</td><td>65.4</td><td>54.6</td><td>73.3</td><td>82.4</td></tr><tr><td>HolE*</td><td>93.8</td><td>93.0</td><td>94.5</td><td>94.9</td><td>52.4</td><td>40.2</td><td>61.3</td><td>73.9</td></tr><tr><td>ComplEx*</td><td>94.1</td><td>93.6</td><td>94.5</td><td>94.7</td><td>69.2</td><td>59.9</td><td>75.9</td><td>84.0</td></tr><tr><td>ANALOGY**</td><td>94.2</td><td>93.9</td><td>94.4</td><td>94.7</td><td>72.5</td><td>64.6</td><td>78.5</td><td>85.4</td></tr><tr><td>CP***</td><td>94.2</td><td>93.9</td><td>94.4</td><td>94.7</td><td>72.7</td><td>66.0</td><td>77.3</td><td>83.9</td></tr><tr><td>ConvE**</td><td>94.3</td><td>93.5</td><td>94.6</td><td>95.6</td><td>65.7</td><td>55.8</td><td>72.3</td><td>83.1</td></tr><tr><td>CP(D=200)</td><td>94.2</td><td>93.9</td><td>94.5</td><td>94.7</td><td>71.9</td><td>66.2</td><td>75.2</td><td>82.0</td></tr><tr><td>B-CP(D=200)</td><td>90.1</td><td>88.1</td><td>91.8</td><td>93.3</td><td>69.5</td><td>61.1</td><td>76.0</td><td>83.5</td></tr><tr><td>B-CP(D=400)</td><td>94.5</td><td>94.1</td><td>94.8</td><td>95.0</td><td>72.2</td><td>66.3</td><td>77.5</td><td>84.2</td></tr><tr><td>B-CP(D=300 3)</td><td>94.6</td><td>94.2</td><td>95.0</td><td>95.3</td><td>72.9</td><td>66.5</td><td>77.7</td><td>84.9</td></tr></table>\n",
    "# <table><tr><td></td><td>WN18</td><td>FB15k</td><td>WN18RR</td><td>FB15k-237</td></tr><tr><td>Ne</td><td>40,943</td><td>14,951</td><td>40,559</td><td>14,505</td></tr><tr><td>Nr</td><td>18</td><td>1,345</td><td>11</td><td>237</td></tr><tr><td>#trainingtriples</td><td>141,442</td><td>483,142</td><td>86,835</td><td>272,115</td></tr><tr><td>#validationtriples</td><td>5,000</td><td>50,000</td><td>3,034</td><td>17,535</td></tr><tr><td>#testtriples</td><td>5,000</td><td>59,071</td><td>3,134</td><td>20,466</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_complejo = \"\"\"\n",
    "<table><tr><td rowspan=3>Models</td><td colspan=4>WN18</td><td colspan=4>FB15k</td></tr><tr><td rowspan=2>MRR</td><td colspan=3>Hits@</td><td rowspan=2>MRR</td><td colspan=3>Hits@</td></tr><tr><td>1</td><td>3</td><td>10</td><td>1</td><td>3</td><td>10</td></tr><tr><td>TransE*</td><td>45.4</td><td>8.9</td><td>82.3</td><td>93.4</td><td>38.0</td><td>23.1</td><td>47.2</td><td>64.1</td></tr><tr><td>DistMult*</td><td>82.2</td><td>72.8</td><td>91.4</td><td>93.6</td><td>65.4</td><td>54.6</td><td>73.3</td><td>82.4</td></tr><tr><td>HolE*</td><td>93.8</td><td>93.0</td><td>94.5</td><td>94.9</td><td>52.4</td><td>40.2</td><td>61.3</td><td>73.9</td></tr><tr><td>ComplEx*</td><td>94.1</td><td>93.6</td><td>94.5</td><td>94.7</td><td>69.2</td><td>59.9</td><td>75.9</td><td>84.0</td></tr><tr><td>ANALOGY**</td><td>94.2</td><td>93.9</td><td>94.4</td><td>94.7</td><td>72.5</td><td>64.6</td><td>78.5</td><td>85.4</td></tr><tr><td>CP***</td><td>94.2</td><td>93.9</td><td>94.4</td><td>94.7</td><td>72.7</td><td>66.0</td><td>77.3</td><td>83.9</td></tr><tr><td>ConvE**</td><td>94.3</td><td>93.5</td><td>94.6</td><td>95.6</td><td>65.7</td><td>55.8</td><td>72.3</td><td>83.1</td></tr><tr><td>CP(D=200)</td><td>94.2</td><td>93.9</td><td>94.5</td><td>94.7</td><td>71.9</td><td>66.2</td><td>75.2</td><td>82.0</td></tr><tr><td>B-CP(D=200)</td><td>90.1</td><td>88.1</td><td>91.8</td><td>93.3</td><td>69.5</td><td>61.1</td><td>76.0</td><td>83.5</td></tr><tr><td>B-CP(D=400)</td><td>94.5</td><td>94.1</td><td>94.8</td><td>95.0</td><td>72.2</td><td>66.3</td><td>77.5</td><td>84.2</td></tr><tr><td>B-CP(D=300 3)</td><td>94.6</td><td>94.2</td><td>95.0</td><td>95.3</td><td>72.9</td><td>66.5</td><td>77.7</td><td>84.9</td></tr></table>\n",
    "\"\"\"\n",
    "html_simple = \"<table><tr><td></td><td>WN18</td><td>FB15k</td><td>WN18RR</td><td>FB15k-237</td></tr><tr><td>Ne</td><td>40,943</td><td>14,951</td><td>40,559</td><td>14,505</td></tr><tr><td>Nr</td><td>18</td><td>1,345</td><td>11</td><td>237</td></tr><tr><td>#trainingtriples</td><td>141,442</td><td>483,142</td><td>86,835</td><td>272,115</td></tr><tr><td>#validationtriples</td><td>5,000</td><td>50,000</td><td>3,034</td><td>17,535</td></tr><tr><td>#testtriples</td><td>5,000</td><td>59,071</td><td>3,134</td><td>20,466</td></tr></table>\"\n",
    "\n",
    "html_complejo_2 = \"<table><tr><td rowspan=2>Model</td><td rowspan=2>Bitsperentity</td><td rowspan=2>Bitsperrelation</td><td colspan=2>MRR</td></tr><tr><td>WN18RR</td><td>FB15k-237</td></tr><tr><td rowspan=2 colspan=2>DistMult*(D=200) 6,400 ComplEx*(D=200) 12,800</td><td>6,400</td><td>43.0</td><td>24.1</td></tr><tr><td>12,800</td><td>44.0</td><td>24.7</td></tr><tr><td>ConvE*(D=200)</td><td>6,400</td><td>6,400</td><td>43.0</td><td>32.5</td></tr><tr><td rowspan=2>CP(D=15) CP(D=50)</td><td>960</td><td>480</td><td>40.0</td><td>22.0</td></tr><tr><td>3,200</td><td>1,600</td><td>43.0</td><td>24.8</td></tr><tr><td>CP(D=200)</td><td>12,800</td><td>6,400</td><td>44.0</td><td>29.0</td></tr><tr><td>CP(D=500)</td><td>32,000</td><td>16,000</td><td>43.0</td><td>29.2</td></tr><tr><td>VQ-CP(D=200)</td><td>400</td><td>200</td><td>36.0</td><td>8.7</td></tr><tr><td>VQ-CP(D=500)</td><td>1,000</td><td>500</td><td>36.0</td><td>8.3</td></tr><tr><td>B-CP(D=100)</td><td>200</td><td>100</td><td>38.0</td><td>23.2</td></tr><tr><td>B-CP(D=200)</td><td>400</td><td>200</td><td>45.0</td><td>27.8</td></tr><tr><td>B-CP(D=300)</td><td>600</td><td>300</td><td>46.0</td><td>29.0</td></tr><tr><td>B-CP(D=400)</td><td>800</td><td>400</td><td>45.0</td><td>29.2</td></tr><tr><td>B-CP(D=500)</td><td>1,000</td><td>500</td><td>45.0</td><td>29.1</td></tr><tr><td>B-CP(D=300 3)</td><td>1,800</td><td>900</td><td>48.0</td><td>30.3</td></tr></table>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WN18RR', '|E|', '40,943')\n",
      "('WN18RR', '|R|', '11')\n",
      "('WN18RR', '#Train', '86,835')\n",
      "('WN18RR', '#Valid', '3,034')\n",
      "('WN18RR', '#Test', '3,134')\n",
      "('FB15k-237', '|E|', '14,541')\n",
      "('FB15k-237', '|R|', '237')\n",
      "('FB15k-237', '#Train', '272,115')\n",
      "('FB15k-237', '#Valid', '17,535')\n",
      "('FB15k-237', '#Test', '20,466')\n",
      "('WD', '|E|', '418')\n",
      "('WD', '|R|', '2')\n",
      "('WD', '#Train', '550')\n",
      "('WD', '#Valid', '25')\n",
      "('WD', '#Test', '25')\n",
      "('WD ++', '|E|', '763')\n",
      "('WD ++', '|R|', '2')\n",
      "('WD ++', '#Train', '1,120')\n",
      "('WD ++', '#Valid', '40')\n",
      "('WD ++', '#Test', '40')\n",
      "   ⚠️ SALTANDO TABLA: Estructura errónea o compleja.\n",
      "      └── Causa: list index out of range\n",
      "('DISTMULT(Yangetal.2015)[(cid:63)]', 'Type', 'Bilinear')\n",
      "('DISTMULT(Yangetal.2015)[(cid:63)]', 'WN18RR | MRR', '0.43')\n",
      "('DISTMULT(Yangetal.2015)[(cid:63)]', 'WN18RR | H@10', '49')\n",
      "('DISTMULT(Yangetal.2015)[(cid:63)]', 'FB15k-237 | MRR', '0.24')\n",
      "('DISTMULT(Yangetal.2015)[(cid:63)]', 'FB15k-237 | H@10', '41')\n",
      "('ComplEx(Trouillonetal.2016)[(cid:63)]', 'Type', 'Bilinear')\n",
      "('ComplEx(Trouillonetal.2016)[(cid:63)]', 'WN18RR | MRR', '0.44')\n",
      "('ComplEx(Trouillonetal.2016)[(cid:63)]', 'WN18RR | H@10', '51')\n",
      "('ComplEx(Trouillonetal.2016)[(cid:63)]', 'FB15k-237 | MRR', '0.24')\n",
      "('ComplEx(Trouillonetal.2016)[(cid:63)]', 'FB15k-237 | H@10', '42')\n",
      "('TransE(Bordesetal.2013)[(cid:63)]', 'Type', 'Translational')\n",
      "('TransE(Bordesetal.2013)[(cid:63)]', 'WN18RR | MRR', '0.22')\n",
      "('TransE(Bordesetal.2013)[(cid:63)]', 'WN18RR | H@10', '50')\n",
      "('TransE(Bordesetal.2013)[(cid:63)]', 'FB15k-237 | MRR', '0.29')\n",
      "('TransE(Bordesetal.2013)[(cid:63)]', 'FB15k-237 | H@10', '46')\n",
      "('HyperKG(Mo¨biusaddition)', 'Type', 'Translational')\n",
      "('HyperKG(Mo¨biusaddition)', 'WN18RR | MRR', '0.30')\n",
      "('HyperKG(Mo¨biusaddition)', 'WN18RR | H@10', '44')\n",
      "('HyperKG(Mo¨biusaddition)', 'FB15k-237 | MRR', '0.19')\n",
      "('HyperKG(Mo¨biusaddition)', 'FB15k-237 | H@10', '32')\n",
      "('HyperKG(noregularisation)', 'Type', 'Translational')\n",
      "('HyperKG(noregularisation)', 'WN18RR | MRR', '0.30')\n",
      "('HyperKG(noregularisation)', 'WN18RR | H@10', '46')\n",
      "('HyperKG(noregularisation)', 'FB15k-237 | MRR', '0.25')\n",
      "('HyperKG(noregularisation)', 'FB15k-237 | H@10', '41')\n",
      "('HyperKG', 'Type', 'Translational')\n",
      "('HyperKG', 'WN18RR | MRR', '0.41')\n",
      "('HyperKG', 'WN18RR | H@10', '50')\n",
      "('HyperKG', 'FB15k-237 | MRR', '0.28')\n",
      "('HyperKG', 'FB15k-237 | H@10', '45')\n",
      "('HyperKG', 'MRR | 0.92 0.88', '0.98')\n",
      "('HyperKG', 'WD H@10 | 98 96', '98')\n",
      "('HyperKG', 'WD MRR | 0.81 0.89', '0.88')\n",
      "('HyperKG', '++ H@10 | 92 98', '97')\n",
      "('WN18RR', 'Model', 'HyperKG')\n",
      "('WN18RR', '# negsE', '10')\n",
      "('WN18RR', '# negsR', '0')\n",
      "('WN18RR', 'η', '0.01')\n",
      "('WN18RR', 'λ', '0.8')\n",
      "('WN18RR', 'n', '100')\n",
      "('WN18RR', 'γ,', '1.0')\n",
      "('WN18RR', 'β', '(cid:98)n(cid:99) 2')\n",
      "('WN18RR', 'Model', 'HyperKG(Mo¨biusaddition)')\n",
      "('WN18RR', '# negsE', '10')\n",
      "('WN18RR', '# negsR', '0')\n",
      "('WN18RR', 'η', '0.01')\n",
      "('WN18RR', 'n', '100')\n",
      "('WN18RR', 'γ,', '1.0')\n",
      "('WN18RR', 'β', '(cid:98)n(cid:99) 2')\n",
      "('WN18RR', 'Model', 'HyperKG(noregularisation)')\n",
      "('WN18RR', '# negsE', '10')\n",
      "('WN18RR', '# negsR', '0')\n",
      "('WN18RR', 'η', '0.01')\n",
      "('WN18RR', 'λ', '0.0')\n",
      "('WN18RR', 'n', '100')\n",
      "('WN18RR', 'γ,', '1.0')\n",
      "('WN18RR', 'β', '(cid:98)n(cid:99) 2')\n",
      "('FB15k-237', 'Model', 'HyperKG')\n",
      "('FB15k-237', '# negsE', '5')\n",
      "('FB15k-237', '# negsR', '0')\n",
      "('FB15k-237', 'η', '0.01')\n",
      "('FB15k-237', 'λ', '0.2')\n",
      "('FB15k-237', 'n', '100')\n",
      "('FB15k-237', 'γ,', '0.5')\n",
      "('FB15k-237', 'β', '(cid:98)n(cid:99) 2')\n",
      "('FB15k-237', 'Model', 'HyperKG(Mo¨biusaddition)')\n",
      "('FB15k-237', '# negsE', '5')\n",
      "('FB15k-237', '# negsR', '0')\n",
      "('FB15k-237', 'η', '0.01')\n",
      "('FB15k-237', 'n', '100')\n",
      "('FB15k-237', 'γ,', '0.5')\n",
      "('FB15k-237', 'β', '(cid:98)n(cid:99) 2')\n",
      "('FB15k-237', 'Model', 'HyperKG(noregularisation)')\n",
      "('FB15k-237', '# negsE', '5')\n",
      "('FB15k-237', '# negsR', '0')\n",
      "('FB15k-237', 'η', '0.01')\n",
      "('FB15k-237', 'λ', '0.0')\n",
      "('FB15k-237', 'n', '100')\n",
      "('FB15k-237', 'γ,', '0.5')\n",
      "('FB15k-237', 'β', '(cid:98)n(cid:99) 2')\n",
      "('WD', 'Model', 'HyperKG')\n",
      "('WD', '# negsE', '1')\n",
      "('WD', '# negsR', '1')\n",
      "('WD', 'η', '0.8')\n",
      "('WD', 'λ', '0')\n",
      "('WD', 'n', '100')\n",
      "('WD', 'γ,', '7')\n",
      "('WD', 'β', '(cid:98)n(cid:99) 2')\n",
      "('WD ++', 'Model', 'HyperKG')\n",
      "('WD ++', '# negsE', '1')\n",
      "('WD ++', '# negsR', '1')\n",
      "('WD ++', 'η', '0.1')\n",
      "('WD ++', 'λ', '0')\n",
      "('WD ++', 'n', '100')\n",
      "('WD ++', 'γ,', '7')\n",
      "('WD ++', 'β', '(cid:98)n(cid:99) 2')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "FOLDER_ROOT = Path.cwd()\n",
    "TABLES_JSON = FOLDER_ROOT / \"deepdoctection_output.json\"\n",
    "\n",
    "def html_to_matrix(html_str):\n",
    "    soup = BeautifulSoup(html_str, 'html.parser')\n",
    "    rows = soup.find_all('tr')\n",
    "    \n",
    "    grid = {} \n",
    "    max_cols = 0\n",
    "    max_rows = len(rows)\n",
    "    \n",
    "    # Processing\n",
    "    for r, row in enumerate(rows):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        c_idx = 0\n",
    "        \n",
    "        for cell in cells:\n",
    "            while (r, c_idx) in grid:\n",
    "                c_idx += 1\n",
    "            \n",
    "            text = cell.get_text(strip=True)\n",
    "            rowspan = int(cell.get('rowspan', 1))\n",
    "            colspan = int(cell.get('colspan', 1))\n",
    "            \n",
    "            for i in range(rowspan):\n",
    "                for j in range(colspan):\n",
    "                    real_row = r + i\n",
    "                    real_column = c_idx + j\n",
    "                    \n",
    "                    grid[(real_row, real_column)] = text\n",
    "                    if real_column >= max_cols:\n",
    "                        max_cols = real_column + 1\n",
    "\n",
    "            c_idx += colspan\n",
    "\n",
    "    # Turn dictionary into lists (matrix)\n",
    "    matrix = []\n",
    "    for r in range(max_rows):\n",
    "        current_row = []\n",
    "        for c in range(max_cols):\n",
    "            current_row.append(grid.get((r, c), \"\")) \n",
    "        matrix.append(current_row)\n",
    "    return matrix\n",
    "\n",
    "def is_value(text):\n",
    "    text = text.strip()\n",
    "    value_regex = r'^[\\d.,]+[%*]?$|^[-–]$'\n",
    "    return bool(re.match(value_regex, text))\n",
    "\n",
    "def clean_and_convert_to_float(value_str):\n",
    "    if not value_str: return None\n",
    "    clean_str = str(value_str).strip().replace(\"*\", \"\").replace(\",\", \"\")\n",
    "    if clean_str in [\"-\", \"–\", \"—\", \"nan\", \"N/A\"]:\n",
    "        return None\n",
    "    try:\n",
    "        return float(clean_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def split_header(matrix):\n",
    "    if not matrix: return [], []\n",
    "    stub_header = matrix[0][0] \n",
    "    split_idx = 0\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        cells_to_evaluate = row[1:]\n",
    "        if not cells_to_evaluate: continue\n",
    "            \n",
    "        cells_total = len(cells_to_evaluate)\n",
    "        num_count = sum(1 for c in cells_to_evaluate if is_value(c))\n",
    "        different_stub = (row[0] != stub_header)\n",
    "        \n",
    "        if (num_count / cells_total) > 0.5 and different_stub:\n",
    "            split_idx = i\n",
    "            break\n",
    "\n",
    "    headers = matrix[:split_idx]\n",
    "    values = matrix[split_idx:]\n",
    "    return headers, values\n",
    "\n",
    "def extract_tuples(headers, values):\n",
    "    context_by_column = []\n",
    "    num_of_columns = len(headers[0])\n",
    "    \n",
    "    for col_idx in range(1, num_of_columns):\n",
    "        linked_parts = []\n",
    "        last_seen_value = \"\"\n",
    "        \n",
    "        for header_row in headers:\n",
    "            current_value = header_row[col_idx]\n",
    "            if current_value and current_value != last_seen_value:\n",
    "                linked_parts.append(current_value)\n",
    "                last_seen_value = current_value\n",
    "        \n",
    "        final_context = \" | \".join(linked_parts)\n",
    "        context_by_column.append(final_context)\n",
    "    \n",
    "    tuples = []\n",
    "    \n",
    "    for value_row in values:\n",
    "        row_title = value_row[0]\n",
    "        all_values = value_row[1:]\n",
    "        for context, value in zip(context_by_column, all_values):\n",
    "            if value in [\"-\", \"–\", \"\"]:\n",
    "                continue\n",
    "            tuple = (row_title, context, value)\n",
    "            print(f\"{tuple}\")\n",
    "            tuples.append(tuple)\n",
    "            \n",
    "    return tuples\n",
    "\n",
    "def extract_values_from_html_table(html):\n",
    "    matrix = html_to_matrix(html)\n",
    "    if not matrix:\n",
    "        raise ValueError(\"La matriz generada está vacía (HTML sin estructura válida).\")\n",
    "    headers, values = split_header(matrix)\n",
    "    if not values:\n",
    "        raise ValueError(\"No se pudieron separar datos numéricos de las cabeceras.\")\n",
    "    tuples = extract_tuples(headers, values)\n",
    "    structured_data = []\n",
    "\n",
    "    for tuple in tuples:\n",
    "        structured_data.append({\n",
    "                    \"row\": tuple[0],\n",
    "                    \"column\": tuple[1],\n",
    "                    \"value\": clean_and_convert_to_float(tuple[2])\n",
    "                })\n",
    "        \n",
    "    return structured_data\n",
    "    \n",
    "def extract_values_from_paper():\n",
    "    with open(TABLES_JSON, \"r\", encoding=\"utf-8\") as j:\n",
    "        tables_json = json.load(j)\n",
    "\n",
    "    all_tables_data = []\n",
    "    id = 0\n",
    "    for page_data in tables_json['results']:\n",
    "        for table in page_data['tables']:\n",
    "            try:\n",
    "                extracted_data = extract_values_from_html_table(table['html'])\n",
    "                id += 1\n",
    "                table_object = {\n",
    "                    \"id\": id,\n",
    "                    \"page\": page_data['page'],\n",
    "                    \"num_values\": len(extracted_data),\n",
    "                    \"data\": extracted_data\n",
    "                }\n",
    "                all_tables_data.append(table_object)\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ SALTANDO TABLA: Estructura errónea o compleja.\")\n",
    "                print(f\"      └── Causa: {e}\")\n",
    "    values_output_json = {\n",
    "        \"file_name\": tables_json[\"file_name\"],\n",
    "        \"total_num_tables\": all_tables_data.__len__(),\n",
    "        \"table_values\": all_tables_data\n",
    "    }\n",
    "\n",
    "    with open(\"values.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(values_output_json, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "extract_values_from_paper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ddd7b",
   "metadata": {},
   "source": [
    "## Extracción de tareas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c499d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracción de tareas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
